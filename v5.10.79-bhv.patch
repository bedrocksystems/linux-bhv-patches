diff --git arch/arm64/Kbuild arch/arm64/Kbuild
index d6465823b281..f1ea15a79b5a 100644
--- arch/arm64/Kbuild
+++ arch/arm64/Kbuild
@@ -3,4 +3,5 @@ obj-y			+= kernel/ mm/
 obj-$(CONFIG_NET)	+= net/
 obj-$(CONFIG_KVM)	+= kvm/
 obj-$(CONFIG_XEN)	+= xen/
+obj-$(CONFIG_BHV_VAS)	+= bhv/
 obj-$(CONFIG_CRYPTO)	+= crypto/
diff --git arch/arm64/Kconfig arch/arm64/Kconfig
index 5e5cf3af6351..1ed9422f27f4 100644
--- arch/arm64/Kconfig
+++ arch/arm64/Kconfig
@@ -1149,6 +1149,16 @@ config XEN
 	help
 	  Say Y if you want to run Linux in a Virtual Machine on Xen on ARM64.
 
+config BHV_VAS
+	def_bool y
+	bool "BVH guest support on ARM64"
+	depends on ARM64 && OF
+	help
+	  Say Y if you want to run Linux in a Virtual Machine on BHV on ARM64
+	  and benefit from Virtualization-assisted Security.
+
+source "kernel/bhv/Kconfig"
+
 config FORCE_MAX_ZONEORDER
 	int
 	default "14" if (ARM64_64K_PAGES && TRANSPARENT_HUGEPAGE)
diff --git arch/arm64/bhv/Makefile arch/arm64/bhv/Makefile
new file mode 100644
index 000000000000..e66e83fdb5eb
--- /dev/null
+++ arch/arm64/bhv/Makefile
@@ -0,0 +1,14 @@
+# SPDX-License-Identifier: GPL-2.0-only
+
+# Copyright (C) 2022 - BedRock Systems Inc
+# Authors: Sergej Proskurin <sergej@bedrocksystems.com>
+#          Jonas Pfoh <jonas@bedrocksystems.com>
+#          Sebastian Vogl <sebastian@bedrocksystems.com>
+
+obj-$(CONFIG_BHV_VAS)		:= start.o
+obj-$(CONFIG_BHV_VAS)		+= init.o
+obj-$(CONFIG_BHV_VAS)		+= integrity.o
+ifeq ($(CONFIG_JUMP_LABEL),y)
+obj-$(CONFIG_BHV_VAS)		+= patch_jump_label.o
+endif
+obj-$(CONFIG_BHV_VAS)		+= patch_alternative.o
diff --git arch/arm64/bhv/init.c arch/arm64/bhv/init.c
new file mode 100644
index 000000000000..70a504119bab
--- /dev/null
+++ arch/arm64/bhv/init.c
@@ -0,0 +1,14 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Author: Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#include <asm/sections.h>
+
+#include <bhv/interface/integrity.h>
+
+void __init bhv_init_hyp_arch(bhv_mem_region_t *init_phys_mem_regions,
+			      unsigned int *region_counter)
+{
+}
diff --git arch/arm64/bhv/integrity.c arch/arm64/bhv/integrity.c
new file mode 100644
index 000000000000..454a5689442c
--- /dev/null
+++ arch/arm64/bhv/integrity.c
@@ -0,0 +1,68 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Author: Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#include <asm/page.h>
+#include <asm/io.h>
+#include <asm-generic/sections.h>
+
+#include <bhv/interface/common.h>
+#include <bhv/integrity.h>
+
+#include <bhv/bhv.h>
+
+extern char vdso_start[], vdso_end[];
+
+int bhv_start_integrity_arch(void)
+{
+#define NUM_BHV_MEM_REGION_NODES 2
+	int rv = 0;
+	int rc;
+	bhv_mem_region_node_t *n[NUM_BHV_MEM_REGION_NODES];
+
+	if (!bhv_integrity_is_enabled())
+		return 0;
+
+	rc = kmem_cache_alloc_bulk(bhv_mem_region_cache, GFP_KERNEL,
+				   NUM_BHV_MEM_REGION_NODES, (void **)&n);
+	if (!rc) {
+		bhv_fail("BHV: failed to allocate mem region");
+		return -ENOMEM;
+	}
+
+	BUG_ON((uint64_t)vdso_start < (uint64_t)__start_rodata ||
+	       (uint64_t)vdso_start >= (uint64_t)__end_rodata);
+	BUG_ON((uint64_t)vdso_end < (uint64_t)__start_rodata ||
+	       (uint64_t)vdso_end >= (uint64_t)__end_rodata);
+
+	/* Add ro_data section
+	 * NOTE: ro_after_init is contained in this section as well
+	 * NOTE: We split this out such that the VDSO section is not included.
+	 */
+	n[0]->region.bhv_mem_region_create.start_addr =
+		virt_to_phys((void *)__start_rodata);
+	n[0]->region.bhv_mem_region_create.size = vdso_start - __start_rodata;
+	n[0]->region.bhv_mem_region_create.type = BHV_MEM_TYPE_DATA_READ_ONLY;
+	n[0]->region.bhv_mem_region_create.flags = BHV_MEM_FLAGS_NONE;
+	n[0]->region.bhv_mem_region_create.next = virt_to_phys(&(n[1]->region));
+
+	n[1]->region.bhv_mem_region_create.start_addr =
+		virt_to_phys((void *)vdso_end);
+	n[1]->region.bhv_mem_region_create.size = __end_rodata - vdso_end;
+	n[1]->region.bhv_mem_region_create.type = BHV_MEM_TYPE_DATA_READ_ONLY;
+	n[1]->region.bhv_mem_region_create.flags = BHV_MEM_FLAGS_NONE;
+	n[1]->region.bhv_mem_region_create.next = BHV_INVALID_PHYS_ADDR;
+
+	rc = bhv_create_kern_phys_mem_region_hyp(0, &(n[0]->region));
+	if (rc) {
+		pr_err("BHV: create phys mem region failed: %d", rc);
+		rv = rc;
+	}
+
+	kmem_cache_free_bulk(bhv_mem_region_cache, NUM_BHV_MEM_REGION_NODES,
+			     (void **)&n);
+
+	return rv;
+}
diff --git arch/arm64/bhv/patch_alternative.c arch/arm64/bhv/patch_alternative.c
new file mode 100644
index 000000000000..a16d97cd2704
--- /dev/null
+++ arch/arm64/bhv/patch_alternative.c
@@ -0,0 +1,376 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Sebastian Vogl <sebastian@bedrocksystems.com>
+ *          Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#include <bhv/patch.h>
+#include <bhv/interface/patch.h>
+#include <asm/bhv/patch.h>
+#include <bhv/vault.h>
+#include <bhv/bhv.h>
+#include <asm/insn.h>
+#include <asm/debug-monitors.h>
+#include <linux/mm.h>
+
+void bhv_alternatives_add_module_arch(struct alt_instr *begin,
+				      struct alt_instr *end, bool is_module)
+{
+	struct bhv_alternatives_mod_arch arch = { .is_module = is_module };
+	bhv_alternatives_add_module(begin, end, &arch);
+}
+
+static int __bhv_text bhv_aarch64_get_imm_shift_mask(
+	enum aarch64_insn_imm_type type, u32 *maskp, int *shiftp)
+{
+	u32 mask;
+	int shift;
+
+	switch (type) {
+	case AARCH64_INSN_IMM_26:
+		mask = BIT(26) - 1;
+		shift = 0;
+		break;
+	case AARCH64_INSN_IMM_19:
+		mask = BIT(19) - 1;
+		shift = 5;
+		break;
+	case AARCH64_INSN_IMM_16:
+		mask = BIT(16) - 1;
+		shift = 5;
+		break;
+	case AARCH64_INSN_IMM_14:
+		mask = BIT(14) - 1;
+		shift = 5;
+		break;
+	case AARCH64_INSN_IMM_12:
+		mask = BIT(12) - 1;
+		shift = 10;
+		break;
+	case AARCH64_INSN_IMM_9:
+		mask = BIT(9) - 1;
+		shift = 12;
+		break;
+	case AARCH64_INSN_IMM_7:
+		mask = BIT(7) - 1;
+		shift = 15;
+		break;
+	case AARCH64_INSN_IMM_6:
+	case AARCH64_INSN_IMM_S:
+		mask = BIT(6) - 1;
+		shift = 10;
+		break;
+	case AARCH64_INSN_IMM_R:
+		mask = BIT(6) - 1;
+		shift = 16;
+		break;
+	case AARCH64_INSN_IMM_N:
+		mask = 1;
+		shift = 22;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	*maskp = mask;
+	*shiftp = shift;
+
+	return 0;
+}
+
+#define ADR_IMM_HILOSPLIT 2
+#define ADR_IMM_SIZE SZ_2M
+#define ADR_IMM_LOMASK ((1 << ADR_IMM_HILOSPLIT) - 1)
+#define ADR_IMM_HIMASK ((ADR_IMM_SIZE >> ADR_IMM_HILOSPLIT) - 1)
+#define ADR_IMM_LOSHIFT 29
+#define ADR_IMM_HISHIFT 5
+
+static u64 __bhv_text
+bhv_aarch64_insn_decode_immediate(enum aarch64_insn_imm_type type, u32 insn)
+{
+	u32 immlo, immhi, mask;
+	int shift;
+
+	switch (type) {
+	case AARCH64_INSN_IMM_ADR:
+		shift = 0;
+		immlo = (insn >> ADR_IMM_LOSHIFT) & ADR_IMM_LOMASK;
+		immhi = (insn >> ADR_IMM_HISHIFT) & ADR_IMM_HIMASK;
+		insn = (immhi << ADR_IMM_HILOSPLIT) | immlo;
+		mask = ADR_IMM_SIZE - 1;
+		break;
+	default:
+		if (bhv_aarch64_get_imm_shift_mask(type, &mask, &shift) < 0) {
+			return 0;
+		}
+	}
+
+	return (insn >> shift) & mask;
+}
+
+static s32 __bhv_text bhv_aarch64_get_branch_offset(u32 insn)
+{
+	s32 imm;
+
+	if (aarch64_insn_is_b(insn) || aarch64_insn_is_bl(insn)) {
+		imm = bhv_aarch64_insn_decode_immediate(AARCH64_INSN_IMM_26,
+							insn);
+		return (imm << 6) >> 4;
+	}
+
+	if (aarch64_insn_is_cbz(insn) || aarch64_insn_is_cbnz(insn) ||
+	    aarch64_insn_is_bcond(insn)) {
+		imm = bhv_aarch64_insn_decode_immediate(AARCH64_INSN_IMM_19,
+							insn);
+		return (imm << 13) >> 11;
+	}
+
+	if (aarch64_insn_is_tbz(insn) || aarch64_insn_is_tbnz(insn)) {
+		imm = bhv_aarch64_insn_decode_immediate(AARCH64_INSN_IMM_14,
+							insn);
+		return (imm << 18) >> 16;
+	}
+
+	return 0;
+}
+
+static bool __bhv_text bhv_aarch64_insn_is_branch_imm(u32 insn)
+{
+	return (aarch64_insn_is_b(insn) || aarch64_insn_is_bl(insn) ||
+		aarch64_insn_is_tbz(insn) || aarch64_insn_is_tbnz(insn) ||
+		aarch64_insn_is_cbz(insn) || aarch64_insn_is_cbnz(insn) ||
+		aarch64_insn_is_bcond(insn));
+}
+
+static u32 __bhv_text bhv_aarch64_insn_encode_immediate(
+	enum aarch64_insn_imm_type type, u32 insn, u64 imm)
+{
+	u32 immlo, immhi, mask;
+	int shift;
+
+	if (insn == AARCH64_BREAK_FAULT)
+		return AARCH64_BREAK_FAULT;
+
+	switch (type) {
+	case AARCH64_INSN_IMM_ADR:
+		shift = 0;
+		immlo = (imm & ADR_IMM_LOMASK) << ADR_IMM_LOSHIFT;
+		imm >>= ADR_IMM_HILOSPLIT;
+		immhi = (imm & ADR_IMM_HIMASK) << ADR_IMM_HISHIFT;
+		imm = immlo | immhi;
+		mask = ((ADR_IMM_LOMASK << ADR_IMM_LOSHIFT) |
+			(ADR_IMM_HIMASK << ADR_IMM_HISHIFT));
+		break;
+	default:
+		if (bhv_aarch64_get_imm_shift_mask(type, &mask, &shift) < 0) {
+			return AARCH64_BREAK_FAULT;
+		}
+	}
+
+	/* Update the immediate field. */
+	insn &= ~(mask << shift);
+	insn |= (imm & mask) << shift;
+
+	return insn;
+}
+
+static u32 __bhv_text bhv_aarch64_set_branch_offset(u32 insn, s32 offset)
+{
+	if (aarch64_insn_is_b(insn) || aarch64_insn_is_bl(insn))
+		return aarch64_insn_encode_immediate(AARCH64_INSN_IMM_26, insn,
+						     offset >> 2);
+
+	if (aarch64_insn_is_cbz(insn) || aarch64_insn_is_cbnz(insn) ||
+	    aarch64_insn_is_bcond(insn))
+		return aarch64_insn_encode_immediate(AARCH64_INSN_IMM_19, insn,
+						     offset >> 2);
+
+	if (aarch64_insn_is_tbz(insn) || aarch64_insn_is_tbnz(insn))
+		return aarch64_insn_encode_immediate(AARCH64_INSN_IMM_14, insn,
+						     offset >> 2);
+
+	return 0;
+}
+
+static s32 __bhv_text bhv_aarch64_insn_adrp_get_offset(u32 insn)
+{
+	return bhv_aarch64_insn_decode_immediate(AARCH64_INSN_IMM_ADR, insn)
+	       << 12;
+}
+
+static u32 __bhv_text bhv_aarch64_insn_adrp_set_offset(u32 insn, s32 offset)
+{
+	return bhv_aarch64_insn_encode_immediate(AARCH64_INSN_IMM_ADR, insn,
+						 offset >> 12);
+}
+
+#define __ALT_PTR(a, f) ((void *)&(a)->f + (a)->f)
+#define ALT_ORIG_PTR(a) __ALT_PTR(a, orig_offset)
+#define ALT_REPL_PTR(a) __ALT_PTR(a, alt_offset)
+
+static bool __bhv_text branch_insn_requires_update(struct alt_instr *alt,
+						   unsigned long pc)
+{
+	unsigned long replptr = (unsigned long)ALT_REPL_PTR(alt);
+	return !(pc >= replptr && pc <= (replptr + alt->alt_len));
+}
+
+#define align_down(x, a) ((unsigned long)(x) & ~(((unsigned long)(a)) - 1))
+
+static u32 __bhv_text bhv_get_alt_insn(struct alt_instr *alt, __le32 *insnptr,
+				       __le32 *altinsnptr)
+{
+	u32 insn;
+
+	insn = le32_to_cpu(*altinsnptr);
+
+	if (bhv_aarch64_insn_is_branch_imm(insn)) {
+		s32 offset = bhv_aarch64_get_branch_offset(insn);
+		unsigned long target;
+
+		target = (unsigned long)altinsnptr + offset;
+
+		/*
+		 * If we're branching inside the alternate sequence,
+		 * do not rewrite the instruction, as it is already
+		 * correct. Otherwise, generate the new instruction.
+		 */
+		if (branch_insn_requires_update(alt, target)) {
+			offset = target - (unsigned long)insnptr;
+			insn = bhv_aarch64_set_branch_offset(insn, offset);
+		}
+	} else if (aarch64_insn_is_adrp(insn)) {
+		s32 orig_offset, new_offset;
+		unsigned long target;
+
+		/*
+		 * If we're replacing an adrp instruction, which uses PC-relative
+		 * immediate addressing, adjust the offset to reflect the new
+		 * PC. adrp operates on 4K aligned addresses.
+		 */
+		orig_offset = bhv_aarch64_insn_adrp_get_offset(insn);
+		target = align_down(altinsnptr, SZ_4K) + orig_offset;
+		new_offset = target - align_down(insnptr, SZ_4K);
+		insn = bhv_aarch64_insn_adrp_set_offset(insn, new_offset);
+	}
+
+	return insn;
+}
+
+static void __bhv_text bhv_alternatives_patch(struct alt_instr *alt,
+					      __le32 *origptr, __le32 *updptr,
+					      int nr_inst,
+					      bhv_patch_arg_t *bhv_arg)
+{
+	__le32 *replptr = 0;
+	int i;
+
+	replptr = ALT_REPL_PTR(alt);
+	for (i = 0; i < nr_inst; i++) {
+		u32 insn;
+
+		insn = bhv_get_alt_insn(alt, origptr + i, replptr + i);
+		insn = cpu_to_le32(insn);
+
+		bhv_arg->bhv_patch_patch_arg.dest_phys_addr =
+			virt_to_phys((void *)&updptr[i]);
+		memcpy(bhv_arg->bhv_patch_patch_arg.src_value, &insn,
+		       sizeof(bhv_arg->bhv_patch_patch_arg.src_value));
+		bhv_arg->bhv_patch_patch_arg.size =
+			sizeof(bhv_arg->bhv_patch_patch_arg.src_value);
+
+		bhv_hypercall_vas(BHV_VAS_BACKEND_PATCH,
+				  BHV_VAS_PATCH_OP_PATCH_NO_CLOSE, bhv_arg);
+	}
+}
+
+/*
+ * We provide our own, private D-cache cleaning function so that we don't
+ * accidentally call into the cache.S code, which is patched by us at
+ * runtime.
+ */
+static void __bhv_text clean_dcache_range_nopatch(u64 start, u64 end)
+{
+	u64 cur, d_size, ctr_el0;
+
+	ctr_el0 = read_sanitised_ftr_reg(SYS_CTR_EL0);
+	d_size = 4 << cpuid_feature_extract_unsigned_field(ctr_el0,
+							   CTR_DMINLINE_SHIFT);
+	cur = start & ~(d_size - 1);
+	do {
+		/*
+		 * We must clean+invalidate to the PoC in order to avoid
+		 * Cortex-A53 errata 826319, 827319, 824069 and 819472
+		 * (this corresponds to ARM64_WORKAROUND_CLEAN_CACHE)
+		 */
+		asm volatile("dc civac, %0" : : "r"(cur) : "memory");
+	} while (cur += d_size, cur < end);
+}
+
+int __bhv_text bhv_alternatives_apply_vault_arch(
+	struct bhv_alternatives_mod *mod, void *arch, bhv_patch_arg_t *bhv_arg)
+{
+	unsigned long *feature_mask = (unsigned long *)arch;
+
+	struct alt_instr *alt;
+	__le32 *origptr, *updptr;
+	alternative_cb_t alt_cb;
+
+	for (alt = mod->begin; alt < mod->end; alt++) {
+		int nr_inst;
+
+		if (!test_bit(alt->cpufeature, feature_mask))
+			continue;
+
+		/* Use ARM64_CB_PATCH as an unconditional patch */
+		if (alt->cpufeature < ARM64_CB_PATCH &&
+		    !cpus_have_cap(alt->cpufeature))
+			continue;
+
+		if (alt->cpufeature == ARM64_CB_PATCH) {
+			if (alt->alt_len != 0) {
+				return -EACCES;
+			}
+		} else {
+			if (alt->alt_len != alt->orig_len) {
+				return -EACCES;
+			}
+		}
+
+		origptr = ALT_ORIG_PTR(alt);
+		updptr = mod->arch.is_module ? origptr : lm_alias(origptr);
+		nr_inst = alt->orig_len / AARCH64_INSN_SIZE;
+
+		if (alt->cpufeature < ARM64_CB_PATCH) {
+			bhv_alternatives_patch(alt, origptr, updptr, nr_inst,
+					       bhv_arg);
+		} else {
+			alt_cb = ALT_REPL_PTR(alt);
+			alt_cb(alt, origptr, updptr, nr_inst, bhv_arg);
+		}
+
+		if (!mod->arch.is_module) {
+			clean_dcache_range_nopatch((u64)origptr,
+						   (u64)(origptr + nr_inst));
+		}
+	}
+
+	return 0;
+}
+
+struct bhv_alternatives_mod *__bhv_text
+bhv_alternatives_get_static_mods_vault(uint32_t *nr_mods)
+{
+	static struct bhv_alternatives_mod kernel = {
+		.begin = (struct alt_instr *)__alt_instructions,
+		.end = (struct alt_instr *)__alt_instructions_end,
+		.delete_policy = BHV_ALTERNATIVES_DELETE_AFTER_INIT,
+		.allocated = false,
+		.arch = { .is_module = false },
+		.next = { .next = NULL, .prev = NULL }
+	};
+
+	*nr_mods = 1;
+	return &kernel;
+}
diff --git arch/arm64/bhv/patch_jump_label.c arch/arm64/bhv/patch_jump_label.c
new file mode 100644
index 000000000000..610215168f50
--- /dev/null
+++ arch/arm64/bhv/patch_jump_label.c
@@ -0,0 +1,79 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ *          Sebastian Vogl <sebastian@bedrocksystems.com>
+ */
+
+#include <linux/jump_label.h>
+#include <linux/string.h>
+#include <asm/insn.h>
+#include <asm/debug-monitors.h>
+#include <asm/bhv/patch.h>
+
+static __always_inline bool bhv_branch_imm_common(unsigned long pc,
+						  unsigned long addr,
+						  long range, long *offset)
+{
+	if ((pc & 0x3) || (addr & 0x3)) {
+		return false;
+	}
+
+	*offset = ((long)addr - (long)pc);
+
+	if (*offset < -range || *offset >= range) {
+		return false;
+	}
+
+	return true;
+}
+
+u32 __always_inline bhv_aarch64_insn_encode_immediate(u32 insn, u64 imm)
+{
+	u32 mask;
+	int shift;
+
+	if (insn == AARCH64_BREAK_FAULT)
+		return AARCH64_BREAK_FAULT;
+
+	mask = BIT(26) - 1;
+	shift = 0;
+
+	/* Update the immediate field. */
+	insn &= ~(mask << shift);
+	insn |= (imm & mask) << shift;
+
+	return insn;
+}
+
+bool __bhv_text bhv_jump_label_validate_opcode(struct jump_entry *entry,
+					       enum jump_label_type type,
+					       const void *expected_opcode,
+					       size_t size)
+{
+	u32 jmp_insn, nop_insn;
+	long offset;
+	void *addr = (void *)jump_entry_code(entry);
+
+	if (!bhv_branch_imm_common((long)addr, jump_entry_target(entry),
+				   SZ_128M, &offset))
+		return false;
+	jmp_insn = aarch64_insn_get_b_value();
+	jmp_insn = bhv_aarch64_insn_encode_immediate(jmp_insn, offset >> 2);
+
+	nop_insn = aarch64_insn_get_hint_value() | AARCH64_INSN_HINT_NOP;
+
+	if (type == JUMP_LABEL_JMP) {
+		if (memcmp(addr, &nop_insn, AARCH64_INSN_SIZE))
+			return false;
+		if (memcmp(expected_opcode, &jmp_insn, AARCH64_INSN_SIZE))
+			return false;
+	} else {
+		if (memcmp(addr, &jmp_insn, AARCH64_INSN_SIZE))
+			return false;
+		if (memcmp(expected_opcode, &nop_insn, AARCH64_INSN_SIZE))
+			return false;
+	}
+
+	return true;
+}
diff --git arch/arm64/bhv/start.c arch/arm64/bhv/start.c
new file mode 100644
index 000000000000..605d0ae18110
--- /dev/null
+++ arch/arm64/bhv/start.c
@@ -0,0 +1,18 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ *          Sergej Proskurin <sergej@bedrocksystems.com>
+ */
+
+#include <asm/io.h>
+#include <asm/syscall.h>
+
+#include <bhv/interface/common.h>
+#include <bhv/integrity.h>
+#include <bhv/bhv.h>
+
+int bhv_start_arch(void)
+{
+	return bhv_start_integrity_arch();
+}
diff --git arch/arm64/include/asm/alternative.h arch/arm64/include/asm/alternative.h
index 3cb3c4ab3ea5..632546cb6526 100644
--- arch/arm64/include/asm/alternative.h
+++ arch/arm64/include/asm/alternative.h
@@ -14,6 +14,8 @@
 #include <linux/stddef.h>
 #include <linux/stringify.h>
 
+#include <bhv/interface/patch.h>
+
 struct alt_instr {
 	s32 orig_offset;	/* offset to original instruction */
 	s32 alt_offset;		/* offset to replacement instruction */
@@ -22,8 +24,14 @@ struct alt_instr {
 	u8  alt_len;		/* size of new instruction(s), <= orig_len */
 };
 
+#ifdef CONFIG_BHV_VAS
+typedef void (*alternative_cb_t)(struct alt_instr *alt, __le32 *origptr,
+				 __le32 *updptr, int nr_inst,
+				 bhv_patch_arg_t *bhv_arg);
+#else /* !CONFIG_BHV_VAS */
 typedef void (*alternative_cb_t)(struct alt_instr *alt,
 				 __le32 *origptr, __le32 *updptr, int nr_inst);
+#endif /* CONFIG_BHV_VAS */
 
 void __init apply_boot_alternatives(void);
 void __init apply_alternatives_all(void);
diff --git arch/arm64/include/asm/bhv/hypercall.h arch/arm64/include/asm/bhv/hypercall.h
new file mode 100644
index 000000000000..16f767181c09
--- /dev/null
+++ arch/arm64/include/asm/bhv/hypercall.h
@@ -0,0 +1,30 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#ifndef __ASM_BHV_HYPERCALL_H__
+#define __ASM_BHV_HYPERCALL_H__
+
+#define BHV_IMM 0x539
+
+static __always_inline unsigned long BHV_HYPERCALL(uint16_t target,
+						   uint32_t backend,
+						   uint32_t op, uint32_t ver,
+						   uint64_t arg)
+{
+	// https://gcc.gnu.org/onlinedocs/gcc/Local-Register-Variables.html
+	register unsigned long x0 __asm__("x0") = target;
+	register unsigned long x1 __asm__("x1") = backend;
+	register unsigned long x2 __asm__("x2") = op;
+	register unsigned long x3 __asm__("x3") = ver;
+	register unsigned long x4 __asm__("x4") = arg;
+	__asm__ __volatile__("hvc " __stringify(BHV_IMM) "\n\t"
+			     : "+r"(x0)
+			     : "r"(x1), "r"(x2), "r"(x3), "r"(x4)
+			     :);
+	return x0;
+}
+
+#endif /* __ASM_BHV_HYPERCALL_H__ */
diff --git arch/arm64/include/asm/bhv/patch.h arch/arm64/include/asm/bhv/patch.h
new file mode 100644
index 000000000000..0a0a0dedd484
--- /dev/null
+++ arch/arm64/include/asm/bhv/patch.h
@@ -0,0 +1,43 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ *          Sebastian Vogl <sebastian@bedrocksystems.com>
+ */
+
+#ifndef __ASM_BHV_PATCH_H__
+#define __ASM_BHV_PATCH_H__
+
+struct bhv_alternatives_mod;
+struct bhv_alternatives_mod_arch {
+	bool is_module;
+};
+
+#ifdef CONFIG_BHV_VAS
+#include <bhv/bhv.h>
+
+#ifdef CONFIG_JUMP_LABEL
+#include <linux/jump_label.h>
+
+bool __bhv_text bhv_jump_label_validate_opcode(struct jump_entry *entry,
+					       enum jump_label_type type,
+					       const void *expected_opcode,
+					       size_t len);
+#endif /* CONFIG_JUMP_LABEL */
+
+int __bhv_text bhv_alternatives_apply_vault_arch(
+	struct bhv_alternatives_mod *mod, void *arch, bhv_patch_arg_t *bhv_arg);
+void __bhv_text bhv_alternatives_add_module_arch(struct alt_instr *begin,
+						 struct alt_instr *end,
+						 bool is_module);
+struct bhv_alternatives_mod *__bhv_text
+bhv_alternatives_get_static_mods_vault(uint32_t *nr_mods);
+
+#else /* !CONFIG_BHV_VAS */
+static inline void bhv_alternatives_add_module_arch(struct alt_instr *,
+						    struct alt_instr *, bool)
+{
+}
+#endif /* CONFIG_BHV_VAS */
+
+#endif /* __ASM_BHV_PATCH_H__ */
diff --git arch/arm64/include/asm/kvm_mmu.h arch/arm64/include/asm/kvm_mmu.h
index 331394306cce..0cdb121c095d 100644
--- arch/arm64/include/asm/kvm_mmu.h
+++ arch/arm64/include/asm/kvm_mmu.h
@@ -80,8 +80,17 @@ alternative_cb_end
 #include <asm/cacheflush.h>
 #include <asm/mmu_context.h>
 
+#ifdef CONFIG_BHV_VAS
+#include <bhv/interface/patch.h>
+#endif
+
+#ifdef CONFIG_BHV_VAS
+void kvm_update_va_mask(struct alt_instr *alt, __le32 *origptr, __le32 *updptr,
+			int nr_inst, bhv_patch_arg_t *bhv_arg);
+#else /* CONFIG_BHV_VAS */
 void kvm_update_va_mask(struct alt_instr *alt,
 			__le32 *origptr, __le32 *updptr, int nr_inst);
+#endif /* CONFIG_BHV_VAS */
 void kvm_compute_layout(void);
 
 static __always_inline unsigned long __kern_hyp_va(unsigned long v)
diff --git arch/arm64/kernel/alternative.c arch/arm64/kernel/alternative.c
index 73039949b5ce..12cdee47c9da 100644
--- arch/arm64/kernel/alternative.c
+++ arch/arm64/kernel/alternative.c
@@ -17,6 +17,9 @@
 #include <asm/sections.h>
 #include <linux/stop_machine.h>
 
+#include <bhv/patch.h>
+#include <bhv/integrity.h>
+
 #define __ALT_PTR(a,f)		((void *)&(a)->f + (a)->f)
 #define ALT_ORIG_PTR(a)		__ALT_PTR(a, orig_offset)
 #define ALT_REPL_PTR(a)		__ALT_PTR(a, alt_offset)
@@ -94,8 +97,13 @@ static u32 get_alt_insn(struct alt_instr *alt, __le32 *insnptr, __le32 *altinsnp
 	return insn;
 }
 
+#ifdef CONFIG_BHV_VAS
+static void patch_alternative(struct alt_instr *alt, __le32 *origptr,
+			      __le32 *updptr, int nr_inst, bhv_patch_arg_t *arg)
+#else
 static void patch_alternative(struct alt_instr *alt,
 			      __le32 *origptr, __le32 *updptr, int nr_inst)
+#endif
 {
 	__le32 *replptr;
 	int i;
@@ -132,14 +140,22 @@ static void clean_dcache_range_nopatch(u64 start, u64 end)
 	} while (cur += d_size, cur < end);
 }
 
-static void __apply_alternatives(void *alt_region,  bool is_module,
+static void __apply_alternatives(void *alt_region, bool is_module,
 				 unsigned long *feature_mask)
 {
-	struct alt_instr *alt;
 	struct alt_region *region = alt_region;
+	struct alt_instr *alt;
 	__le32 *origptr, *updptr;
 	alternative_cb_t alt_cb;
 
+#ifdef CONFIG_BHV_VAS
+	if (bhv_integrity_is_enabled()) {
+		bhv_alternatives_apply(region->begin, region->end,
+				       feature_mask);
+		return;
+	}
+#endif /* CONFIG_BHV_VAS */
+
 	for (alt = region->begin; alt < region->end; alt++) {
 		int nr_inst;
 
@@ -167,7 +183,11 @@ static void __apply_alternatives(void *alt_region,  bool is_module,
 		else
 			alt_cb  = ALT_REPL_PTR(alt);
 
+#ifdef CONFIG_BHV_VAS
+		alt_cb(alt, origptr, updptr, nr_inst, NULL);
+#else
 		alt_cb(alt, origptr, updptr, nr_inst);
+#endif
 
 		if (!is_module) {
 			clean_dcache_range_nopatch((u64)origptr,
@@ -254,10 +274,15 @@ void apply_alternatives_module(void *start, size_t length)
 		.begin	= start,
 		.end	= start + length,
 	};
+
 	DECLARE_BITMAP(all_capabilities, ARM64_NPATCHABLE);
 
 	bitmap_fill(all_capabilities, ARM64_NPATCHABLE);
 
+	if (bhv_integrity_is_enabled()) {
+		bhv_alternatives_add_module_arch(region.begin, region.end,
+						 true);
+	}
 	__apply_alternatives(&region, true, &all_capabilities[0]);
 }
 #endif
diff --git arch/arm64/kernel/jump_label.c arch/arm64/kernel/jump_label.c
index 9a8a0ae1e75f..c95fe7342c61 100644
--- arch/arm64/kernel/jump_label.c
+++ arch/arm64/kernel/jump_label.c
@@ -9,10 +9,14 @@
 #include <linux/jump_label.h>
 #include <asm/insn.h>
 
+#include <bhv/bhv.h>
+#include <bhv/integrity.h>
+#include <bhv/patch.h>
+
 void arch_jump_label_transform(struct jump_entry *entry,
 			       enum jump_label_type type)
 {
-	void *addr = (void *)jump_entry_code(entry);
+	void __maybe_unused *addr = (void *)jump_entry_code(entry);
 	u32 insn;
 
 	if (type == JUMP_LABEL_JMP) {
@@ -23,6 +27,13 @@ void arch_jump_label_transform(struct jump_entry *entry,
 		insn = aarch64_insn_gen_nop();
 	}
 
+#ifdef CONFIG_BHV_VAS
+	if (bhv_integrity_is_enabled()) {
+		bhv_patch_jump_label(entry, &insn, AARCH64_INSN_SIZE);
+		return;
+	}
+#endif
+
 	aarch64_insn_patch_text_nosync(addr, insn);
 }
 
diff --git arch/arm64/kernel/proton-pack.c arch/arm64/kernel/proton-pack.c
index f6e4e3737405..8b54537ca941 100644
--- arch/arm64/kernel/proton-pack.c
+++ arch/arm64/kernel/proton-pack.c
@@ -27,6 +27,13 @@
 #include <asm/spectre.h>
 #include <asm/traps.h>
 
+#include <bhv/bhv.h>
+#include <bhv/integrity.h>
+#include <bhv/patch.h>
+#include <bhv/interface/hypercall.h>
+#include <bhv/interface/patch.h>
+#include <asm/bhv/patch.h>
+
 /*
  * We try to ensure that the mitigation state can never change as the result of
  * onlining a late CPU.
@@ -551,10 +558,21 @@ static enum mitigation_state spectre_v4_enable_hw_mitigation(void)
  * Patch a branch over the Spectre-v4 mitigation code with a NOP so that
  * we fallthrough and check whether firmware needs to be called on this CPU.
  */
+#ifdef CONFIG_BHV_VAS
+void __init spectre_v4_patch_fw_mitigation_enable(struct alt_instr *alt,
+						  __le32 *origptr,
+						  __le32 *updptr, int nr_inst,
+						  bhv_patch_arg_t *bhv_arg)
+#else /* !CONFIG_BHV_VAS */
 void __init spectre_v4_patch_fw_mitigation_enable(struct alt_instr *alt,
 						  __le32 *origptr,
 						  __le32 *updptr, int nr_inst)
+#endif /* CONFIG_BHV_VAS */
 {
+#ifdef CONFIG_BHV_VAS
+	u32 insn;
+#endif /* CONFIG_BHV_VAS */
+
 	BUG_ON(nr_inst != 1); /* Branch -> NOP */
 
 	if (spectre_v4_mitigations_off())
@@ -563,17 +581,42 @@ void __init spectre_v4_patch_fw_mitigation_enable(struct alt_instr *alt,
 	if (cpus_have_final_cap(ARM64_SSBS))
 		return;
 
-	if (spectre_v4_mitigations_dynamic())
+	if (spectre_v4_mitigations_dynamic()) {
+#ifdef CONFIG_BHV_VAS
+		if (bhv_integrity_is_enabled()) {
+			insn = cpu_to_le32(aarch64_insn_gen_nop());
+			bhv_arg->bhv_patch_patch_arg.dest_phys_addr =
+				virt_to_phys((void *)updptr);
+			memcpy(bhv_arg->bhv_patch_patch_arg.src_value, &insn,
+			       sizeof(bhv_arg->bhv_patch_patch_arg.src_value));
+			bhv_arg->bhv_patch_patch_arg.size =
+				sizeof(bhv_arg->bhv_patch_patch_arg.src_value);
+			bhv_hypercall_vas(BHV_VAS_BACKEND_PATCH,
+					  BHV_VAS_PATCH_OP_PATCH_NO_CLOSE,
+					  bhv_arg);
+		} else {
+			*updptr = cpu_to_le32(aarch64_insn_gen_nop());
+		}
+#else /* !CONFIG_BHV_VAS */
 		*updptr = cpu_to_le32(aarch64_insn_gen_nop());
+#endif /* CONFIG_BHV_VAS */
+	}
 }
 
 /*
  * Patch a NOP in the Spectre-v4 mitigation code with an SMC/HVC instruction
  * to call into firmware to adjust the mitigation state.
  */
+#ifdef CONFIG_BHV_VAS
+void __init spectre_v4_patch_fw_mitigation_conduit(struct alt_instr *alt,
+						   __le32 *origptr,
+						   __le32 *updptr, int nr_inst,
+						   bhv_patch_arg_t *bhv_arg)
+#else /* !CONFIG_BHV_VAS */
 void __init spectre_v4_patch_fw_mitigation_conduit(struct alt_instr *alt,
 						   __le32 *origptr,
 						   __le32 *updptr, int nr_inst)
+#endif /* CONFIG_BHV_VAS */
 {
 	u32 insn;
 
@@ -590,7 +633,23 @@ void __init spectre_v4_patch_fw_mitigation_conduit(struct alt_instr *alt,
 		return;
 	}
 
+#ifdef CONFIG_BHV_VAS
+	if (bhv_integrity_is_enabled()) {
+		insn = cpu_to_le32(insn);
+		bhv_arg->bhv_patch_patch_arg.dest_phys_addr =
+			virt_to_phys((void *)updptr);
+		memcpy(bhv_arg->bhv_patch_patch_arg.src_value, &insn,
+		       sizeof(bhv_arg->bhv_patch_patch_arg.src_value));
+		bhv_arg->bhv_patch_patch_arg.size =
+			sizeof(bhv_arg->bhv_patch_patch_arg.src_value);
+		bhv_hypercall_vas(BHV_VAS_BACKEND_PATCH,
+				  BHV_VAS_PATCH_OP_PATCH_NO_CLOSE, bhv_arg);
+	} else {
+		*updptr = cpu_to_le32(insn);
+	}
+#else /* !CONFIG_BHV_VAS */
 	*updptr = cpu_to_le32(insn);
+#endif /* CONFIG_BHV_VAS */
 }
 
 static enum mitigation_state spectre_v4_enable_fw_mitigation(void)
diff --git arch/arm64/kernel/setup.c arch/arm64/kernel/setup.c
index eb4b24652c10..849c9741fd9e 100644
--- arch/arm64/kernel/setup.c
+++ arch/arm64/kernel/setup.c
@@ -51,6 +51,8 @@
 #include <asm/xen/hypervisor.h>
 #include <asm/mmu_context.h>
 
+#include <bhv/start.h>
+
 static int num_standard_resources;
 static struct resource *standard_resources;
 
@@ -323,6 +325,7 @@ void __init __no_sanitize_address setup_arch(char **cmdline_p)
 	cpu_uninstall_idmap();
 
 	xen_early_init();
+	bhv_init_platform();
 	efi_init();
 
 	if (!efi_enabled(EFI_BOOT) && ((u64)_text % MIN_KIMG_ALIGN) != 0)
diff --git arch/arm64/kernel/vmlinux.lds.S arch/arm64/kernel/vmlinux.lds.S
index 30c102978942..b7a1d8115090 100644
--- arch/arm64/kernel/vmlinux.lds.S
+++ arch/arm64/kernel/vmlinux.lds.S
@@ -135,6 +135,7 @@ SECTIONS
 			IDMAP_TEXT
 			HIBERNATE_TEXT
 			TRAMP_TEXT
+			BHV_TEXT
 			*(.fixup)
 			*(.gnu.warning)
 		. = ALIGN(16);
@@ -250,6 +251,17 @@ SECTIONS
 		__mmuoff_data_end = .;
 	}
 
+#ifdef CONFIG_BHV_VAS
+	. = ALIGN(PAGE_SIZE);
+	.bhv.data : {
+		__bhv_data_start = .;
+		. += PAGE_SIZE;
+		*(.bhv.data)
+		. = ALIGN(PAGE_SIZE);
+		__bhv_data_end = .;
+	}
+#endif
+
 	PECOFF_EDATA_PADDING
 	__pecoff_data_rawsize = ABSOLUTE(. - __initdata_begin);
 	_edata = .;
diff --git arch/arm64/kvm/va_layout.c arch/arm64/kvm/va_layout.c
index e0404bcab019..f7c85c7f4291 100644
--- arch/arm64/kvm/va_layout.c
+++ arch/arm64/kvm/va_layout.c
@@ -12,6 +12,11 @@
 #include <asm/insn.h>
 #include <asm/kvm_mmu.h>
 
+#ifdef CONFIG_BHV_VAS
+#include <bhv/interface/hypercall.h>
+#include <bhv/integrity.h>
+#endif
+
 /*
  * The LSB of the HYP VA tag
  */
@@ -97,8 +102,27 @@ static u32 compute_instruction(int n, u32 rd, u32 rn)
 	return insn;
 }
 
-void __init kvm_update_va_mask(struct alt_instr *alt,
-			       __le32 *origptr, __le32 *updptr, int nr_inst)
+#ifdef CONFIG_BHV_VAS
+inline void kvm_bhv_alt_patch(__le32 *dest, u32 insn, bhv_patch_arg_t *bhv_arg)
+{
+	__le32 le32_insn = cpu_to_le32(insn);
+	bhv_arg->bhv_patch_patch_arg.dest_phys_addr =
+		virt_to_phys((void *)dest);
+	memcpy(bhv_arg->bhv_patch_patch_arg.src_value, &le32_insn,
+	       sizeof(bhv_arg->bhv_patch_patch_arg.src_value));
+	bhv_arg->bhv_patch_patch_arg.size =
+		sizeof(bhv_arg->bhv_patch_patch_arg.src_value);
+	bhv_hypercall_vas(BHV_VAS_BACKEND_PATCH,
+			  BHV_VAS_PATCH_OP_PATCH_NO_CLOSE, bhv_arg);
+}
+
+void __init kvm_update_va_mask(struct alt_instr *alt, __le32 *origptr,
+			       __le32 *updptr, int nr_inst,
+			       bhv_patch_arg_t *bhv_arg)
+#else /* CONFIG_BHV_VAS */
+void __init kvm_update_va_mask(struct alt_instr *alt, __le32 *origptr,
+			       __le32 *updptr, int nr_inst)
+#endif /* CONFIG_BHV_VAS */
 {
 	int i;
 
@@ -116,7 +140,17 @@ void __init kvm_update_va_mask(struct alt_instr *alt,
 		 * address), NOP everything after masking the kernel VA.
 		 */
 		if (has_vhe() || (!tag_val && i > 0)) {
+#ifdef CONFIG_BHV_VAS
+			if (bhv_integrity_is_enabled()) {
+				kvm_bhv_alt_patch(&(updptr[i]),
+						  aarch64_insn_gen_nop(),
+						  bhv_arg);
+			} else {
+				updptr[i] = cpu_to_le32(aarch64_insn_gen_nop());
+			}
+#else /* CONFIG_BHV_VAS */
 			updptr[i] = cpu_to_le32(aarch64_insn_gen_nop());
+#endif /* CONFIG_BHV_VAS */
 			continue;
 		}
 
@@ -127,15 +161,29 @@ void __init kvm_update_va_mask(struct alt_instr *alt,
 		insn = compute_instruction(i, rd, rn);
 		BUG_ON(insn == AARCH64_BREAK_FAULT);
 
+#ifdef CONFIG_BHV_VAS
+		if (bhv_integrity_is_enabled()) {
+			kvm_bhv_alt_patch(&(updptr[i]), insn, bhv_arg);
+		} else {
+			updptr[i] = cpu_to_le32(insn);
+		}
+#else /* !CONFIG_BHV_VAS */
 		updptr[i] = cpu_to_le32(insn);
+#endif /* CONFIG_BHV_VAS */
 	}
 }
 
 void *__kvm_bp_vect_base;
 int __kvm_harden_el2_vector_slot;
 
+#ifdef CONFIG_BHV_VAS
+void kvm_patch_vector_branch(struct alt_instr *alt, __le32 *origptr,
+			     __le32 *updptr, int nr_inst,
+			     bhv_patch_arg_t *bhv_arg)
+#else /* CONFIG_BHV_VAS */
 void kvm_patch_vector_branch(struct alt_instr *alt,
 			     __le32 *origptr, __le32 *updptr, int nr_inst)
+#endif /* CONFIG_BHV_VAS */
 {
 	u64 addr;
 	u32 insn;
@@ -170,7 +218,15 @@ void kvm_patch_vector_branch(struct alt_instr *alt,
 						-16,
 						AARCH64_INSN_VARIANT_64BIT,
 						AARCH64_INSN_LDST_STORE_PAIR_PRE_INDEX);
+#ifdef CONFIG_BHV_VAS
+	if (bhv_integrity_is_enabled()) {
+		kvm_bhv_alt_patch(updptr++, insn, bhv_arg);
+	} else {
+		*updptr++ = cpu_to_le32(insn);
+	}
+#else /* CONFIG_BHV_VAS */
 	*updptr++ = cpu_to_le32(insn);
+#endif /* CONFIG_BHV_VAS */
 
 	/* movz x0, #(addr & 0xffff) */
 	insn = aarch64_insn_gen_movewide(AARCH64_INSN_REG_0,
@@ -178,15 +234,29 @@ void kvm_patch_vector_branch(struct alt_instr *alt,
 					 0,
 					 AARCH64_INSN_VARIANT_64BIT,
 					 AARCH64_INSN_MOVEWIDE_ZERO);
+#ifdef CONFIG_BHV_VAS
+	if (bhv_integrity_is_enabled()) {
+		kvm_bhv_alt_patch(updptr++, insn, bhv_arg);
+	} else {
+		*updptr++ = cpu_to_le32(insn);
+	}
+#else /* CONFIG_BHV_VAS */
 	*updptr++ = cpu_to_le32(insn);
+#endif /* CONFIG_BHV_VAS */
 
 	/* movk x0, #((addr >> 16) & 0xffff), lsl #16 */
-	insn = aarch64_insn_gen_movewide(AARCH64_INSN_REG_0,
-					 (u16)(addr >> 16),
-					 16,
-					 AARCH64_INSN_VARIANT_64BIT,
+	insn = aarch64_insn_gen_movewide(AARCH64_INSN_REG_0, (u16)(addr >> 16),
+					 16, AARCH64_INSN_VARIANT_64BIT,
 					 AARCH64_INSN_MOVEWIDE_KEEP);
+#ifdef CONFIG_BHV_VAS
+	if (bhv_integrity_is_enabled()) {
+		kvm_bhv_alt_patch(updptr++, insn, bhv_arg);
+	} else {
+		*updptr++ = cpu_to_le32(insn);
+	}
+#else /* CONFIG_BHV_VAS */
 	*updptr++ = cpu_to_le32(insn);
+#endif /* CONFIG_BHV_VAS */
 
 	/* movk x0, #((addr >> 32) & 0xffff), lsl #32 */
 	insn = aarch64_insn_gen_movewide(AARCH64_INSN_REG_0,
@@ -194,10 +264,26 @@ void kvm_patch_vector_branch(struct alt_instr *alt,
 					 32,
 					 AARCH64_INSN_VARIANT_64BIT,
 					 AARCH64_INSN_MOVEWIDE_KEEP);
+#ifdef CONFIG_BHV_VAS
+	if (bhv_integrity_is_enabled()) {
+		kvm_bhv_alt_patch(updptr++, insn, bhv_arg);
+	} else {
+		*updptr++ = cpu_to_le32(insn);
+	}
+#else /* CONFIG_BHV_VAS */
 	*updptr++ = cpu_to_le32(insn);
+#endif /* CONFIG_BHV_VAS */
 
 	/* br x0 */
 	insn = aarch64_insn_gen_branch_reg(AARCH64_INSN_REG_0,
 					   AARCH64_INSN_BRANCH_NOLINK);
+#ifdef CONFIG_BHV_VAS
+	if (bhv_integrity_is_enabled()) {
+		kvm_bhv_alt_patch(updptr++, insn, bhv_arg);
+	} else {
+		*updptr++ = cpu_to_le32(insn);
+	}
+#else /* CONFIG_BHV_VAS */
 	*updptr++ = cpu_to_le32(insn);
+#endif /* CONFIG_BHV_VAS */
 }
diff --git arch/arm64/mm/init.c arch/arm64/mm/init.c
index c0a7f0d90b39..ced3f3d0bc93 100644
--- arch/arm64/mm/init.c
+++ arch/arm64/mm/init.c
@@ -43,6 +43,9 @@
 #include <asm/tlb.h>
 #include <asm/alternative.h>
 
+#include <bhv/bhv.h>
+#include <bhv/start.h>
+
 /*
  * We need to be able to catch inadvertent references to memstart_addr
  * that occur (potentially in generic code) before arm64_memblock_init()
@@ -564,6 +567,7 @@ void __init mem_init(void)
 
 void free_initmem(void)
 {
+	bhv_start();
 	free_reserved_area(lm_alias(__init_begin),
 			   lm_alias(__init_end),
 			   POISON_FREE_INITMEM, "unused kernel");
diff --git arch/x86/Kbuild arch/x86/Kbuild
index 30dec019756b..3235bbc86ff8 100644
--- arch/x86/Kbuild
+++ arch/x86/Kbuild
@@ -13,6 +13,9 @@ obj-$(CONFIG_PVH) += platform/pvh/
 # Hyper-V paravirtualization support
 obj-$(subst m,y,$(CONFIG_HYPERV)) += hyperv/
 
+# BHV VAS support
+obj-$(CONFIG_BHV_VAS)	+= bhv/
+
 obj-y += realmode/
 obj-y += kernel/
 obj-y += mm/
diff --git arch/x86/Kconfig arch/x86/Kconfig
index c3d9f56c9018..325e58f61ae8 100644
--- arch/x86/Kconfig
+++ arch/x86/Kconfig
@@ -864,6 +864,16 @@ config ACRN_GUEST
 	  IOT with small footprint and real-time features. More details can be
 	  found in https://projectacrn.org/.
 
+config BHV_VAS
+	def_bool y
+	bool "BVH guest support on x86_64"
+	depends on X86_64
+	help
+	  Say Y if you want to run Linux in a Virtual Machine on BHV on x86_64
+	  and benefit from Virtualization-assisted Security.
+
+source "kernel/bhv/Kconfig"
+
 endif #HYPERVISOR_GUEST
 
 source "arch/x86/Kconfig.cpu"
diff --git arch/x86/bhv/Makefile arch/x86/bhv/Makefile
new file mode 100644
index 000000000000..e66e83fdb5eb
--- /dev/null
+++ arch/x86/bhv/Makefile
@@ -0,0 +1,14 @@
+# SPDX-License-Identifier: GPL-2.0-only
+
+# Copyright (C) 2022 - BedRock Systems Inc
+# Authors: Sergej Proskurin <sergej@bedrocksystems.com>
+#          Jonas Pfoh <jonas@bedrocksystems.com>
+#          Sebastian Vogl <sebastian@bedrocksystems.com>
+
+obj-$(CONFIG_BHV_VAS)		:= start.o
+obj-$(CONFIG_BHV_VAS)		+= init.o
+obj-$(CONFIG_BHV_VAS)		+= integrity.o
+ifeq ($(CONFIG_JUMP_LABEL),y)
+obj-$(CONFIG_BHV_VAS)		+= patch_jump_label.o
+endif
+obj-$(CONFIG_BHV_VAS)		+= patch_alternative.o
diff --git arch/x86/bhv/init.c arch/x86/bhv/init.c
new file mode 100644
index 000000000000..1833c1b75e6d
--- /dev/null
+++ arch/x86/bhv/init.c
@@ -0,0 +1,102 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Author: Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#include <bhv/interface/common.h>
+#include <bhv/interface/integrity.h>
+#include <bhv/init.h>
+
+#include <asm/io.h>
+#include <asm/sections.h>
+#include <asm/vdso.h>
+
+static __always_inline void
+bhv_init_add_vdso_image_64(bhv_mem_region_t *init_phys_mem_regions,
+			   unsigned int *region_counter)
+{
+#ifdef CONFIG_X86_64
+	BUG_ON((*region_counter) >= BHV_INIT_MAX_REGIONS);
+
+	if ((*region_counter) > 0)
+		init_phys_mem_regions[(*region_counter) - 1]
+			.bhv_mem_region_create.next = virt_to_phys(
+			&(init_phys_mem_regions[(*region_counter)]));
+
+	init_phys_mem_regions[(*region_counter)]
+		.bhv_mem_region_create.start_addr =
+		virt_to_phys(vdso_image_64.data);
+	init_phys_mem_regions[(*region_counter)].bhv_mem_region_create.size =
+		vdso_image_64.size;
+	init_phys_mem_regions[(*region_counter)].bhv_mem_region_create.type =
+		BHV_MEM_TYPE_CODE_PATCHABLE;
+	init_phys_mem_regions[(*region_counter)].bhv_mem_region_create.flags =
+		BHV_MEM_FLAGS_TRANSIENT;
+	init_phys_mem_regions[(*region_counter)].bhv_mem_region_create.next =
+		BHV_INVALID_PHYS_ADDR;
+	(*region_counter)++;
+#endif /* CONFIG_X86_64 */
+}
+
+static __always_inline void
+bhv_init_add_vdso_image_x32(bhv_mem_region_t *init_phys_mem_regions,
+			    unsigned int *region_counter)
+{
+#ifdef CONFIG_X86_X32_ABI
+	BUG_ON((*region_counter) >= BHV_INIT_MAX_REGIONS);
+
+	if ((*region_counter) > 0)
+		init_phys_mem_regions[(*region_counter) - 1]
+			.bhv_mem_region_create.next = virt_to_phys(
+			&(init_phys_mem_regions[(*region_counter)]));
+
+	init_phys_mem_regions[(*region_counter)]
+		.bhv_mem_region_create.start_addr =
+		virt_to_phys(vdso_image_x32.data);
+	init_phys_mem_regions[(*region_counter)].bhv_mem_region_create.size =
+		vdso_image_x32.size;
+	init_phys_mem_regions[(*region_counter)].bhv_mem_region_create.type =
+		BHV_MEM_TYPE_CODE_PATCHABLE;
+	init_phys_mem_regions[(*region_counter)].bhv_mem_region_create.flags =
+		BHV_MEM_FLAGS_TRANSIENT;
+	init_phys_mem_regions[(*region_counter)].bhv_mem_region_create.next =
+		BHV_INVALID_PHYS_ADDR;
+	(*region_counter)++;
+#endif /* CONFIG_X86_X32_ABI */
+}
+
+static __always_inline void
+bhv_init_add_vdso_image_32(bhv_mem_region_t *init_phys_mem_regions,
+			   unsigned int *region_counter)
+{
+#if defined CONFIG_X86_32 || (defined CONFIG_X86_64 && defined CONFIG_COMPAT)
+	BUG_ON((*region_counter) >= BHV_INIT_MAX_REGIONS);
+
+	if ((*region_counter) > 0)
+		init_phys_mem_regions[(*region_counter) - 1]
+			.bhv_mem_region_create.next = virt_to_phys(
+			&(init_phys_mem_regions[(*region_counter)]));
+
+	init_phys_mem_regions[(*region_counter)]
+		.bhv_mem_region_create.start_addr =
+		virt_to_phys(vdso_image_32.data);
+	init_phys_mem_regions[(*region_counter)].bhv_mem_region_create.size =
+		vdso_image_32.size;
+	init_phys_mem_regions[(*region_counter)].bhv_mem_region_create.type =
+		BHV_MEM_TYPE_CODE_PATCHABLE;
+	init_phys_mem_regions[(*region_counter)].bhv_mem_region_create.flags =
+		BHV_MEM_FLAGS_TRANSIENT;
+	init_phys_mem_regions[(*region_counter)].bhv_mem_region_create.next =
+		BHV_INVALID_PHYS_ADDR;
+	(*region_counter)++;
+#endif /* defined CONFIG_X86_32 || (defined CONFIG_X86_64 && defined CONFIG_COMPAT) */
+}
+
+void __init bhv_init_hyp_arch(bhv_mem_region_t *init_phys_mem_regions,
+			      unsigned int *region_counter)
+{
+	bhv_init_add_vdso_image_64(init_phys_mem_regions, region_counter);
+	bhv_init_add_vdso_image_x32(init_phys_mem_regions, region_counter);
+	bhv_init_add_vdso_image_32(init_phys_mem_regions, region_counter);
+}
diff --git arch/x86/bhv/integrity.c arch/x86/bhv/integrity.c
new file mode 100644
index 000000000000..c3a87ea2a774
--- /dev/null
+++ arch/x86/bhv/integrity.c
@@ -0,0 +1,297 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ *          Sergej Proskurin <sergej@bedrocksystems.com>
+ */
+
+#include <asm/io.h>
+#include <asm/syscall.h>
+#include <asm/vdso.h>
+#include <asm-generic/sections.h>
+
+#include <asm/bhv/integrity.h>
+#include <bhv/interface/common.h>
+#include <bhv/integrity.h>
+#include <bhv/bhv.h>
+
+struct {
+	bool valid;
+	uint64_t addr;
+	uint64_t size;
+} typedef table_data_t;
+
+static table_data_t table_data __ro_after_init;
+
+static int bhv_alloc_node_idt_region(struct list_head *head)
+{
+	uint64_t addr = virt_to_phys((void *)table_data.addr);
+	uint64_t size = table_data.size;
+
+	return bhv_link_node_op_create(head, addr, size,
+				       BHV_MEM_TYPE_DATA_READ_ONLY,
+				       BHV_MEM_FLAGS_NONE);
+}
+
+static int bhv_start_integrity_add_idt(void)
+{
+	int rc = 0;
+	bhv_mem_region_node_t *n = NULL;
+
+	LIST_HEAD(head);
+
+	// NOTE: the x86 system call table does not need explict protection
+	//       it is contained in the ro_data section.
+
+	if (!table_data.valid)
+		return 0;
+
+	rc = bhv_alloc_node_idt_region(&head);
+	if (rc)
+		goto out;
+
+	n = list_first_entry_or_null(&head, bhv_mem_region_node_t, list);
+	if (n == NULL) {
+		rc = -ENOENT;
+		goto out;
+	}
+
+	rc = bhv_create_kern_phys_mem_region_hyp(0, &n->region);
+	if (rc) {
+		bhv_fail("BHV: Cannot create phys mem regions");
+		goto out;
+	}
+
+out:
+	bhv_release_arg_list(&head);
+	return rc;
+}
+
+static inline int rm_vdso_image_64(struct list_head *head)
+{
+#ifdef CONFIG_X86_64
+	return bhv_link_node_op_remove(head, virt_to_phys(vdso_image_64.data));
+#else
+	return 0;
+#endif
+}
+
+static inline int rm_vdso_image_x32(struct list_head *head)
+{
+#ifdef CONFIG_X86_X32_ABI
+	return bhv_link_node_op_remove(head, virt_to_phys(vdso_image_x32.data));
+#else
+	return 0;
+#endif
+}
+
+static inline int rm_vdso_image_32(struct list_head *head)
+{
+#if defined CONFIG_X86_32 || (defined CONFIG_X86_64 && defined CONFIG_COMPAT)
+	return bhv_link_node_op_remove(head, virt_to_phys(vdso_image_32.data));
+#else
+	return 0;
+#endif
+}
+
+static int bhv_start_integrity_rm_vdso(void)
+{
+	int rc = 0;
+	bhv_mem_region_node_t *n = NULL;
+
+	LIST_HEAD(head);
+
+	rc = rm_vdso_image_64(&head);
+	if (rc)
+		goto out;
+
+	rc = rm_vdso_image_x32(&head);
+	if (rc)
+		goto out;
+
+	rc = rm_vdso_image_32(&head);
+	if (rc)
+		goto out;
+
+	n = list_first_entry_or_null(&head, bhv_mem_region_node_t, list);
+	BUG_ON(n == NULL);
+
+	rc = bhv_remove_kern_phys_mem_region_by_region_hyp(&n->region);
+	if (rc) {
+		bhv_fail("BHV: Cannot remove phys mem regions");
+		goto out;
+	}
+
+out:
+	bhv_release_arg_list(&head);
+	return rc;
+}
+
+static void bhv_start_integrity_add_vdso_bump(unsigned int i, uint64_t addr,
+					      uint64_t *range, size_t range_sz)
+{
+	unsigned int j;
+	uint64_t tmp1, tmp2;
+	BUG_ON(i >= range_sz);
+	tmp1 = addr;
+	for (j = i; j < range_sz; j++) {
+		if (tmp1 == 0)
+			return;
+		BUG_ON(range[j] != 0 && tmp1 > range[j]);
+		tmp2 = range[j];
+		range[j] = tmp1;
+		tmp1 = tmp2;
+	}
+	BUG_ON(tmp1 != 0);
+}
+
+static void bhv_start_integrity_add_vdso_common(uint64_t start, uint64_t end,
+						uint64_t *range,
+						size_t range_sz)
+{
+	unsigned int i;
+	BUG_ON(start == end);
+	BUG_ON(range_sz == 0);
+	BUG_ON(start < range[0]);
+
+	for (i = 1; i < range_sz - 1; i++) {
+		BUG_ON(range[i] == 0);
+		if (start < range[i]) {
+			bhv_start_integrity_add_vdso_bump(i, start, range,
+							  range_sz);
+			bhv_start_integrity_add_vdso_bump(i + 1, end, range,
+							  range_sz);
+			return;
+		}
+	}
+	BUG();
+}
+
+static __always_inline void
+bhv_start_integrity_add_vdso_image_64_to_range(uint64_t *range, size_t range_sz)
+{
+#ifdef CONFIG_X86_64
+	uint64_t start = virt_to_phys(vdso_image_64.data);
+	uint64_t end = start + vdso_image_64.size;
+	bhv_start_integrity_add_vdso_common(start, end, range, range_sz);
+#endif /* CONFIG_X86_64 */
+}
+
+static __always_inline void
+bhv_start_integrity_add_vdso_image_x32_to_range(uint64_t *range,
+						size_t range_sz)
+{
+#ifdef CONFIG_X86_X32_ABI
+	uint64_t start = virt_to_phys(vdso_image_x32.data);
+	uint64_t end = start + vdso_image_x32.size;
+	bhv_start_integrity_add_vdso_common(start, end, range, range_sz);
+#endif /* CONFIG_X86_X32_ABI */
+}
+
+static __always_inline void
+bhv_start_integrity_add_vdso_image_32_to_range(uint64_t *range, size_t range_sz)
+{
+#if defined CONFIG_X86_32 || (defined CONFIG_X86_64 && defined CONFIG_COMPAT)
+	uint64_t start = virt_to_phys(vdso_image_32.data);
+	uint64_t end = start + vdso_image_32.size;
+	bhv_start_integrity_add_vdso_common(start, end, range, range_sz);
+#endif /* defined CONFIG_X86_32 || (defined CONFIG_X86_64 && defined CONFIG_COMPAT) */
+}
+
+static void bhv_start_integrity_get_ro_ranges(uint64_t *range, size_t range_sz)
+{
+	BUG_ON(range_sz < 2);
+	range[0] = virt_to_phys((void *)__start_rodata);
+	range[1] = virt_to_phys((void *)__end_rodata);
+
+	bhv_start_integrity_add_vdso_image_64_to_range(range, range_sz);
+	bhv_start_integrity_add_vdso_image_x32_to_range(range, range_sz);
+	bhv_start_integrity_add_vdso_image_32_to_range(range, range_sz);
+}
+
+int bhv_start_integrity_add_ro(void)
+{
+#define BHV_MAX_RO_RANGES 8
+#define BHV_NUM_MEM_REGION_NODES (BHV_MAX_RO_RANGES / 2)
+	unsigned int i, j;
+	uint64_t start, size;
+	bhv_mem_region_node_t *prev = NULL;
+	int rc = 0;
+	uint64_t ro_ranges[BHV_MAX_RO_RANGES] = { 0 };
+	bhv_mem_region_node_t *n[BHV_NUM_MEM_REGION_NODES];
+
+	bhv_start_integrity_get_ro_ranges(ro_ranges, BHV_MAX_RO_RANGES);
+
+	rc = kmem_cache_alloc_bulk(bhv_mem_region_cache, GFP_KERNEL,
+				   BHV_NUM_MEM_REGION_NODES, (void **)&n);
+	if (!rc) {
+		bhv_fail("BHV: failed to allocate mem region");
+		return -ENOMEM;
+	}
+
+	for (i = 0; i < BHV_NUM_MEM_REGION_NODES; i++) {
+		j = i * 2;
+		start = ro_ranges[j];
+		size = ro_ranges[j + 1] - start;
+
+		if (start == 0)
+			break;
+
+		if (size == 0)
+			continue;
+
+		n[i]->region.bhv_mem_region_create.start_addr = start;
+		n[i]->region.bhv_mem_region_create.size = size;
+		n[i]->region.bhv_mem_region_create.type =
+			BHV_MEM_TYPE_DATA_READ_ONLY;
+		n[i]->region.bhv_mem_region_create.flags = BHV_MEM_FLAGS_NONE;
+		n[i]->region.bhv_mem_region_create.next = BHV_INVALID_PHYS_ADDR;
+
+		if (prev != NULL) {
+			prev->region.bhv_mem_region_create.next =
+				virt_to_phys(&(n[i]->region));
+		}
+
+		prev = n[i];
+	}
+
+	rc = bhv_create_kern_phys_mem_region_hyp(0, &(n[0]->region));
+	if (rc) {
+		pr_err("BHV: create phys mem region failed: %d", rc);
+	}
+
+	kmem_cache_free_bulk(bhv_mem_region_cache, BHV_NUM_MEM_REGION_NODES,
+			     (void **)&n);
+
+	return rc;
+}
+
+int bhv_start_integrity_arch(void)
+{
+	int rc;
+
+	if (!bhv_integrity_is_enabled())
+		return 0;
+
+	rc = bhv_start_integrity_add_idt();
+	if (rc)
+		return rc;
+
+	rc = bhv_start_integrity_rm_vdso();
+	if (rc)
+		return rc;
+
+	return bhv_start_integrity_add_ro();
+}
+
+void __init bhv_register_idt(uint64_t addr, int numpages)
+{
+	table_data.addr = addr;
+	table_data.size = numpages * PAGE_SIZE;
+	table_data.valid = true;
+}
+
+void __init bhv_integrity_arch_init(void)
+{
+	memset(&table_data, 0, sizeof(table_data));
+}
diff --git arch/x86/bhv/patch_alternative.c arch/x86/bhv/patch_alternative.c
new file mode 100644
index 000000000000..dec45eaf6533
--- /dev/null
+++ arch/x86/bhv/patch_alternative.c
@@ -0,0 +1,381 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Sebastian Vogl <sebastian@bedrocksystems.com>
+ *          Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#include <bhv/bhv.h>
+#include <bhv/vault.h>
+
+#include <bhv/patch.h>
+#include <bhv/interface/patch.h>
+#include <asm/bhv/patch.h>
+
+#include <asm/sections.h>
+
+void bhv_alternatives_add_module_arch(struct alt_instr *begin,
+				      struct alt_instr *end,
+				      const s32 *locks_begin,
+				      const s32 *locks_end, u8 *text_begin,
+				      u8 *text_end)
+{
+	struct bhv_alternatives_mod_arch arch = { .locks_begin = locks_begin,
+						  .locks_end = locks_end,
+						  .text_begin = text_begin,
+						  .text_end = text_end };
+	bhv_alternatives_add_module(begin, end, &arch);
+}
+
+static void __bhv_text bhv_add_nops(void *insns, unsigned int len,
+				    bhv_patch_arg_t *bhv_arg, bool patch)
+{
+	size_t total_length = 0;
+
+	while (len > 0) {
+		unsigned int noplen = len;
+		if (noplen > ASM_NOP_MAX)
+			noplen = ASM_NOP_MAX;
+
+		if (patch &&
+		    total_length >=
+			    sizeof(bhv_arg->bhv_patch_patch_arg.src_value))
+			panic("Size for NOP patch exceeded!");
+
+		if (patch) {
+			memcpy(bhv_arg->bhv_patch_patch_arg.src_value +
+				       total_length,
+			       ideal_nops[noplen], noplen);
+			total_length += noplen;
+		} else {
+			memcpy(insns, ideal_nops[noplen], noplen);
+			insns += noplen;
+		}
+
+		len -= noplen;
+	}
+
+	if (patch) {
+		bhv_arg->bhv_patch_patch_arg.dest_phys_addr =
+			virt_to_phys(insns);
+		bhv_arg->bhv_patch_patch_arg.size = total_length;
+
+		bhv_hypercall_vas(BHV_VAS_BACKEND_PATCH,
+				  BHV_VAS_PATCH_OP_PATCH_NO_CLOSE, bhv_arg);
+	}
+}
+
+static bool __bhv_text bhv_optimize_nops(struct alt_instr *a, u8 *instr,
+					 bhv_patch_arg_t *bhv_arg, bool patch)
+{
+	int i;
+
+	for (i = 0; i < a->padlen; i++) {
+		if (instr[i] != 0x90) {
+			return false;
+		}
+	}
+
+	bhv_add_nops(instr + (a->instrlen - a->padlen), a->padlen, bhv_arg,
+		     patch);
+	return true;
+}
+
+static void __bhv_text bhv_recompute_jump(struct alt_instr *a, u8 *orig_insn,
+					  u8 *repl_insn, u8 *insn_buff)
+{
+	u8 *next_rip, *tgt_rip;
+	s32 n_dspl, o_dspl;
+	int repl_len;
+
+	if (a->replacementlen != 5)
+		return;
+
+	o_dspl = *(s32 *)(insn_buff + 1);
+
+	/* next_rip of the replacement JMP */
+	next_rip = repl_insn + a->replacementlen;
+	/* target rip of the replacement JMP */
+	tgt_rip = next_rip + o_dspl;
+	n_dspl = tgt_rip - orig_insn;
+
+	if (tgt_rip - orig_insn >= 0) {
+		if (n_dspl - 2 <= 127)
+			goto two_byte_jmp;
+		else
+			goto five_byte_jmp;
+		/* negative offset */
+	} else {
+		if (((n_dspl - 2) & 0xff) == (n_dspl - 2))
+			goto two_byte_jmp;
+		else
+			goto five_byte_jmp;
+	}
+
+two_byte_jmp:
+	n_dspl -= 2;
+
+	insn_buff[0] = 0xeb;
+	insn_buff[1] = (s8)n_dspl;
+	bhv_add_nops(insn_buff + 2, 3, NULL, false);
+
+	repl_len = 2;
+	goto done;
+
+five_byte_jmp:
+	n_dspl -= 5;
+
+	insn_buff[0] = 0xe9;
+	*(s32 *)&insn_buff[1] = n_dspl;
+
+	repl_len = 5;
+
+done:
+	return;
+}
+
+static int __bhv_text bhv_alternatives_smp_lock_unlock_apply_vault(
+	u8 *target, bool lock, bhv_patch_arg_t *bhv_arg)
+{
+	static const u8 unlock_opcode = 0x3e;
+	static const u8 lock_opcode = 0xf0;
+
+	unsigned long r = 0;
+	u8 opcode;
+
+	// Check opcode
+	if (lock) {
+		if (*target != unlock_opcode)
+			return -EACCES;
+
+		opcode = lock_opcode;
+	} else {
+		if (*target != lock_opcode)
+			return -EACCES;
+
+		opcode = unlock_opcode;
+	}
+
+	bhv_arg->bhv_patch_patch_arg.dest_phys_addr =
+		virt_to_phys((void *)target);
+	memcpy(bhv_arg->bhv_patch_patch_arg.src_value, &opcode, 1);
+	bhv_arg->bhv_patch_patch_arg.size = 1;
+
+	r = bhv_hypercall_vas(BHV_VAS_BACKEND_PATCH,
+			      BHV_VAS_PATCH_OP_PATCH_NO_CLOSE, bhv_arg);
+	if (r) {
+		panic("BHV vault close failure! hypercall returned %lu", r);
+	}
+	return 0;
+}
+
+static int __bhv_text bhv_alternatives_smp_lock_unlock_vault(
+	struct bhv_alternatives_mod *mod, bool lock, bhv_patch_arg_t *bhv_arg)
+{
+	const s32 *poff;
+
+	for (poff = mod->arch.locks_begin; poff < mod->arch.locks_end; poff++) {
+		u8 *ptr = (u8 *)poff + *poff;
+
+		if (!*poff || ptr < mod->arch.text_begin ||
+		    ptr >= mod->arch.text_end)
+			continue;
+
+		bhv_alternatives_smp_lock_unlock_apply_vault(ptr, lock,
+							     bhv_arg);
+	}
+
+	return 0;
+}
+
+static int __bhv_text bhv_alternatives_patch_vault(struct alt_instr *a,
+						   bhv_patch_arg_t *bhv_arg)
+{
+	u8 *instr, *replacement;
+	u8 insn_buff[254];
+	int insn_buff_sz = 0;
+
+	instr = (u8 *)&a->instr_offset + a->instr_offset;
+	replacement = (u8 *)&a->repl_offset + a->repl_offset;
+
+	if (a->instrlen > sizeof(insn_buff)) {
+		return -EACCES;
+	}
+
+	if (a->cpuid >= (NCAPINTS + NBUGINTS) * 32) {
+		return -EACCES;
+	}
+
+	if (!boot_cpu_has(a->cpuid)) {
+		if (a->padlen > 1) {
+			bhv_optimize_nops(a, instr, bhv_arg, true);
+		}
+
+		return 0;
+	}
+
+	memcpy(insn_buff, replacement, a->replacementlen);
+	insn_buff_sz = a->replacementlen;
+
+	/*
+		* 0xe8 is a relative jump; fix the offset.
+		*
+		* Instruction length is checked before the opcode to avoid
+		* accessing uninitialized bytes for zero-length replacements.
+		*/
+	if (a->replacementlen == 5 && *insn_buff == 0xe8)
+		*(s32 *)(insn_buff + 1) += replacement - instr;
+
+	if (a->replacementlen &&
+	    (replacement[0] == 0xeb || replacement[0] == 0xe9))
+		bhv_recompute_jump(a, instr, replacement, insn_buff);
+
+	if (a->instrlen > a->replacementlen) {
+		bhv_add_nops(insn_buff + a->replacementlen,
+			     a->instrlen - a->replacementlen, NULL, false);
+		insn_buff_sz += a->instrlen - a->replacementlen;
+	}
+
+	if (insn_buff_sz >= sizeof(bhv_arg->bhv_patch_patch_arg.src_value))
+		panic("Instruction buffer size too small!");
+
+	bhv_arg->bhv_patch_patch_arg.dest_phys_addr =
+		virt_to_phys((void *)instr);
+	memcpy(bhv_arg->bhv_patch_patch_arg.src_value, &insn_buff,
+	       insn_buff_sz);
+	bhv_arg->bhv_patch_patch_arg.size = insn_buff_sz;
+
+	return bhv_hypercall_vas(BHV_VAS_BACKEND_PATCH,
+				 BHV_VAS_PATCH_OP_PATCH_NO_CLOSE, bhv_arg);
+}
+
+int __bhv_text bhv_alternatives_apply_vault_arch(
+	struct bhv_alternatives_mod *mod, void *arch, bhv_patch_arg_t *bhv_arg)
+{
+	struct alt_instr *a;
+	int rv = 0;
+	bool *smp = arch;
+
+	// SMP?
+	if (smp != NULL) {
+		bhv_alternatives_smp_lock_unlock_vault(mod, *smp, bhv_arg);
+	}
+
+	for (a = mod->begin; a < mod->end; a++) {
+		if (rv == 0)
+			rv = bhv_alternatives_patch_vault(a, bhv_arg);
+		else
+			bhv_alternatives_patch_vault(a, bhv_arg);
+	}
+
+	return rv;
+}
+
+bool __bhv_text bhv_alternatives_find_by_lock(void *search_param,
+					      struct bhv_alternatives_mod *cur)
+{
+	struct bhv_alternatives_lock_search_param *param = search_param;
+
+	if (cur->arch.locks_begin == param->locks_begin &&
+	    cur->arch.locks_end == param->locks_end) {
+		return true;
+	}
+
+	return false;
+}
+
+extern struct alt_instr __alt_instructions[], __alt_instructions_end[];
+extern s32 __smp_locks[], __smp_locks_end[];
+struct bhv_alternatives_mod *__bhv_text
+bhv_alternatives_get_static_mods_vault(uint32_t *nr_mods)
+{
+#if defined(CONFIG_X86_64) && defined(CONFIG_X86_X32_ABI) &&                   \
+	defined(CONFIG_COMPAT)
+#define MOD_NR 4 // kernel + 3 VDSO
+#endif
+#if defined(CONFIG_X86_64) && !defined(CONFIG_X86_X32_ABI) &&                  \
+	defined(CONFIG_COMPAT)
+#define MOD_NR 3 // kernel + 2 VDSO
+#endif
+#if defined(CONFIG_X86_64) && !defined(CONFIG_X86_X32_ABI) &&                  \
+	!defined(CONFIG_COMPAT)
+#define MOD_NR 2 // kernel + 1 VDSO
+#endif
+#if defined(CONFIG_X86_32) && defined(CONFIG_X86_X32_ABI)
+#define MOD_NR 3 // kernel + 2 VDSO
+#endif
+#if defined(CONFIG_X86_32) && !defined(CONFIG_X86_X32_ABI)
+#define MOD_NR 2 // kernel + 1 VDSO
+#endif
+#if defined(CONFIG_X86_X32_ABI) && !defined(CONFIG_X86_32) &&                  \
+	!defined(CONFIG_COMPAT)
+#define MOD_NR 2 // kernel + 1 VDSO
+#endif
+	static struct bhv_alternatives_mod static_mods[MOD_NR];
+	uint32_t counter = 0;
+
+	// Init kernel.
+	static_mods[counter].begin = __alt_instructions;
+	static_mods[counter].end = __alt_instructions_end;
+	static_mods[counter].delete_policy = BHV_ALTERNATIVES_DELETE_AFTER_INIT;
+	static_mods[counter].allocated = false;
+	static_mods[counter].arch.locks_begin = __smp_locks;
+	static_mods[counter].arch.locks_end = __smp_locks_end;
+	static_mods[counter].arch.text_begin = _text;
+	static_mods[counter].arch.text_end = _etext;
+	static_mods[counter].next.next = NULL;
+	static_mods[counter].next.prev = NULL;
+#if defined(CONFIG_X86_64)
+	// Init x64 VDSO
+	counter++;
+	static_mods[counter].begin =
+		(void *)(vdso_image_64.data + vdso_image_64.alt);
+	static_mods[counter].end =
+		(void *)(vdso_image_64.data + vdso_image_64.alt +
+			 vdso_image_64.alt_len);
+	static_mods[counter].delete_policy = BHV_ALTERNATIVES_DELETE_AFTER_INIT;
+	static_mods[counter].allocated = false;
+	static_mods[counter].arch.locks_begin = NULL;
+	static_mods[counter].arch.locks_end = NULL;
+	static_mods[counter].arch.text_begin = NULL;
+	static_mods[counter].arch.text_end = NULL;
+	static_mods[counter].next.next = NULL;
+	static_mods[counter].next.prev = NULL;
+#endif
+#if defined(CONFIG_X86_32) || defined(CONFIG_COMPAT)
+	// Init x64 VDSO
+	counter++;
+	static_mods[counter].begin =
+		(void *)(vdso_image_32.data + vdso_image_32.alt);
+	static_mods[counter].end =
+		(void *)(vdso_image_32.data + vdso_image_32.alt +
+			 vdso_image_32.alt_len);
+	static_mods[counter].delete_policy = BHV_ALTERNATIVES_DELETE_AFTER_INIT;
+	static_mods[counter].allocated = false;
+	static_mods[counter].arch.locks_begin = NULL;
+	static_mods[counter].arch.locks_end = NULL;
+	static_mods[counter].arch.text_begin = NULL;
+	static_mods[counter].arch.text_end = NULL;
+	static_mods[counter].next.next = NULL;
+	static_mods[counter].next.prev = NULL;
+#endif
+#if defined(CONFIG_X86_X32_ABI)
+	// Init x64 VDSO
+	counter++;
+	static_mods[counter].begin =
+		(void *)(vdso_image_x32.data + vdso_image_x32.alt);
+	static_mods[counter].end =
+		(void *)(vdso_image_x32.data + vdso_image_x32.alt +
+			 vdso_image_x32.alt_len);
+	static_mods[counter].delete_policy = BHV_ALTERNATIVES_DELETE_AFTER_INIT;
+	static_mods[counter].allocated = false;
+	static_mods[counter].arch.locks_begin = NULL;
+	static_mods[counter].arch.locks_end = NULL;
+	static_mods[counter].arch.text_begin = NULL;
+	static_mods[counter].arch.text_end = NULL;
+	static_mods[counter].next.next = NULL;
+	static_mods[counter].next.prev = NULL;
+#endif
+	*nr_mods = MOD_NR;
+	return &static_mods[0];
+}
\ No newline at end of file
diff --git arch/x86/bhv/patch_jump_label.c arch/x86/bhv/patch_jump_label.c
new file mode 100644
index 000000000000..47cc0b8809b9
--- /dev/null
+++ arch/x86/bhv/patch_jump_label.c
@@ -0,0 +1,45 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#include <asm/bhv/integrity.h>
+
+#include <asm-generic/bug.h>
+#include <linux/jump_label.h>
+#include <asm/text-patching.h>
+#include <linux/string.h>
+
+bool __bhv_text bhv_jump_label_validate_opcode(struct jump_entry *entry,
+					       enum jump_label_type type,
+					       const void *expected_opcode,
+					       size_t len)
+{
+	const unsigned char default_nop[] = { STATIC_KEY_INIT_NOP };
+	const unsigned char *ideal_nop = ideal_nops[NOP_ATOMIC5];
+	const void *code;
+	const void *addr, *dest;
+
+	if (len != JUMP_LABEL_NOP_SIZE)
+		return false;
+
+	addr = (void *)jump_entry_code(entry);
+	dest = (void *)jump_entry_target(entry);
+
+	code = text_gen_insn(JMP32_INSN_OPCODE, addr, dest);
+
+	if (type != JUMP_LABEL_JMP) {
+		if (memcmp(addr, code, len))
+			return false;
+		if (memcmp(expected_opcode, ideal_nop, len))
+			return false;
+	} else {
+		if (memcmp(addr, ideal_nop, len) &&
+		    memcmp(addr, default_nop, len))
+			return false;
+		if (memcmp(expected_opcode, code, len))
+			return false;
+	}
+	return true;
+}
diff --git arch/x86/bhv/start.c arch/x86/bhv/start.c
new file mode 100644
index 000000000000..d038b5a2d97e
--- /dev/null
+++ arch/x86/bhv/start.c
@@ -0,0 +1,44 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#include <asm/hypervisor.h>
+#include <asm/processor.h>
+#include <asm/x86_init.h>
+
+#include <asm/bhv/integrity.h>
+#include <bhv/integrity.h>
+#include <bhv/start.h>
+
+static uint32_t __init bhv_detect(void)
+{
+	if (boot_cpu_data.cpuid_level < 0)
+		return 0;	/* So we don't blow up on old processors */
+
+	if (boot_cpu_has(X86_FEATURE_HYPERVISOR))
+		return hypervisor_cpuid_base("BHV.VMM.VAS.", 0);
+
+	return 0;
+}
+
+static void __init bhv_init_platform_x86(void)
+{
+	bhv_integrity_arch_init();
+	bhv_init_platform();
+}
+
+const __initconst struct hypervisor_x86 x86_hyper_bhv = {
+	.name = "BHV BRASS",
+	.detect = bhv_detect,
+	.type = X86_HYPER_BHV,
+	.init.guest_late_init = x86_init_noop,
+	.init.x2apic_available = bool_x86_init_noop,
+	.init.init_platform = bhv_init_platform_x86
+};
+
+int bhv_start_arch(void)
+{
+	return bhv_start_integrity_arch();
+}
diff --git arch/x86/include/asm/bhv/hypercall.h arch/x86/include/asm/bhv/hypercall.h
new file mode 100644
index 000000000000..5140906c8697
--- /dev/null
+++ arch/x86/include/asm/bhv/hypercall.h
@@ -0,0 +1,26 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#ifndef __ASM_BHV_HYPERCALL_H__
+#define __ASM_BHV_HYPERCALL_H__
+
+static __always_inline unsigned long BHV_HYPERCALL(uint16_t target,
+						   uint32_t backend,
+						   uint32_t op, uint32_t ver,
+						   uint64_t arg)
+{
+	unsigned long rv;
+	// https://gcc.gnu.org/onlinedocs/gcc/Local-Register-Variables.html
+	register unsigned long r8 __asm__("r8") = arg;
+	__asm__ __volatile__("vmcall\n\t"
+			     : "=a"(rv)
+			     : "D"(target), "S"(backend), "d"(op), "c"(ver),
+			       "r"(r8)
+			     :);
+	return rv;
+}
+
+#endif /* __ASM_BHV_HYPERCALL_H__ */
diff --git arch/x86/include/asm/bhv/integrity.h arch/x86/include/asm/bhv/integrity.h
new file mode 100644
index 000000000000..f1213d0a8c4c
--- /dev/null
+++ arch/x86/include/asm/bhv/integrity.h
@@ -0,0 +1,32 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#ifndef __ASM_BHV_INTEGRITY_H__
+#define __ASM_BHV_INTEGRITY_H__
+
+#ifdef CONFIG_BHV_VAS
+
+#include <bhv/bhv.h>
+
+void __init bhv_integrity_arch_init(void);
+void __init bhv_register_idt(uint64_t addr,
+							 int numpages);
+
+#ifdef CONFIG_JUMP_LABEL
+#include <linux/jump_label.h>
+
+bool __bhv_text bhv_jump_label_validate_opcode(struct jump_entry *entry,
+					       enum jump_label_type type,
+					       const void *expected_opcode,
+					       size_t len);
+#endif /* CONFIG_JUMP_LABEL */
+#else /* CONFIG_BHV_VAS */
+static inline void __init bhv_register_idt(uint64_t addr, int numpages)
+{
+}
+#endif /* CONFIG_BHV_VAS */
+
+#endif /* __ASM_BHV_INTEGRITY_H__ */
diff --git arch/x86/include/asm/bhv/patch.h arch/x86/include/asm/bhv/patch.h
new file mode 100644
index 000000000000..4927cecdec62
--- /dev/null
+++ arch/x86/include/asm/bhv/patch.h
@@ -0,0 +1,59 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ *          Sebastian Vogl <sebastian@bedrocksystems.com>
+ */
+
+#ifndef __ASM_BHV_PATCH_H__
+#define __ASM_BHV_PATCH_H__
+
+struct bhv_alternatives_mod;
+struct bhv_alternatives_mod_arch {
+	const s32 *locks_begin;
+	const s32 *locks_end;
+	u8 *text_begin;
+	u8 *text_end;
+};
+
+#ifdef CONFIG_BHV_VAS
+
+#include <bhv/bhv.h>
+#include <bhv/patch.h>
+#include <bhv/interface/patch.h>
+
+#ifdef CONFIG_JUMP_LABEL
+#include <linux/jump_label.h>
+
+bool __bhv_text bhv_jump_label_validate_opcode(struct jump_entry *entry,
+					       enum jump_label_type type,
+					       const void *expected_opcode,
+					       size_t len);
+#endif /* CONFIG_JUMP_LABEL */
+
+struct bhv_alternatives_lock_search_param {
+	const s32 *locks_begin;
+	const s32 *locks_end;
+};
+
+bool __bhv_text bhv_alternatives_find_by_lock(void *search_param,
+					      struct bhv_alternatives_mod *cur);
+int __bhv_text bhv_alternatives_apply_vault_arch(
+	struct bhv_alternatives_mod *mod, void *arch, bhv_patch_arg_t *bhv_arg);
+void bhv_alternatives_add_module_arch(struct alt_instr *begin,
+				      struct alt_instr *end, const s32 *locks,
+				      const s32 *locks_end, u8 *text,
+				      u8 *text_end);
+struct bhv_alternatives_mod *__bhv_text
+bhv_alternatives_get_static_mods_vault(uint32_t *nr_mods);
+#else
+static inline void bhv_alternatives_add_module_arch(struct alt_instr *begin,
+						    struct alt_instr *end,
+						    const s32 *locks,
+						    const s32 *locks_end,
+						    u8 *text, u8 *text_end)
+{
+}
+#endif /* CONFIG_BHV_VAS */
+
+#endif /* __ASM_BHV_PATCH_H__ */
\ No newline at end of file
diff --git arch/x86/include/asm/hypervisor.h arch/x86/include/asm/hypervisor.h
index e41cbf2ec41d..591e48b05097 100644
--- arch/x86/include/asm/hypervisor.h
+++ arch/x86/include/asm/hypervisor.h
@@ -30,6 +30,7 @@ enum x86_hypervisor_type {
 	X86_HYPER_KVM,
 	X86_HYPER_JAILHOUSE,
 	X86_HYPER_ACRN,
+	X86_HYPER_BHV
 };
 
 #ifdef CONFIG_HYPERVISOR_GUEST
@@ -65,6 +66,7 @@ extern const struct hypervisor_x86 x86_hyper_kvm;
 extern const struct hypervisor_x86 x86_hyper_jailhouse;
 extern const struct hypervisor_x86 x86_hyper_acrn;
 extern struct hypervisor_x86 x86_hyper_xen_hvm;
+extern const struct hypervisor_x86 x86_hyper_bhv;
 
 extern bool nopv;
 extern enum x86_hypervisor_type x86_hyper_type;
diff --git arch/x86/kernel/alternative.c arch/x86/kernel/alternative.c
index 2400ad62f330..af170c380fe4 100644
--- arch/x86/kernel/alternative.c
+++ arch/x86/kernel/alternative.c
@@ -29,6 +29,9 @@
 #include <asm/io.h>
 #include <asm/fixmap.h>
 
+#include <asm/bhv/patch.h>
+#include <bhv/integrity.h>
+
 int __read_mostly alternatives_patched;
 
 EXPORT_SYMBOL_GPL(alternatives_patched);
@@ -376,6 +379,13 @@ void __init_or_module noinline apply_alternatives(struct alt_instr *start,
 	u8 *instr, *replacement;
 	u8 insn_buff[MAX_PATCH_LEN];
 
+#ifdef CONFIG_BHV_VAS
+	if (bhv_integrity_is_enabled()) {
+		bhv_alternatives_apply(start, end, NULL);
+		return;
+	}
+#endif /* CONFIG_BHV_VAS */
+
 	DPRINTK("alt table %px, -> %px", start, end);
 	/*
 	 * The scan order should be from start to end. A later scanned
@@ -471,7 +481,6 @@ static void alternatives_smp_unlock(const s32 *start, const s32 *end,
 			text_poke(ptr, ((unsigned char []){0x3E}), 1);
 	}
 }
-
 struct smp_alt_module {
 	/* what is this ??? */
 	struct module	*mod;
@@ -497,6 +506,11 @@ void __init_or_module alternatives_smp_module_add(struct module *mod,
 {
 	struct smp_alt_module *smp;
 
+#ifdef CONFIG_BHV_VAS
+	struct bhv_alternatives_lock_search_param p;
+	bool smp_lock;
+#endif
+
 	mutex_lock(&text_mutex);
 	if (!uniproc_patched)
 		goto unlock;
@@ -522,7 +536,23 @@ void __init_or_module alternatives_smp_module_add(struct module *mod,
 
 	list_add_tail(&smp->next, &smp_alt_modules);
 smp_unlock:
+#ifdef CONFIG_BHV_VAS
+	if (bhv_integrity_is_enabled()) {
+		// Add module with locks as this will be used for SMP only
+		bhv_alternatives_add_module_arch(locks, locks_end, locks,
+						 locks_end, text, text_end);
+		// Apply
+		smp_lock = false;
+		p.locks_begin = locks;
+		p.locks_end = locks_end;
+		bhv_alternatives_apply_custom_filter(
+			&p, &smp, bhv_alternatives_find_by_lock);
+	} else {
+		alternatives_smp_unlock(locks, locks_end, text, text_end);
+	}
+#else /* !CONFIG_BHV_VAS */
 	alternatives_smp_unlock(locks, locks_end, text, text_end);
+#endif /* CONFIG_BHV_VAS */
 unlock:
 	mutex_unlock(&text_mutex);
 }
@@ -556,9 +586,26 @@ void alternatives_enable_smp(void)
 		BUG_ON(num_online_cpus() != 1);
 		clear_cpu_cap(&boot_cpu_data, X86_FEATURE_UP);
 		clear_cpu_cap(&cpu_data(0), X86_FEATURE_UP);
-		list_for_each_entry(mod, &smp_alt_modules, next)
+		list_for_each_entry (mod, &smp_alt_modules, next) {
+#ifdef CONFIG_BHV_VAS
+			if (bhv_integrity_is_enabled()) {
+				struct bhv_alternatives_lock_search_param p;
+				bool smp = true;
+				p.locks_begin = mod->locks;
+				p.locks_end = mod->locks_end;
+				bhv_alternatives_apply_custom_filter(
+					&p, &smp,
+					bhv_alternatives_find_by_lock);
+			} else {
+				alternatives_smp_lock(mod->locks,
+						      mod->locks_end, mod->text,
+						      mod->text_end);
+			}
+#else /* !CONFIG_BHV_VAS */
 			alternatives_smp_lock(mod->locks, mod->locks_end,
 					      mod->text, mod->text_end);
+#endif /* CONFIG_BHV_VAS */
+		}
 		uniproc_patched = false;
 	}
 	mutex_unlock(&text_mutex);
diff --git arch/x86/kernel/cpu/hypervisor.c arch/x86/kernel/cpu/hypervisor.c
index 553bfbfc3a1b..20bfa373b05b 100644
--- arch/x86/kernel/cpu/hypervisor.c
+++ arch/x86/kernel/cpu/hypervisor.c
@@ -45,6 +45,9 @@ static const __initconst struct hypervisor_x86 * const hypervisors[] =
 #ifdef CONFIG_ACRN_GUEST
 	&x86_hyper_acrn,
 #endif
+#ifdef CONFIG_BHV_VAS
+	&x86_hyper_bhv,
+#endif
 };
 
 enum x86_hypervisor_type x86_hyper_type;
diff --git arch/x86/kernel/idt.c arch/x86/kernel/idt.c
index ee1a283f8e96..93615b1064fc 100644
--- arch/x86/kernel/idt.c
+++ arch/x86/kernel/idt.c
@@ -10,6 +10,7 @@
 #include <asm/proto.h>
 #include <asm/desc.h>
 #include <asm/hw_irq.h>
+#include <asm/bhv/integrity.h>
 
 #define DPL0		0x0
 #define DPL3		0x3
@@ -310,6 +311,8 @@ void __init idt_setup_apic_and_irq_gates(void)
 	/* Make the IDT table read only */
 	set_memory_ro((unsigned long)&idt_table, 1);
 
+	bhv_register_idt((uint64_t)&idt_table, 1);
+
 	idt_setup_done = true;
 }
 
diff --git arch/x86/kernel/jump_label.c arch/x86/kernel/jump_label.c
index 5ba8477c2cb7..03ef91a49150 100644
--- arch/x86/kernel/jump_label.c
+++ arch/x86/kernel/jump_label.c
@@ -15,6 +15,9 @@
 #include <asm/kprobes.h>
 #include <asm/alternative.h>
 #include <asm/text-patching.h>
+#include <bhv/bhv.h>
+#include <bhv/patch.h>
+#include <bhv/integrity.h>
 
 static void bug_at(const void *ip, int line)
 {
@@ -58,9 +61,30 @@ __jump_label_set_jump_code(struct jump_entry *entry, enum jump_label_type type,
 	return code;
 }
 
+#ifdef CONFIG_BHV_VAS
+static void __orig_jump_label_transform(struct jump_entry *entry,
+					enum jump_label_type type, int init);
+
 static inline void __jump_label_transform(struct jump_entry *entry,
 					  enum jump_label_type type,
 					  int init)
+{
+	if (bhv_integrity_is_enabled()) {
+		const void *opcode =
+			__jump_label_set_jump_code(entry, type, init);
+		bhv_patch_jump_label(entry, opcode, JUMP_LABEL_NOP_SIZE);
+	} else {
+		__orig_jump_label_transform(entry, type, init);
+	}
+}
+
+static inline void __orig_jump_label_transform(struct jump_entry *entry,
+					       enum jump_label_type type,
+					       int init)
+#else /* CONFIG_BHV_VAS */
+static inline void __jump_label_transform(struct jump_entry *entry,
+					  enum jump_label_type type, int init)
+#endif /* CONFIG_BHV_VAS */
 {
 	const void *opcode = __jump_label_set_jump_code(entry, type, init);
 
@@ -114,18 +138,38 @@ bool arch_jump_label_transform_queue(struct jump_entry *entry,
 
 	mutex_lock(&text_mutex);
 	opcode = __jump_label_set_jump_code(entry, type, 0);
+#ifdef CONFIG_BHV_VAS
+	if (bhv_integrity_is_enabled())
+		bhv_patch_jump_label(entry, opcode, JUMP_LABEL_NOP_SIZE);
+	else {
+		text_poke_queue((void *)jump_entry_code(entry), opcode,
+				JUMP_LABEL_NOP_SIZE, NULL);
+	}
+#else
 	text_poke_queue((void *)jump_entry_code(entry),
 			opcode, JUMP_LABEL_NOP_SIZE, NULL);
+#endif
 	mutex_unlock(&text_mutex);
 	return true;
 }
 
+#ifdef CONFIG_BHV_VAS
+void arch_jump_label_transform_apply(void)
+{
+	if (!bhv_integrity_is_enabled()) {
+		mutex_lock(&text_mutex);
+		text_poke_finish();
+		mutex_unlock(&text_mutex);
+	}
+}
+#else /* CONFIG_BHV_VAS */
 void arch_jump_label_transform_apply(void)
 {
 	mutex_lock(&text_mutex);
 	text_poke_finish();
 	mutex_unlock(&text_mutex);
 }
+#endif /* CONFIG_BHV_VAS */
 
 static enum {
 	JL_STATE_START,
diff --git arch/x86/kernel/module.c arch/x86/kernel/module.c
index 5e9a34b5bd74..9b6a4cedd63e 100644
--- arch/x86/kernel/module.c
+++ arch/x86/kernel/module.c
@@ -25,6 +25,9 @@
 #include <asm/setup.h>
 #include <asm/unwind.h>
 
+#include <asm/bhv/patch.h>
+#include <bhv/integrity.h>
+
 #if 0
 #define DEBUGP(fmt, ...)				\
 	printk(KERN_DEBUG fmt, ##__VA_ARGS__)
@@ -254,6 +257,12 @@ int module_finalize(const Elf_Ehdr *hdr,
 		*para = NULL, *orc = NULL, *orc_ip = NULL;
 	char *secstrings = (void *)hdr + sechdrs[hdr->e_shstrndx].sh_offset;
 
+#ifdef CONFIG_BHV_VAS
+	void *alt_start = NULL;
+	void *alt_end = NULL;
+	struct bhv_alternatives_mod_arch arch;
+#endif
+
 	for (s = sechdrs; s < sechdrs + hdr->e_shnum; s++) {
 		if (!strcmp(".text", secstrings + s->sh_name))
 			text = s;
@@ -269,9 +278,28 @@ int module_finalize(const Elf_Ehdr *hdr,
 			orc_ip = s;
 	}
 
+#ifdef CONFIG_BHV_VAS
+	if (alt) {
+		alt_start = (void *)alt->sh_addr;
+		alt_end = alt_start + alt->sh_size;
+	}
+
+	if (locks && text) {
+		arch.locks_begin = (void *)locks->sh_addr;
+		arch.locks_end = (void *)locks->sh_addr + locks->sh_size;
+		arch.text_begin = (void *)text->sh_addr;
+		arch.text_end = (void *)text->sh_addr + text->sh_size;
+	}
+#endif /* CONFIG_BHV_VAS */
+
 	if (alt) {
 		/* patch .altinstructions */
 		void *aseg = (void *)alt->sh_addr;
+#ifdef CONFIG_BHV_VAS
+		if (bhv_integrity_is_enabled()) {
+			bhv_alternatives_add_module(alt_start, alt_end, &arch);
+		}
+#endif /* CONFIG_BHV_VAS */
 		apply_alternatives(aseg, aseg + alt->sh_size);
 	}
 	if (locks && text) {
diff --git arch/x86/kernel/vmlinux.lds.S arch/x86/kernel/vmlinux.lds.S
index bf9e0adb5b7e..58c5485e47d4 100644
--- arch/x86/kernel/vmlinux.lds.S
+++ arch/x86/kernel/vmlinux.lds.S
@@ -137,6 +137,7 @@ SECTIONS
 		ALIGN_ENTRY_TEXT_END
 		SOFTIRQENTRY_TEXT
 		STATIC_CALL_TEXT
+		BHV_TEXT
 		*(.fixup)
 		*(.gnu.warning)
 
@@ -354,6 +355,17 @@ SECTIONS
 	}
 #endif
 
+#ifdef CONFIG_BHV_VAS
+	. = ALIGN(PAGE_SIZE);
+	.bhv.data : AT(ADDR(.bhv.data) - LOAD_OFFSET) {
+		__bhv_data_start = .;
+		. += PAGE_SIZE;
+		*(.bhv.data)
+		. = ALIGN(PAGE_SIZE);
+		__bhv_data_end = .;
+	}
+#endif
+
 	/* BSS */
 	. = ALIGN(PAGE_SIZE);
 	.bss : AT(ADDR(.bss) - LOAD_OFFSET) {
diff --git arch/x86/mm/init.c arch/x86/mm/init.c
index c7a47603537f..be0b8e625e66 100644
--- arch/x86/mm/init.c
+++ arch/x86/mm/init.c
@@ -36,6 +36,9 @@
 
 #include "mm_internal.h"
 
+#include <bhv/bhv.h>
+#include <bhv/start.h>
+
 /*
  * Tables translating between page_cache_type_t and pte encoding.
  *
@@ -919,6 +922,8 @@ void __ref free_initmem(void)
 
 	mem_encrypt_free_decrypted_mem();
 
+	bhv_start();
+
 	free_kernel_image_pages("unused kernel image (initmem)",
 				&__init_begin, &__init_end);
 }
diff --git include/asm-generic/sections.h include/asm-generic/sections.h
index d16302d3eb59..5ce32b4ce2e0 100644
--- include/asm-generic/sections.h
+++ include/asm-generic/sections.h
@@ -58,6 +58,13 @@ extern char __noinstr_text_start[], __noinstr_text_end[];
 
 extern __visible const void __nosave_begin, __nosave_end;
 
+#ifdef CONFIG_BHV_VAS
+extern char __bhv_text_start[];
+extern char __bhv_text_end[];
+extern char __bhv_data_start[];
+extern char __bhv_data_end[];
+#endif
+
 /* Function descriptor handling (if any).  Override in asm/sections.h */
 #ifndef dereference_function_descriptor
 #define dereference_function_descriptor(p) ((void *)(p))
diff --git include/asm-generic/vmlinux.lds.h include/asm-generic/vmlinux.lds.h
index a774361f28d4..4b1e92cdc356 100644
--- include/asm-generic/vmlinux.lds.h
+++ include/asm-generic/vmlinux.lds.h
@@ -656,6 +656,17 @@
 		*(.static_call.text)					\
 		__static_call_text_end = .;
 
+#ifdef CONFIG_BHV_VAS
+#define BHV_TEXT							\
+		. = ALIGN(PAGE_SIZE);				\
+		__bhv_text_start = .;				\
+		*(.bhv.text)						\
+		. = ALIGN(PAGE_SIZE);				\
+		__bhv_text_end = .;
+#else
+#define BHV_TEXT
+#endif
+
 /* Section used for early init (in .S files) */
 #define HEAD_TEXT  KEEP(*(.head.text))
 
diff --git include/bhv/acl.h include/bhv/acl.h
new file mode 100644
index 000000000000..9f507a87a668
--- /dev/null
+++ include/bhv/acl.h
@@ -0,0 +1,51 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Sebastian Vogl <sebastian@bedrocksystems.com>
+ *          Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#ifndef __BHV_ACL_H__
+#define __BHV_ACL_H__
+
+#ifdef CONFIG_BHV_VAS
+#include <linux/init.h>
+
+#include <bhv/bhv.h>
+#include <bhv/interface/common.h>
+
+void __init bhv_acl_mm_init(void);
+
+static inline bool bhv_acl_is_proc_acl_enabled(void)
+{
+	if (!is_bhv_initialized() || bhv_configuration_bitmap == NULL)
+		return false;
+
+	return (bool)test_bit(BHV_CONFIG_PROC_ACL, bhv_configuration_bitmap);
+}
+
+static inline bool bhv_acl_is_driver_acl_enabled(void)
+{
+	if (!is_bhv_initialized() || bhv_configuration_bitmap == NULL)
+		return false;
+
+	return (bool)test_bit(BHV_CONFIG_DRIVER_ACL, bhv_configuration_bitmap);
+}
+
+bool bhv_block_driver(const char *target);
+bool bhv_block_process(const char *target);
+
+#else /* CONFIG_BHV_VAS */
+
+static inline bool bhv_acl_is_proc_acl_enabled(void)
+{
+	return false;
+}
+
+static inline bool bhv_acl_is_driver_acl_enabled(void)
+{
+	return false;
+}
+
+#endif /* CONFIG_BHV_VAS */
+#endif /* __BHV_ACL_H__ */
\ No newline at end of file
diff --git include/bhv/bhv.h include/bhv/bhv.h
new file mode 100644
index 000000000000..b1eecdd1cf5c
--- /dev/null
+++ include/bhv/bhv.h
@@ -0,0 +1,43 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#ifndef __BHV_BHV_H__
+#define __BHV_BHV_H__
+
+#include <linux/kernel.h>
+#include <asm/bug.h>
+
+#define __bhv_text __section(".bhv.text") noinline
+#define __bhv_data __section(".bhv.data") noinline
+
+#ifdef CONFIG_BHV_PANIC_ON_FAIL
+#define bhv_fail(fmt, ...) panic(fmt, ##__VA_ARGS__)
+#else
+#define bhv_fail(fmt, ...) pr_err(fmt, ##__VA_ARGS__)
+#endif
+
+#ifdef CONFIG_BHV_VAS
+extern bool bhv_initialized __ro_after_init;
+extern unsigned long *bhv_configuration_bitmap __ro_after_init;
+
+static inline bool is_bhv_initialized(void)
+{
+	BUG_ON(bhv_initialized && bhv_configuration_bitmap == NULL);
+	return bhv_initialized;
+}
+
+void __init bhv_mm_init(void);
+#else /* CONFIG_BHV_VAS */
+static inline bool is_bhv_initialized(void)
+{
+	return false;
+}
+static inline void bhv_mm_init(void)
+{
+}
+#endif /* CONFIG_BHV_VAS */
+
+#endif /* __BHV_BHV_H__ */
diff --git include/bhv/bhv_print.h include/bhv/bhv_print.h
new file mode 100644
index 000000000000..35d267d47d64
--- /dev/null
+++ include/bhv/bhv_print.h
@@ -0,0 +1,26 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Sebastian Vogl <sebastian@bedrocksystems.com>
+ */
+
+#ifndef __BHV_BHV_PRINT_H__
+#define __BHV_BHV_PRINT_H__
+
+#ifdef CONFIG_BHV_VAS
+
+// Common print prefix
+#ifndef pr_fmt
+#define pr_fmt(fmt) "[BHV-VAS] " fmt
+#endif
+
+#ifdef CONFIG_BHV_VAS_DEBUG
+#define bhv_debug(fmt, ...)                                                    \
+	printk(KERN_DEBUG pr_fmt("[DEBUG] " fmt), ##__VA_ARGS__)
+#else
+#define bhv_debug(fmt, ...) no_printk(KERN_DEBUG pr_fmt(fmt), ##__VA_ARGS__)
+#endif /* CONFIG_BHV_VAS_DEBUG */
+
+#endif /* CONFIG_BHV_VAS */
+
+#endif /* __BHV_BHV_PRINT_H__ */
\ No newline at end of file
diff --git include/bhv/creds.h include/bhv/creds.h
new file mode 100644
index 000000000000..81a73366fb15
--- /dev/null
+++ include/bhv/creds.h
@@ -0,0 +1,79 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Sergej Proskurin <sergej@bedrocksystems.com>
+ */
+
+#ifndef __BHV_CREDS_H__
+#define __BHV_CREDS_H__
+
+#include <linux/sched.h>
+
+#include <bhv/bhv.h>
+#include <bhv/interface/common.h>
+#include <bhv/interface/init.h>
+
+#ifdef CONFIG_BHV_VAS
+
+static inline bool bhv_cred_is_enabled(void)
+{
+	if (!is_bhv_initialized())
+		return false;
+
+	return !!test_bit(BHV_CONFIG_CREDS, bhv_configuration_bitmap);
+}
+
+
+int bhv_cred_assign(struct task_struct *t, uint64_t clone_flags);
+int bhv_cred_assign_priv(struct cred *c, struct task_struct *daemon);
+void bhv_cred_commit(struct cred *c);
+void bhv_cred_release(struct cred *c);
+int bhv_cred_verify(struct task_struct *t);
+
+int __init bhv_cred_init(void);
+void __init bhv_cred_mm_init(void);
+
+#else /* CONFIG_BHV_VAS */
+
+static inline int bhv_cred_init(void)
+{
+	return 0;
+}
+
+static inline bool bhv_cred_is_enabled(void)
+{
+	return false;
+}
+
+static inline int bhv_cred_assign(struct task_struct *t, uint64_t clone_flags)
+{
+	return 0;
+}
+
+static inline int bhv_cred_assign_priv(struct cred *c, struct task_struct *d)
+{
+	return 0;
+}
+
+static inline void bhv_cred_commit(struct cred *c)
+{
+}
+
+static inline void bhv_cred_release(struct cred *c)
+{
+}
+
+static inline int bhv_cred_verify(struct task_struct *t)
+{
+	return 0;
+}
+
+static inline void bhv_cred_mm_init(void)
+{
+}
+
+
+
+#endif /* CONFIG_BHV_VAS */
+
+#endif /* __BHV_CREDS_H__ */
diff --git include/bhv/guestlog.h include/bhv/guestlog.h
new file mode 100644
index 000000000000..f7ab25e0c726
--- /dev/null
+++ include/bhv/guestlog.h
@@ -0,0 +1,86 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ *          Sergej Proskurin <sergej@bedrocksystems.com>
+ *          Sebastian Vogl <sebastian@bedrocksystems.com>
+ */
+#ifndef __BHV_GUESTLOG_H__
+#define __BHV_GUESTLOG_H__
+
+#include <linux/types.h>
+#include <bhv/bhv.h>
+#include <bhv/interface/common.h>
+#include <bhv/interface/guestlog.h>
+
+extern bhv_guestlog_config_t bhv_guestlog_config __ro_after_init;
+
+void __init bhv_guestlog_init(void);
+
+static inline bool bhv_guestlog_enabled(void)
+{
+	if (!is_bhv_initialized() || bhv_configuration_bitmap == NULL)
+		return false;
+
+	return (bool)test_bit(BHV_CONFIG_LOGGING, bhv_configuration_bitmap);
+}
+
+static inline bool bhv_guestlog_log_process_events(void)
+{
+	if (!bhv_guestlog_enabled())
+		return false;
+
+	if (!bhv_guestlog_config.valid ||
+	    !test_bit(BHV_GUESTLOG_CONFIG_LOG_PROCESS_EVENTS,
+		      (unsigned long *)&bhv_guestlog_config.log_bitmap))
+		return false;
+
+	return true;
+}
+
+static inline bool bhv_guestlog_log_driver_events(void)
+{
+	if (!bhv_guestlog_enabled())
+		return false;
+
+	if (!bhv_guestlog_config.valid ||
+	    !test_bit(BHV_GUESTLOG_CONFIG_LOG_DRIVER_EVENTS,
+		      (unsigned long *)&bhv_guestlog_config.log_bitmap))
+		return false;
+
+	return true;
+}
+
+static inline uint16_t bhv_guestlog_calc_msg_sz(uint16_t type, size_t buf_sz)
+{
+	switch (type) {
+	case BHV_GUESTLOG_MSG_TYPE_STR:
+		return sizeof(guestlog_msg_header_t) + buf_sz;
+	case BHV_GUESTLOG_MSG_TYPE_PROCESS_FORK:
+		return sizeof(guestlog_msg_header_t) +
+		       sizeof(guestlog_msg_process_fork_t) + buf_sz;
+	case BHV_GUESTLOG_MSG_TYPE_PROCESS_EXEC:
+		return sizeof(guestlog_msg_header_t) +
+		       sizeof(guestlog_msg_process_exec_t) + buf_sz;
+	case BHV_GUESTLOG_MSG_TYPE_PROCESS_EXIT:
+		return sizeof(guestlog_msg_header_t) +
+		       sizeof(guestlog_msg_process_exit_t) + buf_sz;
+	case BHV_GUESTLOG_MSG_TYPE_DRIVER_LOAD:
+		return sizeof(guestlog_msg_header_t) +
+		       sizeof(guestlog_msg_driver_load_t) + buf_sz;
+	default:
+		return 0;
+	}
+}
+
+int bhv_guestlog_log_str(char *fmt, ...);
+int bhv_guestlog_log_process_fork(uint32_t child_pid, const char *child_comm,
+				  uint32_t parent_pid, const char *parent_comm);
+int bhv_guestlog_log_process_exec(uint32_t pid, uint32_t parent_pid,
+				  const char *comm);
+int bhv_guestlog_log_process_exit(uint32_t pid, uint32_t parent_pid,
+				  const char *comm);
+int bhv_guestlog_log_driver_load(const char *name);
+void bhv_guestlog_start(void);
+
+#endif /* __BHV_GUESTLOG_H__ */
\ No newline at end of file
diff --git include/bhv/init.h include/bhv/init.h
new file mode 100644
index 000000000000..0b9a72e48ea9
--- /dev/null
+++ include/bhv/init.h
@@ -0,0 +1,21 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#ifndef __BHV_INIT_H__
+#define __BHV_INIT_H__
+
+#include <bhv/interface/integrity.h>
+
+/* This constant must take into account any regions added in bhv_init_hyp_arch(...) */
+static const unsigned int BHV_INIT_MAX_REGIONS = 5;
+
+int __init bhv_init_hyp(void *init_start, uint64_t init_size, void *text_start,
+			uint64_t text_size);
+void __init bhv_init_hyp_arch(bhv_mem_region_t *init_phys_mem_regions,
+			      unsigned int *region_counter);
+int bhv_start_hyp(void);
+
+#endif /* __BHV_INIT_H__ */
diff --git include/bhv/integrity.h include/bhv/integrity.h
new file mode 100644
index 000000000000..71a1881ea194
--- /dev/null
+++ include/bhv/integrity.h
@@ -0,0 +1,194 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ *          Sergej Proskurin <sergej@bedrocksystems.com>
+ *          Sebastian Vogl <sebastian@bedrocksystems.com>
+ */
+
+#ifndef __BHV_INTEGRITY_H__
+#define __BHV_INTEGRITY_H__
+
+#include <asm/io.h>
+#include <linux/list.h>
+
+#include <bhv/bhv.h>
+#include <bhv/interface/common.h>
+#include <bhv/interface/integrity.h>
+
+#ifdef CONFIG_BHV_VAS
+struct bhv_mem_region_node {
+	bhv_mem_region_t region;
+	struct list_head list;
+};
+typedef struct bhv_mem_region_node bhv_mem_region_node_t;
+
+extern struct kmem_cache *bhv_mem_region_cache;
+
+static inline bool bhv_integrity_is_enabled(void)
+{
+	if (!is_bhv_initialized())
+		return false;
+
+	return (bool)test_bit(BHV_CONFIG_INTEGRITY, bhv_configuration_bitmap);
+}
+
+void __init bhv_integrity_mm_init(void);
+
+int bhv_start_integrity_arch(void);
+
+int bhv_integrity_disable_events(void);
+int bhv_create_kern_phys_mem_region_hyp(uint64_t owner,
+					bhv_mem_region_t *region_head);
+int bhv_update_kern_phys_mem_region_hyp(bhv_mem_region_t *region_head);
+int bhv_remove_kern_phys_mem_region_by_region_hyp(bhv_mem_region_t *region_head);
+int bhv_remove_kern_phys_mem_region_by_owner_hyp(uint64_t owner);
+
+static inline void bhv_release_arg_list(struct list_head *head)
+{
+	bhv_mem_region_node_t *entry, *tmp;
+	list_for_each_entry_safe (entry, tmp, head, list)
+		kmem_cache_free(bhv_mem_region_cache, entry);
+}
+
+static inline int bhv_link_node_op_create(struct list_head *head, uint64_t addr,
+					  uint64_t size, uint32_t type,
+					  uint64_t flags)
+{
+	bhv_mem_region_node_t *n =
+		kmem_cache_alloc(bhv_mem_region_cache, GFP_KERNEL);
+	if (n == NULL) {
+		bhv_fail("BHV: failed to allocate mem region");
+		return -ENOMEM;
+	}
+
+	n->region.bhv_mem_region_create.start_addr = addr;
+	n->region.bhv_mem_region_create.size = size;
+	n->region.bhv_mem_region_create.type = type;
+	n->region.bhv_mem_region_create.flags = flags;
+	n->region.bhv_mem_region_create.next = BHV_INVALID_PHYS_ADDR;
+
+	/*
+	 * XXX: Consider moving the field 'next' out of the union in
+	 * bhv_mem_region_t. This will allow to move the remaining
+	 * list-maintenance operations into the calling function.
+	 */
+
+	if (!list_empty(head)) {
+		bhv_mem_region_node_t *tail =
+			list_last_entry(head, bhv_mem_region_node_t, list);
+		tail->region.bhv_mem_region_create.next =
+			virt_to_phys(&n->region);
+	}
+
+	list_add_tail(&n->list, head);
+
+	return 0;
+}
+
+static inline int bhv_link_node_op_update(struct list_head *head, uint64_t addr,
+					  uint32_t type, uint64_t flags)
+{
+	bhv_mem_region_node_t *n =
+		kmem_cache_alloc(bhv_mem_region_cache, GFP_KERNEL);
+	if (n == NULL) {
+		bhv_fail("BHV: failed to allocate mem region");
+		return -ENOMEM;
+	}
+
+	n->region.bhv_mem_region_update.start_addr = addr;
+	n->region.bhv_mem_region_update.type = type;
+	n->region.bhv_mem_region_update.flags = flags;
+	n->region.bhv_mem_region_update.next = BHV_INVALID_PHYS_ADDR;
+
+	/*
+	 * XXX: Consider moving the field 'next' out of the union in
+	 * bhv_mem_region_t. This will allow to move the remaining
+	 * list-maintenance operations into the calling function.
+	 */
+
+	if (!list_empty(head)) {
+		struct bhv_mem_region_node *tail =
+			list_last_entry(head, struct bhv_mem_region_node, list);
+		tail->region.bhv_mem_region_update.next =
+			virt_to_phys(&n->region);
+	}
+
+	list_add_tail(&n->list, head);
+
+	return 0;
+}
+
+static inline int bhv_link_node_op_remove(struct list_head *head, uint64_t addr)
+{
+	bhv_mem_region_node_t *n =
+		kmem_cache_alloc(bhv_mem_region_cache, GFP_KERNEL);
+	if (n == NULL) {
+		bhv_fail("BHV: failed to allocate mem region");
+		return -ENOMEM;
+	}
+
+	n->region.bhv_mem_region_remove.start_addr = addr;
+	n->region.bhv_mem_region_remove.next = BHV_INVALID_PHYS_ADDR;
+
+	/*
+	 * XXX: Consider moving the field 'next' out of the union in
+	 * bhv_mem_region_t. This will allow to move the remaining
+	 * list-maintenance operations into the calling function.
+	 */
+
+	if (!list_empty(head)) {
+		bhv_mem_region_node_t *tail =
+			list_last_entry(head, bhv_mem_region_node_t, list);
+		tail->region.bhv_mem_region_remove.next =
+			virt_to_phys(&n->region);
+	}
+
+	list_add_tail(&n->list, head);
+
+	return 0;
+}
+
+#else /* CONFIG_BHV_VAS */
+
+static inline bool bhv_integrity_is_enabled(void)
+{
+	return false;
+}
+
+static inline void bhv_integrity_mm_init(void)
+{
+}
+
+static inline int bhv_integrity_disable_events(void)
+{
+	return 0;
+}
+
+static inline int
+bhv_create_kern_phys_mem_region_hyp(uint64_t owner,
+				    bhv_mem_region_t *region_head)
+{
+	return 0;
+}
+
+static inline int
+bhv_update_kern_phys_mem_region_hyp(bhv_mem_region_t *region_head)
+{
+	return 0;
+}
+
+static inline int
+bhv_remove_kern_phys_mem_region_by_region_hyp(bhv_mem_region_t *region_head)
+{
+	return 0;
+}
+
+static inline int bhv_remove_kern_phys_mem_region_by_owner_hyp(uint64_t owner)
+{
+	return 0;
+}
+
+#endif /* CONFIG_BHV_VAS */
+
+#endif /* __BHV_INTEGRITY_H__ */
diff --git include/bhv/interface/acl.h include/bhv/interface/acl.h
new file mode 100644
index 000000000000..c6822e3027c2
--- /dev/null
+++ include/bhv/interface/acl.h
@@ -0,0 +1,33 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Sebastian Vogl <sebastian@bedrocksystems.com>
+ *          Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#ifndef __BHV_INTERFACE_ACL_H__
+#define __BHV_INTERFACE_ACL_H__
+
+#include <linux/types.h>
+
+/* BHV VAS ACL BACKEND OPS */
+#define BHV_VAS_ACL_OP_INIT_PROC_ACL 0U
+#define BHV_VAS_ACL_OP_INIT_DRIVER_ACL 1U
+#define BHV_VAS_ACL_OP_VIOLATION_PROC_ACL 2U
+#define BHV_VAS_ACL_OP_VIOLATION_DRIVER_ACL 3U
+
+typedef struct {
+	uint8_t valid;
+	uint8_t is_allow;
+	uint16_t num_pages;
+	uint16_t list_len;
+	uint16_t padding;
+	uint64_t list[];
+} __attribute__((__packed__)) bhv_acl_config_t;
+
+typedef struct {
+	uint64_t name;
+	uint16_t name_len;
+	uint8_t block;
+} __attribute__((__packed__)) bhv_acl_violation_t;
+#endif /* __BHV_INTERFACE_ACL_H__ */
diff --git include/bhv/interface/common.h include/bhv/interface/common.h
new file mode 100644
index 000000000000..f6e5c8f52423
--- /dev/null
+++ include/bhv/interface/common.h
@@ -0,0 +1,38 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#ifndef __BHV_INTERFACE_COMMON_H__
+#define __BHV_INTERFACE_COMMON_H__
+
+/* BHV VAS ABI version */
+
+#define BHV_VAS_ABI_VERSION 0xbed00001u
+
+/* BHV Targets */
+
+#define TARGET_BHV_VAS 1
+
+/* BHV VAS Backends */
+
+#define BHV_VAS_BACKEND_INIT 1
+#define BHV_VAS_BACKEND_INTEGRITY 2
+#define BHV_VAS_BACKEND_PATCH 3
+#define BHV_VAS_BACKEND_VAULT 4
+#define BHV_VAS_BACKEND_ACL 5
+#define BHV_VAS_BACKEND_GUESTLOG 6
+#define BHV_VAS_BACKEND_CREDS 7
+
+/* BHV CONFIGURATION BITS */
+#define BHV_CONFIG_INTEGRITY 0
+#define BHV_CONFIG_PROC_ACL 1
+#define BHV_CONFIG_DRIVER_ACL 2
+#define BHV_CONFIG_LOGGING 3
+#define BHV_CONFIG_CREDS 4
+
+/* Common Defines */
+#define BHV_INVALID_PHYS_ADDR (~0ULL)
+
+#endif /* __BHV_INTERFACE_COMMON_H__ */
diff --git include/bhv/interface/creds.h include/bhv/interface/creds.h
new file mode 100644
index 000000000000..3bdee7376b06
--- /dev/null
+++ include/bhv/interface/creds.h
@@ -0,0 +1,90 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Sergej Proskurin <sergej@bedrocksystems.com>
+ */
+
+#ifndef __BHV_INTERFACE_CREDS_H__
+#define __BHV_INTERFACE_CREDS_H__
+
+#include <linux/types.h>
+
+/* BHV VAS CREDS BACKEND OPS */
+#define BHV_VAS_CREDS_OP_CONFIGURE 0U
+#define BHV_VAS_CREDS_OP_REGISTER_INIT_TASK 1U
+#define BHV_VAS_CREDS_OP_ASSIGN 2U
+#define BHV_VAS_CREDS_OP_ASSIGN_PRIV 3U
+#define BHV_VAS_CREDS_OP_COMMIT 4U
+#define BHV_VAS_CREDS_OP_RELEASE 5U
+#define BHV_VAS_CREDS_OP_VERIFICATION 6U
+#define BHV_VAS_CREDS_OP_LOG 7U
+
+enum event_type {
+	EVENT_NONE = 0,
+	CORRUPTION,
+	INVALID_ASSIGNMENT,
+	DOUBLE_ASSIGNMENT,
+	INVALID_COMMIT,
+	DOUBLE_COMMIT,
+	MAX_EVENTS
+};
+
+typedef struct {
+	uint64_t addr;
+	uint64_t cred;
+	uint64_t hmac;
+} __attribute__((__packed__)) bhv_task_cred_t;
+
+typedef struct {
+	bhv_task_cred_t init_task;
+} __attribute__((__packed__)) bhv_creds_init_task_arg_t;
+
+typedef struct {
+	bhv_task_cred_t new_task;
+	bhv_task_cred_t parent;
+	uint8_t ret;
+} __attribute__((__packed__)) bhv_creds_assign_arg_t;
+
+typedef struct {
+	uint64_t cred;
+	uint64_t daemon;
+	uint8_t ret;
+} __attribute__((__packed__)) bhv_creds_assign_priv_arg_t;
+
+typedef struct {
+	bhv_task_cred_t cur;
+	uint8_t ret;
+} __attribute__((__packed__)) bhv_creds_commit_arg_t;
+
+typedef struct {
+	uint64_t cred;
+} __attribute__((__packed__)) bhv_creds_release_arg_t;
+
+typedef struct {
+	bhv_task_cred_t task;
+	uint8_t ret;
+} __attribute__((__packed__)) bhv_creds_verification_arg_t;
+
+typedef struct {
+	uint8_t event_type;
+	uint8_t block;
+	uint16_t pad1;
+	uint32_t task_pid;
+	uint64_t task_addr;
+	uint64_t task_cred;
+	char task_name[TASK_COMM_LEN];
+} __attribute__((__packed__)) bhv_creds_log_arg_t;
+
+typedef struct {
+	union {
+		bhv_creds_init_task_arg_t creds_register;
+		bhv_creds_assign_arg_t creds_assign;
+		bhv_creds_assign_priv_arg_t creds_assign_priv;
+		bhv_creds_commit_arg_t creds_commit;
+		bhv_creds_release_arg_t creds_release;
+		bhv_creds_verification_arg_t creds_verify;
+		bhv_creds_log_arg_t creds_log;
+	};
+} __attribute__((__packed__)) bhv_creds_arg_t;
+
+#endif /* __BHV_INTERFACE_CREDS_H__ */
diff --git include/bhv/interface/guestlog.h include/bhv/interface/guestlog.h
new file mode 100644
index 000000000000..a2a894f78480
--- /dev/null
+++ include/bhv/interface/guestlog.h
@@ -0,0 +1,81 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ *          Sergej Proskurin <sergej@bedrocksystems.com>
+ *          Sebastian Vogl <sebastian@bedrocksystems.com>
+ */
+
+#ifndef __BHV_INTERFACE_GUESTLOG_H__
+#define __BHV_INTERFACE_GUESTLOG_H__
+
+#include <linux/types.h>
+
+/* BHV VAS ACL BACKEND OPS */
+#define BHV_VAS_GUESTLOG_OP_INIT_GUESTLOG 0U
+
+/* BHV GUESTLOG MESSAGE TYPES */
+#define BHV_GUESTLOG_MSG_TYPE_STR 0U
+#define BHV_GUESTLOG_MSG_TYPE_PROCESS_FORK 1U
+#define BHV_GUESTLOG_MSG_TYPE_PROCESS_EXEC 2U
+#define BHV_GUESTLOG_MSG_TYPE_PROCESS_EXIT 3U
+#define BHV_GUESTLOG_MSG_TYPE_DRIVER_LOAD 4U
+
+typedef struct {
+	uint16_t type;
+	uint16_t sz;
+} __attribute__((__packed__)) guestlog_msg_header_t;
+
+#define MAX_MSG_SZ (sizeof(guestlog_msg_header_t) + 1048)
+#define MAX_MSG_DATA_SZ 1048
+
+typedef struct {
+	char buf[MAX_MSG_DATA_SZ];
+} __attribute__((__packed__)) guestlog_msg_str_t;
+
+typedef struct {
+	uint32_t child_pid;
+	uint32_t parent_pid;
+	uint32_t child_comm_offset;
+	uint32_t parent_comm_offset;
+	char buf[];
+} __attribute__((__packed__)) guestlog_msg_process_fork_t;
+
+typedef struct {
+	uint32_t pid;
+	uint32_t parent_pid;
+	char name[];
+} __attribute__((__packed__)) guestlog_msg_process_exec_t;
+
+typedef struct {
+	uint32_t pid;
+	uint32_t parent_pid;
+	char name[];
+} __attribute__((__packed__)) guestlog_msg_process_exit_t;
+
+typedef struct {
+	char name[MAX_MSG_DATA_SZ];
+} __attribute__((__packed__)) guestlog_msg_driver_load_t;
+
+typedef struct {
+	guestlog_msg_header_t header;
+	union {
+		guestlog_msg_str_t str;
+		guestlog_msg_process_fork_t process_fork;
+		guestlog_msg_process_exec_t process_exec;
+		guestlog_msg_process_exit_t process_exit;
+		guestlog_msg_driver_load_t driver_load;
+	};
+} __attribute__((__packed__)) guestlog_msg_t;
+
+#define BHV_GUESTLOG_CONFIG_LOG_PROCESS_EVENTS 0
+#define BHV_GUESTLOG_CONFIG_LOG_DRIVER_EVENTS 1
+
+typedef struct {
+	uint64_t log_bitmap;
+	uint32_t cid;
+	uint32_t port;
+	uint8_t valid;
+} __attribute__((__packed__)) bhv_guestlog_config_t;
+
+#endif /* __BHV_INTERFACE_GUESTLOG_H__ */
\ No newline at end of file
diff --git include/bhv/interface/hypercall.h include/bhv/interface/hypercall.h
new file mode 100644
index 000000000000..d9c92066f040
--- /dev/null
+++ include/bhv/interface/hypercall.h
@@ -0,0 +1,39 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Sergej Proskurin <sergej@bedrocksystems.com>
+ *          Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#ifndef _ASM_INTERFACE_BHV_HYPERCALL_H
+#define _ASM_INTERFACE_BHV_HYPERCALL_H
+
+#include <linux/kernel.h>
+#include <asm/bhv/hypercall.h>
+#include <asm/io.h>
+
+#include <bhv/interface/common.h>
+
+static __always_inline unsigned long bhv_hypercall_vas(uint32_t backend,
+						       uint32_t op, void *arg)
+{
+	unsigned long rv;
+	uint64_t phys_addr = BHV_INVALID_PHYS_ADDR;
+
+	if (arg != NULL)
+		phys_addr = virt_to_phys(arg);
+
+	rv = BHV_HYPERCALL(TARGET_BHV_VAS, backend, op, BHV_VAS_ABI_VERSION,
+			   phys_addr);
+#ifdef CONFIG_BHV_PANIC_ON_FAIL
+	if (rv) {
+		panic("BHV Hypercall failure! hypercall returned %lu (%u %u %u %x %p %llx)",
+		      rv, TARGET_BHV_VAS, backend, op, BHV_VAS_ABI_VERSION, arg,
+		      phys_addr);
+	}
+#endif /* CONFIG_BHV_PANIC_ON_FAIL */
+
+	return rv;
+}
+
+#endif /* _ASM_INTERFACE_BHV_HYPERCALL_H */
diff --git include/bhv/interface/init.h include/bhv/interface/init.h
new file mode 100644
index 000000000000..caad23f68bc3
--- /dev/null
+++ include/bhv/interface/init.h
@@ -0,0 +1,28 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ *	    Sergej Proskurin <sergej@bedrocksystems.com>
+ */
+
+#ifndef __BHV_INTERFACE_INIT_H__
+#define __BHV_INTERFACE_INIT_H__
+
+/* BHV VAS INIT BACKEND OPS */
+#define BHV_VAS_INIT_OP_INIT 0
+#define BHV_VAS_INIT_OP_START 1
+
+typedef struct {
+	uint64_t bhv_data_start;
+	uint64_t bhv_data_size;
+	uint64_t bhv_text_start;
+	uint64_t bhv_text_size;
+	uint64_t owner;
+	uint64_t region_head;
+} __attribute__((__packed__)) bhv_init_init_arg_t;
+
+typedef struct {
+	bhv_init_init_arg_t bhv_init_init_arg;
+} __attribute__((__packed__)) bhv_init_arg_t;
+
+#endif /* __BHV_INTERFACE_INIT_H__ */
diff --git include/bhv/interface/integrity.h include/bhv/interface/integrity.h
new file mode 100644
index 000000000000..d7ddf79d1790
--- /dev/null
+++ include/bhv/interface/integrity.h
@@ -0,0 +1,93 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ *          Sergej Proskurin <sergej@bedrocksystems.com>
+ */
+
+#ifndef __BHV_INTERFACE_INTEGRITY_H__
+#define __BHV_INTERFACE_INTEGRITY_H__
+
+#include <linux/slab.h>
+
+#define BHV_MEM_TYPE_UNKNOWN			0U
+#define BHV_MEM_TYPE_CODE			1U
+#define BHV_MEM_TYPE_CODE_WRITABLE		2U
+#define BHV_MEM_TYPE_CODE_PATCHABLE		3U
+#define BHV_MEM_TYPE_DATA			4U
+#define BHV_MEM_TYPE_DATA_READ_ONLY		5U
+
+#define BHV_MEM_FLAGS_NONE			0UL
+#define BHV_MEM_FLAGS_TRANSIENT		(1UL << 0)
+#define BHV_MEM_FLAGS_MUTABLE		(1UL << 1)
+
+/* BHV VAS INTEGRITY BACKEND OPS */
+#define BHV_VAS_INTEGRITY_OP_CREATE_PHYS	0U
+#define BHV_VAS_INTEGRITY_OP_UPDATE_PHYS	1U
+#define BHV_VAS_INTEGRITY_OP_REMOVE_PHYS	2U
+#define BHV_VAS_INTEGRITY_OP_DISABLE		3U
+
+/*********************************************
+ * BHV memory region definitions
+ ********************************************/
+
+typedef struct {
+	uint64_t start_addr;
+	uint64_t size;
+	uint32_t type;
+	uint32_t pad;
+	uint64_t flags;
+	uint64_t next;
+} __attribute__((__packed__)) bhv_mem_region_create_t;
+
+typedef struct {
+	uint64_t start_addr;
+	uint32_t type;
+	uint32_t pad;
+	uint64_t flags;
+	uint64_t next;
+} __attribute__((__packed__)) bhv_mem_region_update_t;
+
+typedef struct {
+	uint64_t start_addr;
+	uint64_t next;
+} __attribute__((__packed__)) bhv_mem_region_remove_t;
+
+typedef struct {
+	union {
+		bhv_mem_region_create_t bhv_mem_region_create;
+		bhv_mem_region_update_t bhv_mem_region_update;
+		bhv_mem_region_remove_t bhv_mem_region_remove;
+	};
+} __attribute__((__packed__)) bhv_mem_region_t;
+
+/*********************************************
+ * BHV arg definitions
+ ********************************************/
+
+typedef struct {
+	uint64_t owner;
+	uint64_t region_head;
+} __attribute__((__packed__)) bhv_integrity_create_arg_t;
+
+typedef struct {
+	uint64_t region_head;
+} __attribute__((__packed__)) bhv_integrity_update_arg_t;
+
+typedef struct {
+	uint64_t rm_by_owner;
+	union {
+		uint64_t owner;
+		uint64_t region_head;
+	};
+} __attribute__((__packed__)) bhv_integrity_remove_arg_t;
+
+typedef struct {
+	union {
+		bhv_integrity_create_arg_t bhv_integrity_create_arg;
+		bhv_integrity_update_arg_t bhv_integrity_update_arg;
+		bhv_integrity_remove_arg_t bhv_integrity_remove_arg;
+	};
+} __attribute__((__packed__)) bhv_integrity_arg_t;
+
+#endif /* __BHV_INTERFACE_INTEGRITY_H__ */
diff --git include/bhv/interface/patch.h include/bhv/interface/patch.h
new file mode 100644
index 000000000000..9c5db60d5ecd
--- /dev/null
+++ include/bhv/interface/patch.h
@@ -0,0 +1,37 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ *          Sebastian Vogl <sebastian@bedrocksystems.com>
+ */
+
+#ifndef __BHV_INTERFACE_PATCH_H__
+#define __BHV_INTERFACE_PATCH_H__
+
+#include <linux/types.h>
+
+/* BHV VAS PATCH BACKEND OPS */
+#define BHV_VAS_PATCH_OP_PATCH 0
+#define BHV_VAS_PATCH_OP_PATCH_NO_CLOSE 1
+
+#if defined(CONFIG_ARM64)
+#define BHV_MAX_INSN_SZ 4
+#elif defined(CONFIG_X86)
+#define BHV_MAX_INSN_SZ 15
+#else
+#define BHV_MAX_INSN_SZ 0
+#endif
+
+typedef struct {
+	uint64_t dest_phys_addr;
+	uint8_t src_value[BHV_MAX_INSN_SZ];
+	uint64_t size;
+} __attribute__((__packed__)) bhv_patch_patch_arg_t;
+
+typedef struct {
+	union {
+		bhv_patch_patch_arg_t bhv_patch_patch_arg;
+	};
+} __attribute__((__packed__)) bhv_patch_arg_t;
+
+#endif /* __BHV_INTERFACE_PATCH_H__ */
diff --git include/bhv/interface/vault.h include/bhv/interface/vault.h
new file mode 100644
index 000000000000..075752c19838
--- /dev/null
+++ include/bhv/interface/vault.h
@@ -0,0 +1,14 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#ifndef __BHV_INTERFACE_VAULT_H__
+#define __BHV_INTERFACE_VAULT_H__
+
+/* BHV VAS VAULT BACKEND OPS */
+#define BHV_VAS_VAULT_OP_OPEN	0
+#define BHV_VAS_VAULT_OP_CLOSE	1
+
+#endif /* __BHV_INTERFACE_VAULT_H__ */
diff --git include/bhv/module.h include/bhv/module.h
new file mode 100644
index 000000000000..6a099f891013
--- /dev/null
+++ include/bhv/module.h
@@ -0,0 +1,47 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Sergej Proskurin <sergej@bedrocksystems.com>
+ *          Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#ifndef __BHV_MODULE_H__
+#define __BHV_MODULE_H__
+
+#ifdef CONFIG_BHV_VAS
+void bhv_module_load_prepare(const struct module *mod);
+void bhv_module_load_complete(const struct module *mod);
+void bhv_module_unload(const struct module *mod);
+
+void bhv_bpf_protect_ro(const void *base, uint64_t size);
+void bhv_bpf_protect_x(const void *base, uint64_t size);
+void bhv_bpf_unprotect(const void *base);
+#else /* CONFIG_BHV_VAS */
+
+static inline void bhv_module_load_prepare(const struct module *mod)
+{
+}
+
+static inline void bhv_module_load_complete(const struct module *mod)
+{
+}
+
+static inline void bhv_module_unload(const struct module *mod)
+{
+}
+
+static inline void bhv_bpf_protect_ro(const void *base, uint64_t size)
+{
+}
+
+static inline void bhv_bpf_protect_x(const void *base, uint64_t size)
+{
+}
+
+static inline void bhv_bpf_unprotect(const void *base)
+{
+}
+
+#endif /* CONFIG_BHV_VAS */
+
+#endif /* __BHV_MODULE_H__ */
diff --git include/bhv/patch.h include/bhv/patch.h
new file mode 100644
index 000000000000..4e0db069c9e0
--- /dev/null
+++ include/bhv/patch.h
@@ -0,0 +1,77 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ *          Sebastian Vogl <sebastian@bedrocksystems.com>
+ */
+
+#ifndef __BHV_PATCH_H__
+#define __BHV_PATCH_H__
+
+#include <linux/slab.h>
+#include <linux/jump_label.h>
+#include <linux/module.h>
+
+#include <asm/bhv/patch.h>
+
+#ifdef CONFIG_BHV_VAS
+
+#ifdef CONFIG_JUMP_LABEL
+int bhv_patch_jump_label(struct jump_entry *entry, const void *opcode,
+			 size_t len);
+int bhv_jump_label_add_module(struct module *mod);
+void bhv_jump_label_del_module(struct module *mod);
+#endif /* CONFIG_JUMP_LABEL */
+
+enum bhv_alternatives_mod_delete_policy {
+	BHV_ALTERNATIVES_DELETE_AFTER_PATCH = 0,
+	BHV_ALTERNATIVES_DELETE_AFTER_INIT,
+};
+
+struct bhv_alternatives_mod {
+	struct alt_instr *begin;
+	struct alt_instr *end;
+	enum bhv_alternatives_mod_delete_policy delete_policy;
+	bool allocated;
+	struct bhv_alternatives_mod_arch arch;
+	struct list_head next;
+};
+
+typedef bool (*bhv_alternatives_filter_t)(void *search_params,
+					  struct bhv_alternatives_mod *cur);
+
+int bhv_alternatives_apply(struct alt_instr *begin, struct alt_instr *end,
+			   void *arch);
+int bhv_alternatives_apply_custom_filter(void *search_param, void *arch,
+					 bhv_alternatives_filter_t filter);
+void bhv_alternatives_add_module(struct alt_instr *begin, struct alt_instr *end,
+				 struct bhv_alternatives_mod_arch *arch);
+void bhv_alternatives_delete_after_init(void);
+#else /* CONFIG_BHV_VAS */
+
+#ifdef CONFIG_JUMP_LABEL
+static inline int bhv_patch_jump_label(struct jump_entry *entry,
+				       const void *opcode, size_t len)
+{
+	return 0;
+}
+
+static inline int bhv_jump_label_add_module(struct module *mod)
+{
+	return 0;
+}
+
+static inline void bhv_jump_label_del_module(struct module *mod)
+{
+}
+#endif /* CONFIG_JUMP_LABEL */
+
+static inline void
+bhv_alternatives_add_module(struct alt_instr *begin, struct alt_instr *end,
+			    struct bhv_alternatives_mod_arch *arch)
+{
+}
+
+#endif /* CONFIG_BHV_VAS */
+
+#endif /* __BHV_PATCH_H__ */
diff --git include/bhv/start.h include/bhv/start.h
new file mode 100644
index 000000000000..67c90a54cd3e
--- /dev/null
+++ include/bhv/start.h
@@ -0,0 +1,27 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#ifndef __BHV_START_H__
+#define __BHV_START_H__
+
+#ifdef CONFIG_BHV_VAS
+void __init bhv_init_platform(void);
+void bhv_start(void);
+int bhv_start_arch(void);
+#else /* CONFIG_BHV_VAS */
+static inline void bhv_init_platform(void)
+{
+}
+static inline void bhv_start(void)
+{
+}
+static inline int bhv_start_arch(void)
+{
+	return 0;
+}
+#endif /* CONFIG_BHV_VAS */
+
+#endif /* __BHV_START_H__ */
\ No newline at end of file
diff --git include/bhv/vault.h include/bhv/vault.h
new file mode 100644
index 000000000000..902647976c5b
--- /dev/null
+++ include/bhv/vault.h
@@ -0,0 +1,43 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#ifndef __BHV_VAULT_H__
+#define __BHV_VAULT_H__
+
+#ifdef CONFIG_BHV_VAS
+#include <bhv/interface/common.h>
+#include <bhv/interface/hypercall.h>
+#include <bhv/interface/vault.h>
+#include <bhv/bhv.h>
+
+static __always_inline int bhv_vault_open_hyp(void)
+{
+	unsigned long r = bhv_hypercall_vas(BHV_VAS_BACKEND_VAULT,
+					    BHV_VAS_VAULT_OP_OPEN, NULL);
+	if (r)
+		return -EINVAL;
+
+	return 0;
+}
+
+static __always_inline void bhv_vault_close_hyp(void)
+{
+	unsigned long r = bhv_hypercall_vas(BHV_VAS_BACKEND_VAULT,
+					    BHV_VAS_VAULT_OP_CLOSE, NULL);
+	if (r)
+		panic("BHV vault close failure! hypercall returned %lu", r);
+}
+#else /* CONFIG_BHV_VAS */
+static inline int bhv_vault_open_hyp(void)
+{
+}
+
+static inline void bhv_vault_close_hyp(void)
+{
+}
+#endif /* CONFIG_BHV_VAS */
+
+#endif /* __BHV_VAULT_H__ */
diff --git include/linux/filter.h include/linux/filter.h
index 822b701c803d..c41d12d0b782 100644
--- include/linux/filter.h
+++ include/linux/filter.h
@@ -29,6 +29,8 @@
 #include <uapi/linux/filter.h>
 #include <uapi/linux/bpf.h>
 
+#include <bhv/module.h>
+
 struct sk_buff;
 struct sock;
 struct seccomp_data;
@@ -829,6 +831,7 @@ static inline void bpf_prog_lock_ro(struct bpf_prog *fp)
 	if (!fp->jited) {
 		set_vm_flush_reset_perms(fp);
 		set_memory_ro((unsigned long)fp, fp->pages);
+		bhv_bpf_protect_ro(fp, fp->pages << PAGE_SHIFT);
 	}
 #endif
 }
@@ -838,6 +841,7 @@ static inline void bpf_jit_binary_lock_ro(struct bpf_binary_header *hdr)
 	set_vm_flush_reset_perms(hdr);
 	set_memory_ro((unsigned long)hdr, hdr->pages);
 	set_memory_x((unsigned long)hdr, hdr->pages);
+	bhv_bpf_protect_x(hdr, hdr->pages << PAGE_SHIFT);
 }
 
 static inline struct bpf_binary_header *
@@ -875,6 +879,9 @@ void __bpf_prog_free(struct bpf_prog *fp);
 
 static inline void bpf_prog_unlock_free(struct bpf_prog *fp)
 {
+	if (!fp->jited)
+		bhv_bpf_unprotect(fp);
+
 	__bpf_prog_free(fp);
 }
 
diff --git init/main.c init/main.c
index dd26a42e80a8..1118ef396f66 100644
--- init/main.c
+++ init/main.c
@@ -110,6 +110,9 @@
 
 #include <kunit/test.h>
 
+#include <bhv/bhv.h>
+#include <bhv/start.h>
+
 static int kernel_init(void *);
 
 extern void init_IRQ(void);
@@ -838,6 +841,8 @@ static void __init mm_init(void)
 	init_espfix_bsp();
 	/* Should be run after espfix64 is set up. */
 	pti_init();
+
+	bhv_mm_init();
 }
 
 void __init __weak arch_call_rest_init(void)
diff --git kernel/Makefile kernel/Makefile
index e7905bdf6e97..4c4454e8806a 100644
--- kernel/Makefile
+++ kernel/Makefile
@@ -47,6 +47,7 @@ obj-y += rcu/
 obj-y += livepatch/
 obj-y += dma/
 obj-y += entry/
+obj-y += bhv/
 
 obj-$(CONFIG_KCMP) += kcmp.o
 obj-$(CONFIG_FREEZER) += freezer.o
diff --git kernel/bhv/Kconfig kernel/bhv/Kconfig
new file mode 100644
index 000000000000..efb414dc06a9
--- /dev/null
+++ kernel/bhv/Kconfig
@@ -0,0 +1,16 @@
+config BHV_PANIC_ON_FAIL
+	def_bool y
+	bool "BVH guest panics on Hypercall failure"
+	depends on BHV_VAS
+	help
+	  Say Y if you want the kernel to panic in the case a
+	  BRASS hypercall fails.  This will prevent the guest
+	  continuing execution if a security critical hypercall
+	  fails.
+
+config BHV_VAS_DEBUG
+	def_bool n
+	bool "Build BVH guest support with DEBUG information"
+	depends on BHV_VAS
+	help
+	  Say Y if you want to include DEBUG output when using BHV VAS.
diff --git kernel/bhv/Makefile kernel/bhv/Makefile
new file mode 100644
index 000000000000..4fa9b07d9f5f
--- /dev/null
+++ kernel/bhv/Makefile
@@ -0,0 +1,19 @@
+# SPDX-License-Identifier: GPL-2.0-only
+
+# Copyright (C) 2022 - BedRock Systems Inc
+# Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+#          Sergej Proskurin <sergej@bedrocksystems.com>
+#          Sebastian Vogl <sebastian@bedrocksystems.com>
+
+obj-$(CONFIG_BHV_VAS)		:= bhv.o
+obj-$(CONFIG_BHV_VAS)		+= start.o
+obj-$(CONFIG_BHV_VAS)		+= init.o
+obj-$(CONFIG_BHV_VAS)		+= integrity.o
+ifeq ($(CONFIG_JUMP_LABEL),y)
+obj-$(CONFIG_BHV_VAS)		+= patch_jump_label.o
+endif
+obj-$(CONFIG_BHV_VAS)		+= patch_alternative.o
+obj-$(CONFIG_BHV_VAS)		+= module.o
+obj-$(CONFIG_BHV_VAS)		+= acl.o
+obj-$(CONFIG_BHV_VAS)		+= guestlog.o
+obj-$(CONFIG_BHV_VAS)		+= creds.o
diff --git kernel/bhv/acl.c kernel/bhv/acl.c
new file mode 100644
index 000000000000..8dc5e48b9931
--- /dev/null
+++ kernel/bhv/acl.c
@@ -0,0 +1,293 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Sebastian Vogl <sebastian@bedrocksystems.com>
+ *          Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#include <bhv/bhv_print.h>
+
+#include <linux/cache.h>
+#include <linux/gfp.h>
+#include <linux/limits.h>
+#include <linux/types.h>
+#include <linux/slab.h>
+
+#include <bhv/bhv.h>
+#include <bhv/interface/common.h>
+#include <bhv/interface/hypercall.h>
+#include <bhv/interface/acl.h>
+
+#include <bhv/interface/integrity.h>
+#include <bhv/integrity.h>
+
+#include <bhv/acl.h>
+
+#define PATH_DELIMITER '/'
+
+bhv_acl_config_t *process_acl_config __ro_after_init = NULL;
+bhv_acl_config_t *driver_acl_config __ro_after_init = NULL;
+
+struct kmem_cache *bhv_acl_violation_cache;
+
+static void __init bhv_acl_init_acl(uint32_t op, bhv_acl_config_t **global_acl_config)
+{
+	unsigned long r;
+	bhv_acl_config_t *acl_config;
+	static bhv_mem_region_t config_region;
+
+	bhv_acl_violation_cache = kmem_cache_create(
+		"bhv_acl_violation_cache", sizeof(bhv_acl_violation_t), 0,
+		SLAB_HWCACHE_ALIGN | SLAB_PANIC | SLAB_ACCOUNT, NULL);
+
+	acl_config = (bhv_acl_config_t *)__get_free_pages(GFP_KERNEL, 0);
+
+	if (acl_config == NULL) {
+		bhv_fail("Unable to allocate process acl config");
+		return;
+	}
+
+	acl_config->num_pages = 1;
+	r = bhv_hypercall_vas(BHV_VAS_BACKEND_ACL, op, acl_config);
+	if (r) {
+		pr_err("proc acl init fail");
+		return;
+	}
+
+	if (!acl_config->valid) {
+		free_pages((unsigned long)acl_config, 0);
+
+		acl_config =
+		(bhv_acl_config_t *)__get_free_pages(GFP_KERNEL, order_base_2(acl_config->num_pages));
+
+		if (acl_config == NULL) {
+			bhv_fail("Unable to allocate process acl config");
+			return;
+		}
+
+		r = bhv_hypercall_vas(BHV_VAS_BACKEND_ACL, op, acl_config);
+		if (r) {
+			pr_err("proc acl init fail");
+			return;
+		}
+
+		if (!acl_config->valid) {
+			bhv_fail("host returned invalid configuration");
+			return;
+		}
+	}
+
+	// Protect memory
+	if (bhv_integrity_is_enabled()) {
+		config_region.bhv_mem_region_create.start_addr =
+			virt_to_phys(acl_config);
+		config_region.bhv_mem_region_create.size =
+			acl_config->num_pages * PAGE_SIZE;
+		config_region.bhv_mem_region_create.type =
+			BHV_MEM_TYPE_DATA_READ_ONLY;
+		config_region.bhv_mem_region_create.flags = BHV_MEM_FLAGS_NONE;
+		config_region.bhv_mem_region_create.next =
+			BHV_INVALID_PHYS_ADDR;
+
+		r = bhv_create_kern_phys_mem_region_hyp(0, &config_region);
+		if (r) {
+			pr_err("Unable to protect acl config");
+			return;
+		}
+	}
+
+	*global_acl_config = acl_config;
+}
+
+void __init bhv_acl_mm_init(void)
+{
+	if (bhv_acl_is_proc_acl_enabled())
+		bhv_acl_init_acl(BHV_VAS_ACL_OP_INIT_PROC_ACL,
+				 &process_acl_config);
+	if (bhv_acl_is_driver_acl_enabled())
+		bhv_acl_init_acl(BHV_VAS_ACL_OP_INIT_DRIVER_ACL,
+				 &driver_acl_config);
+}
+
+static size_t _get_ext_len(const char *str)
+{
+	char *str_ext = strrchr(str, (int)'.');
+
+	if (str_ext == NULL)
+		return 0;
+
+	return strnlen(str_ext, PATH_MAX);
+}
+
+static bool _match_names(const char *cur, const char *target,
+			 size_t target_ext_len, bool strip_ext)
+{
+	// Get filename of path
+	const char *cur_tmp = strrchr(cur, (int)PATH_DELIMITER);
+	const char *target_tmp = strrchr(target, (int)PATH_DELIMITER);
+	size_t cur_tmp_len = 0;
+	size_t target_tmp_len = 0;
+
+	if (cur_tmp == NULL)
+		cur_tmp = cur;
+	else
+		cur_tmp++;
+
+	if (target_tmp == NULL)
+		target_tmp = target;
+	else
+		target_tmp++;
+
+	// Get length of filename
+	cur_tmp_len = strnlen(cur_tmp, PATH_MAX);
+	target_tmp_len = strnlen(target_tmp, PATH_MAX);
+
+	// Remove extension
+	if (strip_ext) {
+		cur_tmp_len -= _get_ext_len(cur_tmp);
+		target_tmp_len -= target_ext_len;
+	}
+
+	if (cur_tmp_len == 0 || cur_tmp_len >= PATH_MAX ||
+	    target_tmp_len == 0 || target_tmp_len >= PATH_MAX)
+		return false;
+
+	// Check if length matches
+	if (cur_tmp_len != target_tmp_len)
+		return false;
+
+	return strncmp(cur_tmp, target_tmp, cur_tmp_len) == 0;
+}
+
+static bool _matches(const char *target, bool strip_ext,
+		     bhv_acl_config_t *acl_config)
+{
+	size_t target_len = 0;
+	size_t target_ext_len = 0;
+	uint16_t i;
+
+	BUG_ON(target[0] != PATH_DELIMITER);
+
+	if (acl_config == NULL)
+		return false;
+
+	if (!acl_config->valid)
+		return false;
+
+	// Get target len
+	target_len = strnlen(target, PATH_MAX);
+	if (strip_ext) {
+		target_ext_len = _get_ext_len(target);
+		target_len -= target_ext_len;
+	}
+
+	if (target_len == 0 || target_len >= PATH_MAX)
+		return false;
+
+	for (i = 0; i < acl_config->list_len; i++) {
+		const char *cur = ((char *)acl_config) + acl_config->list[i];
+		size_t cur_len = 0;
+
+		if (cur[0] != PATH_DELIMITER) {
+			if (_match_names(cur, target, target_ext_len,
+					 strip_ext))
+				return true;
+			else
+				continue;
+		}
+
+		cur_len = strnlen(cur, PATH_MAX);
+		if (strip_ext) {
+			cur_len -= _get_ext_len(cur);
+		}
+
+		if (cur_len == 0 || cur_len >= PATH_MAX)
+			continue;
+
+		if (cur[cur_len - 1] == '*') {
+			cur_len--;
+
+			if (target_len < cur_len)
+				continue;
+		} else if (target_len != cur_len)
+			continue;
+
+		if (strncmp(cur, target, cur_len) == 0)
+			return true;
+	}
+
+	return false;
+}
+
+static bool _block_entity(const char *target, bool strip_ext,
+			  bhv_acl_config_t *acl_config, uint32_t op)
+{
+	bool rv;
+	unsigned long r;
+	// Tell the compiler this points to volatile data as the hypercall
+	// will update it.
+	bhv_acl_violation_t *volatile acl_violation = NULL;
+	size_t target_len = strlen(target);
+	bool m = _matches(target, strip_ext, acl_config);
+
+	// Is this entity part of the allow list?
+	if (acl_config->is_allow && m)
+		return false;
+	// Is this entity _NOT_ in the deny list?
+	else if (!acl_config->is_allow && !m)
+		return false;
+
+	BUG_ON(target_len >= PAGE_SIZE);
+
+	// Prepare hypercall
+	acl_violation = kmem_cache_alloc(bhv_acl_violation_cache, GFP_KERNEL);
+	if (acl_violation == NULL) {
+		bhv_fail("Unable to allocate acl violation");
+		return true;
+	}
+
+	// Setup arg
+	acl_violation->name_len = target_len;
+	acl_violation->name = virt_to_phys((volatile void *)target);
+
+	// Hypercall
+	r = bhv_hypercall_vas(BHV_VAS_BACKEND_ACL, op, acl_violation);
+	if (r) {
+		pr_err("entity hypercall failed");
+		kmem_cache_free(bhv_acl_violation_cache, acl_violation);
+		return true;
+	}
+
+	// Read block and free
+	rv = (bool)acl_violation->block;
+	kmem_cache_free(bhv_acl_violation_cache, acl_violation);
+	return rv;
+}
+
+bool bhv_block_driver(const char *target)
+{
+	if (!bhv_acl_is_driver_acl_enabled())
+		return false;
+
+	if (target == NULL) {
+		// Unknown filename. For example, init_module call. => BLOCK
+		return true;
+	}
+
+	return _block_entity(target, true, driver_acl_config,
+			     BHV_VAS_ACL_OP_VIOLATION_DRIVER_ACL);
+}
+
+bool bhv_block_process(const char *target)
+{
+	if (!bhv_acl_is_proc_acl_enabled())
+		return false;
+
+	if (target == NULL) {
+		// Unknown filename => BLOCK
+		return true;
+	}
+
+	return _block_entity(target, false, process_acl_config,
+			     BHV_VAS_ACL_OP_VIOLATION_PROC_ACL);
+}
\ No newline at end of file
diff --git kernel/bhv/bhv.c kernel/bhv/bhv.c
new file mode 100644
index 000000000000..07652cf56598
--- /dev/null
+++ kernel/bhv/bhv.c
@@ -0,0 +1,24 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#include <bhv/acl.h>
+#include <bhv/creds.h>
+#include <bhv/integrity.h>
+#include <bhv/guestlog.h>
+#include <bhv/patch.h>
+
+#include <bhv/bhv.h>
+
+bool bhv_initialized __ro_after_init = false;
+unsigned long *bhv_configuration_bitmap __ro_after_init = NULL;
+
+void __init bhv_mm_init(void)
+{
+	bhv_integrity_mm_init();
+	bhv_acl_mm_init();
+	bhv_guestlog_init();
+	bhv_cred_mm_init();
+}
diff --git kernel/bhv/creds.c kernel/bhv/creds.c
new file mode 100644
index 000000000000..fae31bddbe65
--- /dev/null
+++ kernel/bhv/creds.c
@@ -0,0 +1,407 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors:  Sergej Proskurin <sergej@bedrocksystems.com> 
+ */
+
+#include <linux/init_task.h>
+#include <linux/printk.h>
+#include <linux/sched.h>
+#include <linux/siphash.h>
+#include <linux/slab.h>
+#include <linux/types.h>
+
+#include <bhv/bhv.h>
+#include <bhv/creds.h>
+#include <bhv/interface/common.h>
+#include <bhv/interface/creds.h>
+#include <bhv/interface/hypercall.h>
+
+#define BHV_CREDS_HYP(op, arg) bhv_hypercall_vas(BHV_VAS_BACKEND_CREDS, op, arg)
+
+#define BHV_CREDS_CONFIGURE_HYP(arg)                                           \
+	BHV_CREDS_HYP(BHV_VAS_CREDS_OP_CONFIGURE, arg)
+#define BHV_CREDS_REGISTER_INIT_TASK_HYP(arg)                                  \
+	BHV_CREDS_HYP(BHV_VAS_CREDS_OP_REGISTER_INIT_TASK, arg)
+#define BHV_CREDS_ASSIGN_HYP(arg) BHV_CREDS_HYP(BHV_VAS_CREDS_OP_ASSIGN, arg)
+#define BHV_CREDS_ASSIGN_PRIV_HYP(arg)                                         \
+	BHV_CREDS_HYP(BHV_VAS_CREDS_OP_ASSIGN_PRIV, arg)
+#define BHV_CREDS_COMMIT_HYP(arg) BHV_CREDS_HYP(BHV_VAS_CREDS_OP_COMMIT, arg)
+#define BHV_CREDS_RELEASE_HYP(arg) BHV_CREDS_HYP(BHV_VAS_CREDS_OP_RELEASE, arg)
+#define BHV_CREDS_VERIFY_HYP(arg)                                              \
+	BHV_CREDS_HYP(BHV_VAS_CREDS_OP_VERIFICATION, arg)
+#define BHV_CREDS_LOG_HYP(arg) BHV_CREDS_HYP(BHV_VAS_CREDS_OP_LOG, arg)
+
+struct kmem_cache *bhv_creds_arg_cache = NULL;
+
+static siphash_key_t bhv_siphash_key __ro_after_init = { 0 };
+
+static size_t collect_cred_invariants(char *buf, const struct cred *c,
+				      const struct task_struct *context,
+				      size_t max_size)
+{
+	char *_buf = NULL;
+	uint64_t bound_context = 0;
+	struct cred cred_copy;
+
+	static const size_t buf_size = sizeof(uint64_t) + sizeof(struct cred);
+
+	BUG_ON(!buf && max_size < buf_size);
+
+	_buf = buf;
+
+	memcpy(&cred_copy, c, sizeof(struct cred));
+
+	/* Exclude mutable fields from the credentials to be hashed. */
+
+	atomic_set(&cred_copy.usage, 0);
+#ifdef CONFIG_DEBUG_CREDENTIALS
+	atomic_set(&cred_copy.subscribers, 0);
+	cred_copy.put_addr = 0,
+#endif
+	memset(&cred_copy.rcu, 0, sizeof(struct rcu_head));
+
+	/*
+	 * Bind the credentials to the given context; incorporate this
+	 * information into the hash.
+	 */
+
+	bound_context = (uint64_t)c ^ (uint64_t)context;
+
+	_buf = memcpy(_buf, &bound_context, sizeof(uint64_t));
+	_buf += sizeof(uint64_t);
+
+	_buf = memcpy(_buf, &cred_copy, sizeof(struct cred));
+
+	return buf_size;
+}
+
+static uint64_t siphash_cred_context(const struct cred *const c,
+				     const struct task_struct *const context)
+{
+#define MAX_BUF_SIZE sizeof(struct cred) + sizeof(uint64_t)
+	char buf[MAX_BUF_SIZE];
+	size_t size = collect_cred_invariants(buf, c, context, MAX_BUF_SIZE);
+	return siphash(&buf, size, &bhv_siphash_key);
+}
+
+int bhv_cred_assign(struct task_struct *t, uint64_t clone_flags)
+{
+	int rc = 0;
+	uint64_t hmac = 0;
+	bhv_creds_arg_t *arg = NULL;
+	struct task_struct *parent = NULL;
+	enum event_type type = EVENT_NONE;
+
+	if (!bhv_cred_is_enabled())
+		return 0;
+
+	arg = kmem_cache_alloc(bhv_creds_arg_cache, GFP_KERNEL);
+
+	if (arg == NULL) {
+		return -ENOMEM;
+	}
+
+	/*
+	 * Note that we verify the integrity of the currently active process,
+	 * instead of the "real_parent" of the to be assigned credentials.
+	 * Consider verifying the real_parent of the task as well.
+	 */
+	rc = bhv_cred_verify(current);
+	if (rc)
+		return -EPERM;
+
+	if (clone_flags & (CLONE_THREAD | CLONE_PARENT))
+		parent = current->real_parent;
+	else
+		parent = current;
+
+	hmac = siphash_cred_context(t->cred, t);
+
+	arg->creds_assign.new_task.addr = (uint64_t)t;
+	arg->creds_assign.new_task.cred = (uint64_t)t->cred;
+	arg->creds_assign.new_task.hmac = hmac;
+	arg->creds_assign.parent.addr = (uint64_t)parent;
+	arg->creds_assign.parent.cred = (uint64_t)parent->cred;
+
+	rc = BHV_CREDS_ASSIGN_HYP(arg);
+	if (rc) {
+		pr_err("%s: BHV cannot assign credentials @ 0x%llx to task @ 0x%llx (pid=%d)",
+		       __FUNCTION__, (uint64_t)t->cred, (uint64_t)parent,
+		       parent->pid);
+		rc = -EINVAL;
+	}
+
+	type = arg->creds_assign.ret;
+
+	if (!rc && type != EVENT_NONE) {
+		/* Note that we currently log only the parent's information. */
+		arg->creds_log.event_type = type;
+		arg->creds_log.task_addr = (uint64_t)parent;
+		arg->creds_log.task_cred = (uint64_t)parent->cred;
+		arg->creds_log.task_pid = parent->pid;
+		strscpy(arg->creds_log.task_name, parent->comm, TASK_COMM_LEN);
+
+		rc = BHV_CREDS_LOG_HYP(arg);
+		if (rc) {
+			pr_err("%s: BHV Cannot log event with type=%d",
+			       __FUNCTION__, type);
+		}
+
+		/* Check if the policy is configured to be blocking. */
+		if (arg->creds_log.block) {
+			rc = -EPERM;
+		}
+	}
+
+	kmem_cache_free(bhv_creds_arg_cache, arg);
+
+	return rc;
+}
+
+int bhv_cred_assign_priv(struct cred *c, struct task_struct *daemon)
+{
+	int rc = 0;
+	bhv_creds_arg_t *arg = NULL;
+	enum event_type type = EVENT_NONE;
+
+	if (!bhv_cred_is_enabled())
+		return 0;
+
+	arg = kmem_cache_alloc(bhv_creds_arg_cache, GFP_KERNEL);
+	if (arg == NULL) {
+		return -ENOMEM;
+	}
+
+	/* XXX: Do we need to compute an (incomplete) hmac? */
+
+	arg->creds_assign_priv.cred = (uint64_t)c;
+	arg->creds_assign_priv.daemon = (uint64_t)daemon;
+
+	rc = BHV_CREDS_ASSIGN_PRIV_HYP(arg);
+	if (rc) {
+		pr_err("%s: BHV cannot prepare priv credentials @ 0x%llx (daemon @ 0x%llx)",
+		       __FUNCTION__, (uint64_t)c, (uint64_t)daemon);
+		rc = -EINVAL;
+	}
+
+	type = arg->creds_assign_priv.ret;
+
+	if (!rc && type != EVENT_NONE) {
+		arg->creds_log.event_type = type;
+		arg->creds_log.task_addr = (uint64_t)current;
+		arg->creds_log.task_cred = (uint64_t)c;
+		arg->creds_log.task_pid = current->pid;
+		strscpy(arg->creds_log.task_name, current->comm, TASK_COMM_LEN);
+
+		rc = BHV_CREDS_LOG_HYP(arg);
+		if (rc) {
+			pr_err("%s: BHV Cannot log event with type=%d",
+			       __FUNCTION__, type);
+		}
+
+		/* Check if the policy is configured to be blocking. */
+		if (arg->creds_log.block) {
+			rc = -EPERM;
+		}
+	}
+
+	kmem_cache_free(bhv_creds_arg_cache, arg);
+
+	return rc;
+}
+
+void bhv_cred_commit(struct cred *c)
+{
+	int rc = 0;
+	uint64_t hmac = 0;
+	bhv_creds_arg_t *arg = NULL;
+	enum event_type type = EVENT_NONE;
+
+	if (!bhv_cred_is_enabled())
+		return;
+
+	arg = kmem_cache_alloc(bhv_creds_arg_cache, GFP_KERNEL);
+	if (arg == NULL) {
+		return;
+	}
+
+	hmac = siphash_cred_context(c, current);
+
+	arg->creds_commit.cur.cred = (uint64_t)c;
+	arg->creds_commit.cur.addr = (uint64_t)current;
+	arg->creds_commit.cur.hmac = hmac;
+
+	rc = BHV_CREDS_COMMIT_HYP(arg);
+	if (rc) {
+		pr_err("%s: BHV cannot commit credentials @ 0x%llx to current @ 0x%llx",
+		       __FUNCTION__, (uint64_t)c, (uint64_t)current);
+	}
+
+	type = arg->creds_commit.ret;
+
+	if (!rc && type != EVENT_NONE) {
+		arg->creds_log.event_type = type;
+		arg->creds_log.task_addr = (uint64_t)current;
+		arg->creds_log.task_cred = (uint64_t)c;
+		arg->creds_log.task_pid = current->pid;
+		strscpy(arg->creds_log.task_name, current->comm, TASK_COMM_LEN);
+
+		rc = BHV_CREDS_LOG_HYP(arg);
+		if (rc) {
+			pr_err("%s: BHV Cannot log event with type=%d",
+			       __FUNCTION__, type);
+		}
+
+		/*
+		 * Note that we cannot block this function, yet, the corrupted
+		 * credentials will be identified on the next verification
+		 * point.
+		 */
+	}
+
+	kmem_cache_free(bhv_creds_arg_cache, arg);
+}
+
+int bhv_cred_verify(struct task_struct *t)
+{
+	int rc = 0;
+	uint64_t hmac = 0;
+	bhv_creds_arg_t *arg = NULL;
+	enum event_type type = EVENT_NONE;
+
+	if (!bhv_cred_is_enabled())
+		return 0;
+
+	arg = kmem_cache_alloc(bhv_creds_arg_cache, GFP_KERNEL);
+	if (arg == NULL) {
+		return -ENOMEM;
+	}
+
+	hmac = siphash_cred_context(t->cred, t);
+
+	arg->creds_verify.task.cred = (uint64_t)t->cred;
+	arg->creds_verify.task.addr = (uint64_t)t;
+	arg->creds_verify.task.hmac = hmac;
+
+	rc = BHV_CREDS_VERIFY_HYP(arg);
+	if (rc) {
+		pr_err("%s: BHV cannot verify credentials @ 0x%llx of task @ 0x%llx",
+		       __FUNCTION__, (uint64_t)t->cred, (uint64_t)t);
+		rc = -EINVAL;
+	}
+
+	type = arg->creds_verify.ret;
+
+	if (!rc && type != EVENT_NONE) {
+		arg->creds_log.event_type = type;
+		arg->creds_log.task_addr = (uint64_t)t;
+		arg->creds_log.task_cred = (uint64_t)t->cred;
+		arg->creds_log.task_pid = current->pid;
+		strscpy(arg->creds_log.task_name, t->comm, TASK_COMM_LEN);
+
+		rc = BHV_CREDS_LOG_HYP(arg);
+		if (rc) {
+			pr_err("%s: BHV Cannot log event with type=%d",
+			       __FUNCTION__, type);
+		}
+
+		/* Check if the policy is configured to be blocking. */
+		if (arg->creds_log.block) {
+			rc = -EPERM;
+		}
+	}
+
+	kmem_cache_free(bhv_creds_arg_cache, arg);
+
+	return rc;
+}
+
+void bhv_cred_release(struct cred *c)
+{
+	int rc = 0;
+	bhv_creds_arg_t *arg = NULL;
+
+	if (!bhv_cred_is_enabled())
+		return;
+
+	arg = kmem_cache_alloc(bhv_creds_arg_cache, GFP_KERNEL);
+	if (arg == NULL) {
+		return;
+	}
+
+	/*
+	 * XXX: Find a way to better integrate BHV into the RCU mechanism in
+	 * order to batch multpile credentials to be released and hence to avoid
+	 * unnecessary hypercalls.
+	 */
+
+	arg->creds_release.cred = (uint64_t)c;
+
+	rc = BHV_CREDS_RELEASE_HYP(arg);
+	if (rc) {
+		pr_err("%s: BHV cannot release credentials @ 0x%llx",
+		       __FUNCTION__, (uint64_t)c);
+	}
+
+	kmem_cache_free(bhv_creds_arg_cache, arg);
+}
+
+static void __init bhv_cred_register_init_task(struct cred *const c,
+					       struct task_struct *const t)
+{
+	int rc = 0;
+	bhv_creds_arg_t *arg = NULL;
+
+	if (!bhv_cred_is_enabled())
+		return;
+
+	arg = kmem_cache_alloc(bhv_creds_arg_cache, GFP_KERNEL);
+	if (arg == NULL) {
+		return;
+	}
+
+	arg->creds_register.init_task.addr = (uint64_t)t;
+	arg->creds_register.init_task.cred = (uint64_t)c;
+	arg->creds_register.init_task.hmac = siphash_cred_context(c, t);
+
+	rc = BHV_CREDS_REGISTER_INIT_TASK_HYP(arg);
+	if (rc) {
+		pr_err("%s: BHV cannot register init_task @ 0x%llx with cred @ 0x%llx",
+		       __FUNCTION__, (uint64_t)t, (uint64_t)c);
+	}
+
+	kmem_cache_free(bhv_creds_arg_cache, arg);
+}
+
+void __init bhv_cred_mm_init(void)
+{
+	if (!bhv_cred_is_enabled())
+		return;
+
+	bhv_creds_arg_cache = kmem_cache_create(
+		"bhv_creds_arg_cache", sizeof(bhv_creds_arg_t), 0,
+		SLAB_HWCACHE_ALIGN | SLAB_PANIC | SLAB_ACCOUNT, NULL);
+
+	bhv_cred_register_init_task(&init_cred, &init_task);
+}
+
+int __init bhv_cred_init(void)
+{
+	int rc = 0;
+
+	if (!bhv_cred_is_enabled())
+		return -EINVAL;
+	/*
+	 * Inform BRASS about the location of the siphash key. Note that this
+	 * step has to be done first and very early in the bootstrapping phase
+	 * so that we do not miss the instantiation of new credentials.
+	 */
+	rc = BHV_CREDS_CONFIGURE_HYP(&bhv_siphash_key);
+	if (rc) {
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
diff --git kernel/bhv/guestlog.c kernel/bhv/guestlog.c
new file mode 100644
index 000000000000..f80abf2bde67
--- /dev/null
+++ kernel/bhv/guestlog.c
@@ -0,0 +1,304 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ *          Sergej Proskurin <sergej@bedrocksystems.com>
+ *          Sebastian Vogl <sebastian@bedrocksystems.com>
+ */
+#include <linux/atomic.h>
+#include <linux/net.h>
+#include <linux/socket.h>
+#include <linux/types.h>
+#include <linux/reboot.h>
+#include <linux/workqueue.h>
+#include <linux/list.h>
+#include <linux/spinlock.h>
+#include <net/net_namespace.h>
+
+#include <net/vsock_addr.h>
+
+#include <bhv/bhv.h>
+
+#include <bhv/guestlog.h>
+#include <bhv/interface/hypercall.h>
+#include <bhv/interface/guestlog.h>
+
+typedef struct {
+	guestlog_msg_t msg;
+	size_t to_send;
+	struct list_head list;
+} bhv_guestlog_send_item_t;
+
+bhv_guestlog_config_t bhv_guestlog_config __ro_after_init = { false, 0 };
+static struct socket *vsock = NULL;
+
+static atomic_t workqueue_ready = ATOMIC_INIT(0);
+static LIST_HEAD(bhv_guestlog_msg_list);
+static DEFINE_SPINLOCK(bhv_guestlog_msg_lock);
+
+static struct workqueue_struct *bhv_guestlog_workqueue = NULL;
+static struct work_struct bhv_guestlog_work_struct;
+static struct delayed_work bhv_guestlog_delayed_work_struct;
+static struct kmem_cache *bhv_guestlog_send_item_cache;
+
+static inline size_t bhv_send(void *data, size_t size, size_t to_send)
+{
+	int r;
+	struct kvec vec;
+	struct msghdr msghdr = { .msg_flags = MSG_DONTWAIT };
+	while (to_send > 0) {
+		vec.iov_base = data + (size - to_send);
+		vec.iov_len = to_send;
+		r = kernel_sendmsg(vsock, &msghdr, &vec, 1, vec.iov_len);
+		if (r == -EAGAIN) {
+			return to_send;
+		} else if (r < 0) {
+			pr_err("BHV GuestLog: Send Failed (%d)", r);
+			return 0;
+		}
+		to_send -= r;
+	}
+	return 0;
+}
+
+static void bhv_guestlog_sendmsg(struct work_struct *ws)
+{
+	bhv_guestlog_send_item_t *item;
+
+	while (true) {
+		spin_lock(&bhv_guestlog_msg_lock);
+		if (list_empty(&bhv_guestlog_msg_list)) {
+			spin_unlock(&bhv_guestlog_msg_lock);
+			return;
+		}
+		item = list_first_entry(&bhv_guestlog_msg_list,
+					bhv_guestlog_send_item_t, list);
+		spin_unlock(&bhv_guestlog_msg_lock);
+
+		item->to_send = bhv_send(&item->msg, item->msg.header.sz,
+					 item->to_send);
+
+		if (item->to_send == 0) {
+			spin_lock(&bhv_guestlog_msg_lock);
+			list_del(&(item->list));
+			spin_unlock(&bhv_guestlog_msg_lock);
+			kmem_cache_free(bhv_guestlog_send_item_cache, item);
+		} else {
+			queue_delayed_work(bhv_guestlog_workqueue,
+					   &bhv_guestlog_delayed_work_struct,
+					   msecs_to_jiffies(1000));
+			return;
+		}
+	}
+}
+
+static inline int bhv_guestlog_send(guestlog_msg_t *msg)
+{
+	bhv_guestlog_send_item_t *cur;
+
+	pr_debug("BHV GuestLog: Queuing msg of type %u with size %u",
+		 msg->header.type, msg->header.sz);
+
+	cur = kmem_cache_alloc(bhv_guestlog_send_item_cache, GFP_KERNEL);
+	if (cur == NULL) {
+		bhv_fail("BHV: Unable to allocate send item");
+		return -ENOMEM;
+	}
+
+	memcpy(&cur->msg, msg, sizeof(cur->msg));
+	cur->to_send = msg->header.sz;
+
+	spin_lock(&bhv_guestlog_msg_lock);
+	list_add_tail(&(cur->list), &bhv_guestlog_msg_list);
+	spin_unlock(&bhv_guestlog_msg_lock);
+
+	if (atomic_read(&workqueue_ready))
+		queue_work(bhv_guestlog_workqueue, &bhv_guestlog_work_struct);
+
+	return 0;
+}
+
+int bhv_guestlog_log(char *fmt, ...)
+{
+	int len;
+	va_list args;
+	guestlog_msg_t msg;
+
+	// format string and set vector
+	va_start(args, fmt);
+	len = vscnprintf(msg.str.buf, MAX_MSG_DATA_SZ, fmt, args);
+	va_end(args);
+
+	// Setup msg
+	msg.header.type = BHV_GUESTLOG_MSG_TYPE_STR;
+	msg.header.sz = bhv_guestlog_calc_msg_sz(msg.header.type, len);
+
+	// Send
+	return bhv_guestlog_send(&msg);
+}
+
+int bhv_guestlog_log_process_fork(uint32_t child_pid, const char *child_comm,
+				  uint32_t parent_pid, const char *parent_comm)
+{
+	guestlog_msg_t msg;
+
+	// Setup msg
+	msg.header.type = BHV_GUESTLOG_MSG_TYPE_PROCESS_FORK;
+	msg.process_fork.child_pid = child_pid;
+	msg.process_fork.parent_pid = parent_pid;
+	msg.process_fork.child_comm_offset = 0;
+	strscpy(msg.process_fork.buf, child_comm, TASK_COMM_LEN);
+	msg.process_fork.parent_comm_offset =
+		strnlen(msg.process_fork.buf, TASK_COMM_LEN) + 1;
+	strscpy(&msg.process_fork.buf[msg.process_fork.parent_comm_offset],
+		parent_comm, TASK_COMM_LEN);
+	msg.header.sz = bhv_guestlog_calc_msg_sz(
+		msg.header.type,
+		msg.process_fork.parent_comm_offset +
+			strnlen(&msg.process_fork.buf
+					 [msg.process_fork.parent_comm_offset],
+				TASK_COMM_LEN) +
+			1);
+
+	// Send
+	return bhv_guestlog_send(&msg);
+}
+
+int bhv_guestlog_log_process_exec(uint32_t pid, uint32_t parent_pid,
+				  const char *comm)
+{
+	guestlog_msg_t msg;
+
+	// Setup msg
+	msg.header.type = BHV_GUESTLOG_MSG_TYPE_PROCESS_EXEC;
+	msg.process_exec.pid = pid;
+	msg.process_exec.parent_pid = parent_pid;
+	strscpy(msg.process_exec.name, comm, TASK_COMM_LEN);
+	msg.header.sz = bhv_guestlog_calc_msg_sz(
+		msg.header.type,
+		strnlen(msg.process_exec.name, TASK_COMM_LEN) + 1);
+
+	// Send
+	return bhv_guestlog_send(&msg);
+}
+
+int bhv_guestlog_log_process_exit(uint32_t pid, uint32_t parent_pid,
+				  const char *comm)
+{
+	guestlog_msg_t msg;
+
+	// Setup msg
+	msg.header.type = BHV_GUESTLOG_MSG_TYPE_PROCESS_EXIT;
+	msg.process_exit.pid = pid;
+	msg.process_exit.parent_pid = parent_pid;
+	strscpy(msg.process_exit.name, comm, TASK_COMM_LEN);
+	msg.header.sz = bhv_guestlog_calc_msg_sz(
+		msg.header.type,
+		strnlen(msg.process_exit.name, TASK_COMM_LEN) + 1);
+
+	// Send
+	return bhv_guestlog_send(&msg);
+}
+
+int bhv_guestlog_log_driver_load(const char *name)
+{
+	guestlog_msg_t msg;
+
+	// Setup msg
+	msg.header.type = BHV_GUESTLOG_MSG_TYPE_DRIVER_LOAD;
+	strscpy(msg.driver_load.name, name, sizeof(msg.driver_load.name));
+	msg.header.sz = bhv_guestlog_calc_msg_sz(
+		msg.header.type,
+		strnlen(msg.driver_load.name, sizeof(msg.driver_load.name)) +
+			1);
+
+	// Send
+	return bhv_guestlog_send(&msg);
+}
+
+static int bhv_guestlog_reboot(struct notifier_block *notifier,
+			       unsigned long val, void *v)
+{
+	if (vsock) {
+		sock_release(vsock);
+		vsock = NULL;
+	}
+	return NOTIFY_OK;
+}
+
+static struct notifier_block bhv_guestlog_reboot_notifier = {
+	.notifier_call = bhv_guestlog_reboot,
+	.priority = 0,
+};
+
+void bhv_guestlog_start(void)
+{
+	int err;
+	struct sockaddr_vm addr;
+
+	if (!bhv_guestlog_enabled())
+		return;
+
+	vsock_addr_init(&addr, bhv_guestlog_config.cid,
+			bhv_guestlog_config.port);
+	pr_info("bhv_guestlog_started with config: cid %u, port %u, bitmap: 0x%llx, valid: %u",
+		bhv_guestlog_config.cid, bhv_guestlog_config.port,
+		bhv_guestlog_config.log_bitmap, bhv_guestlog_config.valid);
+
+	err = sock_create_kern(&init_net, AF_VSOCK, SOCK_STREAM, 0, &vsock);
+	if (err < 0) {
+		bhv_fail("GuestLog: Could not create kernel socket (%d)", err);
+		return;
+	}
+
+	err = kernel_connect(vsock, (struct sockaddr *)&addr,
+			     sizeof(struct sockaddr_vm), 0);
+	if (err < 0) {
+		bhv_fail("GuestLog: Could not connect to host (%d)", err);
+		return;
+	}
+
+	// Initialize work queue
+	INIT_WORK(&bhv_guestlog_work_struct, bhv_guestlog_sendmsg);
+	INIT_DELAYED_WORK(&bhv_guestlog_delayed_work_struct,
+			  bhv_guestlog_sendmsg);
+	bhv_guestlog_workqueue =
+		alloc_workqueue("bhv_guestlog_workqueue", WQ_UNBOUND, 1);
+	// queue = create_singlethread_workqueue("bhv_guestlog_work_queue");
+	if (bhv_guestlog_workqueue == NULL) {
+		bhv_fail("BHV: Could not allocate work queue!");
+		kmem_cache_destroy(bhv_guestlog_send_item_cache);
+		return;
+	}
+	atomic_inc(&workqueue_ready);
+
+	register_reboot_notifier(&bhv_guestlog_reboot_notifier);
+
+	queue_work(bhv_guestlog_workqueue, &bhv_guestlog_work_struct);
+}
+
+void __init bhv_guestlog_init()
+{
+	unsigned long r;
+
+	if (!bhv_guestlog_enabled())
+		return;
+
+	// Create cache
+	bhv_guestlog_send_item_cache = kmem_cache_create(
+		"bhv_guestlog_send_item_cache",
+		sizeof(bhv_guestlog_send_item_t), 0,
+		SLAB_HWCACHE_ALIGN | SLAB_PANIC | SLAB_ACCOUNT, NULL);
+	if (bhv_guestlog_send_item_cache == NULL) {
+		bhv_fail("BHV: Could not create kmem_cache for work items!");
+		return;
+	}
+
+	r = bhv_hypercall_vas(BHV_VAS_BACKEND_GUESTLOG,
+			      BHV_VAS_GUESTLOG_OP_INIT_GUESTLOG,
+			      &bhv_guestlog_config);
+	if (r) {
+		pr_err("BHV: guestlog init failed");
+		return;
+	}
+}
\ No newline at end of file
diff --git kernel/bhv/init.c kernel/bhv/init.c
new file mode 100644
index 000000000000..09824583e08f
--- /dev/null
+++ kernel/bhv/init.c
@@ -0,0 +1,89 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ *          Sergej Proskurin <sergej@bedrocksystems.com>
+ *          Sebastian Vogl <sebastian@bedrocksystems.com>
+ */
+
+#include <asm/io.h>
+#include <asm/sections.h>
+
+#include <bhv/interface/common.h>
+#include <bhv/interface/hypercall.h>
+#include <bhv/interface/init.h>
+#include <bhv/interface/integrity.h>
+#include <bhv/init.h>
+#include <bhv/creds.h>
+
+int __init bhv_init_hyp(void *init_start, uint64_t init_size, void *text_start,
+			uint64_t text_size)
+{
+	unsigned long r;
+	bhv_mem_region_t *init_phys_mem_regions;
+	bhv_init_arg_t *init_arg;
+
+	void *bhv_data = __bhv_data_start;
+	uint64_t bhv_data_size = __bhv_data_end - __bhv_data_start;
+	void *bhv_text = __bhv_text_start;
+	uint64_t bhv_text_size = __bhv_text_end - __bhv_text_start;
+
+	unsigned int region_counter = 0;
+
+	BUG_ON(((BHV_INIT_MAX_REGIONS * sizeof(bhv_mem_region_t)) +
+		sizeof(bhv_init_arg_t)) > bhv_data_size);
+
+	init_phys_mem_regions = bhv_data;
+
+	init_phys_mem_regions[region_counter].bhv_mem_region_create.start_addr =
+		virt_to_phys(init_start);
+	init_phys_mem_regions[region_counter].bhv_mem_region_create.size =
+		init_size;
+	init_phys_mem_regions[region_counter].bhv_mem_region_create.type =
+		BHV_MEM_TYPE_CODE_PATCHABLE;
+	init_phys_mem_regions[region_counter].bhv_mem_region_create.flags =
+		BHV_MEM_FLAGS_TRANSIENT;
+	init_phys_mem_regions[region_counter].bhv_mem_region_create.next =
+		virt_to_phys(&(init_phys_mem_regions[region_counter + 1]));
+	region_counter++;
+
+	init_phys_mem_regions[region_counter].bhv_mem_region_create.start_addr =
+		virt_to_phys(text_start);
+	init_phys_mem_regions[region_counter].bhv_mem_region_create.size =
+		text_size;
+	init_phys_mem_regions[region_counter].bhv_mem_region_create.type =
+		BHV_MEM_TYPE_CODE_PATCHABLE;
+	init_phys_mem_regions[region_counter].bhv_mem_region_create.flags =
+		BHV_MEM_FLAGS_NONE;
+	init_phys_mem_regions[region_counter].bhv_mem_region_create.next =
+		BHV_INVALID_PHYS_ADDR;
+	region_counter++;
+
+	bhv_init_hyp_arch(init_phys_mem_regions, &region_counter);
+
+	// Set size of init args
+	init_arg = bhv_data + (BHV_INIT_MAX_REGIONS * sizeof(bhv_mem_region_t));
+
+	init_arg->bhv_init_init_arg.bhv_data_start = virt_to_phys(bhv_data);
+	init_arg->bhv_init_init_arg.bhv_data_size = bhv_data_size;
+	init_arg->bhv_init_init_arg.bhv_text_start = virt_to_phys(bhv_text);
+	init_arg->bhv_init_init_arg.bhv_text_size = bhv_text_size;
+	init_arg->bhv_init_init_arg.owner = 0;
+	init_arg->bhv_init_init_arg.region_head =
+		virt_to_phys(init_phys_mem_regions);
+
+	r = bhv_hypercall_vas(BHV_VAS_BACKEND_INIT, BHV_VAS_INIT_OP_INIT,
+			      init_arg);
+	if (r)
+		return -EINVAL;
+	return 0;
+}
+
+int bhv_start_hyp(void)
+{
+	unsigned long r = bhv_hypercall_vas(BHV_VAS_BACKEND_INIT,
+					    BHV_VAS_INIT_OP_START, NULL);
+	if (r)
+		return -EINVAL;
+	return 0;
+}
diff --git kernel/bhv/integrity.c kernel/bhv/integrity.c
new file mode 100644
index 000000000000..25ac14dfd0c1
--- /dev/null
+++ kernel/bhv/integrity.c
@@ -0,0 +1,131 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ *          Sergej Proskurin <sergej@bedrocksystems.com>
+ */
+
+#include <linux/types.h>
+#include <asm/io.h>
+
+#include <bhv/bhv.h>
+#include <bhv/interface/hypercall.h>
+
+#include <bhv/integrity.h>
+
+struct kmem_cache *bhv_mem_region_cache;
+struct kmem_cache *bhv_integrity_arg_cache;
+
+void __init bhv_integrity_mm_init(void)
+{
+	bhv_mem_region_cache = kmem_cache_create(
+		"bhv_mem_region_cache", sizeof(bhv_mem_region_node_t), 0,
+		SLAB_HWCACHE_ALIGN | SLAB_PANIC | SLAB_ACCOUNT, NULL);
+
+	bhv_integrity_arg_cache = kmem_cache_create(
+		"bhv_integrity_arg_cache", sizeof(bhv_integrity_arg_t), 0,
+		SLAB_HWCACHE_ALIGN | SLAB_PANIC | SLAB_ACCOUNT, NULL);
+}
+
+int bhv_integrity_disable_events(void)
+{
+	unsigned long ret = bhv_hypercall_vas(
+		BHV_VAS_BACKEND_INTEGRITY, BHV_VAS_INTEGRITY_OP_DISABLE, NULL);
+
+	return (ret) ? -EINVAL : 0;
+}
+
+int bhv_create_kern_phys_mem_region_hyp(uint64_t owner,
+					bhv_mem_region_t *region_head)
+{
+	int rv = 0;
+	unsigned long r;
+	bhv_integrity_arg_t *bhv_arg =
+		kmem_cache_alloc(bhv_integrity_arg_cache, GFP_KERNEL);
+	if (!bhv_arg) {
+		bhv_fail("BHV: failed to allocate arg.");
+		return -ENOMEM;
+	}
+
+	bhv_arg->bhv_integrity_create_arg.owner = owner;
+	bhv_arg->bhv_integrity_create_arg.region_head =
+		virt_to_phys(region_head);
+
+	r = bhv_hypercall_vas(BHV_VAS_BACKEND_INTEGRITY,
+			      BHV_VAS_INTEGRITY_OP_CREATE_PHYS, bhv_arg);
+	if (r)
+		rv = -EINVAL;
+
+	kmem_cache_free(bhv_integrity_arg_cache, bhv_arg);
+	return rv;
+}
+
+int bhv_update_kern_phys_mem_region_hyp(bhv_mem_region_t *region_head)
+{
+	int rv = 0;
+	unsigned long r;
+	bhv_integrity_arg_t *bhv_arg =
+		kmem_cache_alloc(bhv_integrity_arg_cache, GFP_KERNEL);
+	if (!bhv_arg) {
+		bhv_fail("BHV: failed to allocate arg.");
+		return -ENOMEM;
+	}
+
+	bhv_arg->bhv_integrity_update_arg.region_head =
+		virt_to_phys(region_head);
+
+	r = bhv_hypercall_vas(BHV_VAS_BACKEND_INTEGRITY,
+			      BHV_VAS_INTEGRITY_OP_UPDATE_PHYS, bhv_arg);
+	if (r)
+		rv = -EINVAL;
+
+	kmem_cache_free(bhv_integrity_arg_cache, bhv_arg);
+	return rv;
+}
+
+int bhv_remove_kern_phys_mem_region_by_region_hyp(bhv_mem_region_t *region_head)
+{
+	int rv = 0;
+	unsigned long r;
+	bhv_integrity_arg_t *bhv_arg =
+		kmem_cache_alloc(bhv_integrity_arg_cache, GFP_KERNEL);
+	if (!bhv_arg) {
+		bhv_fail("BHV: failed to allocate arg.");
+		return -ENOMEM;
+	}
+
+	bhv_arg->bhv_integrity_remove_arg.rm_by_owner = 0;
+	bhv_arg->bhv_integrity_remove_arg.region_head =
+		virt_to_phys(region_head);
+
+	r = bhv_hypercall_vas(BHV_VAS_BACKEND_INTEGRITY,
+			      BHV_VAS_INTEGRITY_OP_REMOVE_PHYS, bhv_arg);
+	if (r)
+		rv = -EINVAL;
+
+	kmem_cache_free(bhv_integrity_arg_cache, bhv_arg);
+	return rv;
+}
+
+int bhv_remove_kern_phys_mem_region_by_owner_hyp(uint64_t owner)
+{
+	int rv = 0;
+	unsigned long r;
+	bhv_integrity_arg_t *bhv_arg =
+		kmem_cache_alloc(bhv_integrity_arg_cache, GFP_KERNEL);
+	if (!bhv_arg) {
+		bhv_fail("BHV: failed to allocate arg.");
+		return -ENOMEM;
+	}
+
+	bhv_arg->bhv_integrity_remove_arg.rm_by_owner = 1;
+	bhv_arg->bhv_integrity_remove_arg.owner = owner;
+
+	r = bhv_hypercall_vas(BHV_VAS_BACKEND_INTEGRITY,
+			      BHV_VAS_INTEGRITY_OP_REMOVE_PHYS, bhv_arg);
+	if (r)
+		rv = -EINVAL;
+
+	kmem_cache_free(bhv_integrity_arg_cache, bhv_arg);
+	return rv;
+}
diff --git kernel/bhv/module.c kernel/bhv/module.c
new file mode 100644
index 000000000000..0288d3fb4cb5
--- /dev/null
+++ kernel/bhv/module.c
@@ -0,0 +1,416 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Sergej Proskurin <sergej@bedrocksystems.com>
+ *          Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#include <linux/module.h>
+#include <linux/mm.h>
+#include <linux/kernel.h>
+#include <linux/list.h>
+
+#include <asm/io.h>
+
+#include <bhv/integrity.h>
+#include <bhv/interface/common.h>
+
+typedef int (*bhv_link_node_cb_t)(struct list_head *, uint64_t, uint64_t,
+				  uint32_t, uint64_t);
+
+static int _bhv_link_node_op_create(struct list_head *head, uint64_t pfn,
+				    uint64_t size, uint32_t type,
+				    uint64_t flags)
+{
+	return bhv_link_node_op_create(head, pfn << PAGE_SHIFT, size, type,
+				       flags);
+}
+
+#ifdef CONFIG_MODULES
+static int _bhv_link_node_op_update(struct list_head *head, uint64_t pfn,
+				    uint64_t unused, uint32_t type,
+				    uint64_t flags)
+{
+	return bhv_link_node_op_update(head, pfn << PAGE_SHIFT, type, flags);
+}
+
+static int _bhv_link_node_op_remove(struct list_head *head, uint64_t pfn,
+				    uint64_t unused1, uint32_t unused2,
+				    uint64_t unused3)
+{
+	return bhv_link_node_op_remove(head, pfn << PAGE_SHIFT);
+}
+#endif /* CONFIG_MODULES */
+
+static void bhv_prepare_mod_section(struct list_head *head, const void *base,
+				    uint64_t size, uint32_t type,
+				    uint64_t flags,
+				    bhv_link_node_cb_t link_node_cb)
+{
+	int rv;
+	uint64_t i = 0;
+	uint64_t nr_pages = 0;
+	uint64_t pfn = 0;
+	uint64_t pfn_count_consecutive = 0;
+
+	BUG_ON(!PAGE_ALIGNED(base));
+	BUG_ON(!PAGE_ALIGNED(size));
+
+	if (base == NULL || size == 0)
+		return;
+
+	/* This is ok, because size is always a number of pages. */
+	nr_pages = (((uint64_t)base + size) - (uint64_t)base) >> PAGE_SHIFT;
+
+	for (i = 0; i < nr_pages; ++i) {
+		struct page *p = NULL;
+		uint64_t size_consecutive = 0;
+
+		p = vmalloc_to_page(base + (i << PAGE_SHIFT));
+		if (p == NULL) {
+			pr_err("%s: Cannot translate addr @ 0x%llx",
+			       __FUNCTION__,
+			       (uint64_t)(base + (i << PAGE_SHIFT)));
+			return;
+		}
+
+		if (pfn_count_consecutive == 0) {
+			pfn = page_to_pfn(p);
+			pfn_count_consecutive++;
+			continue;
+		}
+
+		if ((page_to_pfn(p) - pfn) == pfn_count_consecutive) {
+			pfn_count_consecutive++;
+			continue;
+		}
+
+		/* We have found a physically non-contiguous section. */
+
+		if ((pfn_count_consecutive << PAGE_SHIFT) > size)
+			size_consecutive = size;
+		else
+			size_consecutive = pfn_count_consecutive << PAGE_SHIFT;
+
+		rv = link_node_cb(head, pfn, size_consecutive, type, flags);
+		if (rv) {
+			pr_err("%s: failed to allocate mem region",
+			       __FUNCTION__);
+			return;
+		}
+
+		pfn = page_to_pfn(p);
+		pfn_count_consecutive = 1;
+		size -= size_consecutive;
+	}
+
+	rv = link_node_cb(head, pfn, size, type, flags);
+	if (rv) {
+		pr_err("%s: failed to allocate mem region", __FUNCTION__);
+		return;
+	}
+}
+
+static void bhv_create_section(struct list_head *head, const void *base,
+			       uint64_t size, uint32_t type, uint64_t flags)
+{
+	if (type == BHV_MEM_TYPE_UNKNOWN)
+		return;
+
+	bhv_prepare_mod_section(head, base, size, type, flags,
+				_bhv_link_node_op_create);
+}
+
+static void bhv_release_memory_by_owner(uint64_t owner)
+{
+	int rc = bhv_remove_kern_phys_mem_region_by_owner_hyp(owner);
+	if (rc) {
+		pr_err("%s: Cannot remove the module's memory regions",
+		       __FUNCTION__);
+	}
+}
+
+#ifdef CONFIG_MODULES
+static void bhv_update_section(struct list_head *head, const void *base,
+			       uint64_t size, uint32_t type, uint64_t flags)
+{
+	if (type == BHV_MEM_TYPE_UNKNOWN)
+		return;
+
+	type &= ~BHV_MEM_FLAGS_MUTABLE;
+
+	bhv_prepare_mod_section(head, base, size, type, flags,
+				_bhv_link_node_op_update);
+}
+
+static void bhv_remove_section(struct list_head *head, const void *base,
+			       uint64_t size)
+{
+	bhv_prepare_mod_section(head, base, size, BHV_MEM_TYPE_UNKNOWN,
+				BHV_MEM_FLAGS_NONE, _bhv_link_node_op_remove);
+}
+
+static void bhv_prepare_mod_layout(struct list_head *head,
+				   const struct module_layout *layout)
+{
+	if (layout->size == 0)
+		return;
+
+	/* Prepare the module region's .text section. */
+	bhv_create_section(head, layout->base, layout->text_size,
+			   BHV_MEM_TYPE_CODE_PATCHABLE,
+			   BHV_MEM_FLAGS_TRANSIENT);
+
+	/* Prepare the module region's .rodata section. */
+	if (layout->ro_size - layout->text_size) {
+		bhv_create_section(head, (layout->base + layout->text_size),
+				   (layout->ro_size - layout->text_size),
+				   BHV_MEM_TYPE_DATA_READ_ONLY,
+				   BHV_MEM_FLAGS_TRANSIENT);
+	}
+
+	/* Prepare the module region's .ro_after_init section. */
+	if (layout->ro_after_init_size - layout->ro_size) {
+		bhv_create_section(
+			head, (layout->base + layout->ro_size),
+			(layout->ro_after_init_size - layout->ro_size),
+			BHV_MEM_TYPE_DATA,
+			BHV_MEM_FLAGS_TRANSIENT | BHV_MEM_FLAGS_MUTABLE);
+	}
+
+	/* Prepare the module region's .data section. */
+	if (layout->size - layout->ro_after_init_size) {
+		bhv_create_section(head,
+				   (layout->base + layout->ro_after_init_size),
+				   (layout->size - layout->ro_after_init_size),
+				   BHV_MEM_TYPE_DATA, BHV_MEM_FLAGS_TRANSIENT);
+	}
+}
+
+static void bhv_prepare_mod(struct list_head *head, const struct module *mod)
+{
+	bhv_prepare_mod_layout(head, &mod->init_layout);
+	bhv_prepare_mod_layout(head, &mod->core_layout);
+}
+
+void bhv_module_load_prepare(const struct module *mod)
+{
+	int rc = 0;
+	uint64_t owner = (uint64_t)mod;
+	struct bhv_mem_region_node *n = NULL;
+
+	/*
+	 * Note: list operations do not require locking, because the scope of
+	 * the list is limited to the function call; parallel calls to this
+	 * function will create their own lists.
+	 */
+	LIST_HEAD(bhv_region_list_head);
+
+	if (!bhv_integrity_is_enabled())
+		return;
+
+	/*
+	 * XXX: Check whether the addresses are part of the region
+	 * [module_alloc_base;module_alloc_end]
+	 */
+
+	bhv_prepare_mod(&bhv_region_list_head, mod);
+
+	if (list_empty(&bhv_region_list_head))
+		return;
+
+	n = list_first_entry_or_null(&bhv_region_list_head,
+				     struct bhv_mem_region_node, list);
+	if (n == NULL)
+		goto err;
+
+	/*
+	 * XXX: Consider using either the owner or an additional identifier for
+	 * page frames that belong to a given memory layout region. This would
+	 * allow us to efficiently release the respective memory regions.
+	 */
+	rc = bhv_create_kern_phys_mem_region_hyp(owner, &n->region);
+	if (rc) {
+		pr_err("%s: Cannot protect the module's memory regions",
+		       __FUNCTION__);
+		goto err;
+	}
+
+	bhv_release_arg_list(&bhv_region_list_head);
+
+	return;
+
+err:
+	bhv_release_arg_list(&bhv_region_list_head);
+	bhv_remove_kern_phys_mem_region_by_owner_hyp(owner);
+}
+
+static void bhv_complete_free_init(const struct module_layout *layout)
+{
+	int rc = 0;
+	struct bhv_mem_region_node *n = NULL;
+
+	LIST_HEAD(bhv_region_list_head);
+
+	if (layout->size == 0)
+		return;
+
+	/* Prepare the module region's .text section. */
+	bhv_remove_section(&bhv_region_list_head, layout->base,
+			   layout->text_size);
+
+	/* Prepare the module region's .rodata section. */
+	if (layout->ro_size - layout->text_size) {
+		bhv_remove_section(&bhv_region_list_head,
+				   (layout->base + layout->text_size),
+				   (layout->ro_size - layout->text_size));
+	}
+
+	/* Prepare the module region's .ro_after_init section. */
+	if (layout->ro_after_init_size - layout->ro_size) {
+		bhv_remove_section(
+			&bhv_region_list_head, (layout->base + layout->ro_size),
+			(layout->ro_after_init_size - layout->ro_size));
+	}
+
+	/* Prepare the module region's .data section. */
+	if (layout->size - layout->ro_after_init_size) {
+		bhv_remove_section(&bhv_region_list_head,
+				   (layout->base + layout->ro_after_init_size),
+				   (layout->size - layout->ro_after_init_size));
+	}
+
+	if (list_empty(&bhv_region_list_head))
+		return;
+
+	n = list_first_entry_or_null(&bhv_region_list_head,
+				     struct bhv_mem_region_node, list);
+	if (n == NULL)
+		return;
+
+	rc = bhv_remove_kern_phys_mem_region_by_region_hyp(&n->region);
+	if (rc) {
+		/* XXX: Determine a strategy for failed update attempts. */
+		pr_err("%s: Cannot remove the module's memory regions",
+		       __FUNCTION__);
+	}
+
+	bhv_release_arg_list(&bhv_region_list_head);
+}
+
+static void bhv_update_ro_after_init(const struct module *mod)
+{
+	int rc = 0;
+	struct bhv_mem_region_node *n = NULL;
+
+	void *base = mod->core_layout.base + mod->core_layout.ro_size;
+	unsigned int size =
+		mod->core_layout.ro_after_init_size - mod->core_layout.ro_size;
+
+	LIST_HEAD(bhv_region_list_head);
+
+	if (size == 0) {
+		return;
+	}
+
+	bhv_update_section(&bhv_region_list_head, base, size,
+			   BHV_MEM_TYPE_DATA_READ_ONLY,
+			   BHV_MEM_FLAGS_TRANSIENT);
+
+	if (list_empty(&bhv_region_list_head))
+		return;
+
+	n = list_first_entry_or_null(&bhv_region_list_head,
+				     struct bhv_mem_region_node, list);
+	if (n == NULL)
+		return;
+
+	rc = bhv_update_kern_phys_mem_region_hyp(&n->region);
+	if (rc) {
+		/* XXX: Determine a strategy for failed update attempts. */
+		pr_err("%s: Cannot update the module's memory regions",
+		       __FUNCTION__);
+	}
+
+	bhv_release_arg_list(&bhv_region_list_head);
+}
+
+void bhv_module_load_complete(const struct module *mod)
+{
+	if (!bhv_integrity_is_enabled())
+		return;
+	bhv_update_ro_after_init(mod);
+	bhv_complete_free_init(&mod->init_layout);
+}
+
+void bhv_module_unload(const struct module *mod)
+{
+	if (!bhv_integrity_is_enabled())
+		return;
+	bhv_release_memory_by_owner((uint64_t)mod);
+}
+#endif /* CONFIG_MODULES */
+
+static void bhv_bpf_protect(const void *base, uint64_t size, uint32_t type,
+			    uint64_t flags)
+{
+	int rc = 0;
+
+	/*
+	 * XXX: Note that we currently do not group subprograms of a BPF
+	 * program. Instead we protect them individually. Consider changing this
+	 * in the future.
+	 */
+	uint64_t owner = (uint64_t)base;
+	struct bhv_mem_region_node *n = NULL;
+
+	LIST_HEAD(bhv_section_list_head);
+
+	/* Prepare the section belonging to the bpf (sub)program. */
+	bhv_create_section(&bhv_section_list_head, base, size, type, flags);
+
+	if (list_empty(&bhv_section_list_head))
+		return;
+
+	n = list_first_entry_or_null(&bhv_section_list_head,
+				     struct bhv_mem_region_node, list);
+	if (n == NULL)
+		goto err;
+
+	rc = bhv_create_kern_phys_mem_region_hyp(owner, &n->region);
+	if (rc) {
+		pr_err("%s: Cannot protect the module's memory regions",
+		       __FUNCTION__);
+		goto err;
+	}
+
+	bhv_release_arg_list(&bhv_section_list_head);
+
+	return;
+
+err:
+	bhv_release_arg_list(&bhv_section_list_head);
+	bhv_remove_kern_phys_mem_region_by_owner_hyp(owner);
+}
+
+void bhv_bpf_protect_ro(const void *base, uint64_t size)
+{
+	if (!bhv_integrity_is_enabled())
+		return;
+	bhv_bpf_protect(base, size, BHV_MEM_TYPE_DATA_READ_ONLY,
+			BHV_MEM_FLAGS_TRANSIENT);
+}
+
+void bhv_bpf_protect_x(const void *base, uint64_t size)
+{
+	if (!bhv_integrity_is_enabled())
+		return;
+	bhv_bpf_protect(base, size, BHV_MEM_TYPE_CODE, BHV_MEM_FLAGS_TRANSIENT);
+}
+
+void bhv_bpf_unprotect(const void *base)
+{
+	if (!bhv_integrity_is_enabled())
+		return;
+	bhv_release_memory_by_owner((uint64_t)base);
+}
diff --git kernel/bhv/patch_alternative.c kernel/bhv/patch_alternative.c
new file mode 100644
index 000000000000..165d0739b5d6
--- /dev/null
+++ kernel/bhv/patch_alternative.c
@@ -0,0 +1,181 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Sebastian Vogl <sebastian@bedrocksystems.com>
+ *          Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#include <bhv/bhv.h>
+#include <bhv/vault.h>
+#include <bhv/patch.h>
+#include <bhv/interface/patch.h>
+
+#include <asm/bhv/patch.h>
+
+static DEFINE_MUTEX(bhv_alternatives_mutex);
+static LIST_HEAD(bhv_alternatives_head);
+
+static void __always_inline bhv_alternatives_lock(void)
+{
+	mutex_lock(&bhv_alternatives_mutex);
+}
+
+static void __always_inline bhv_alternatives_unlock(void)
+{
+	mutex_unlock(&bhv_alternatives_mutex);
+}
+
+void bhv_alternatives_add_module(struct alt_instr *begin, struct alt_instr *end,
+				 struct bhv_alternatives_mod_arch *arch)
+{
+	struct bhv_alternatives_mod *n;
+
+	n = kzalloc(sizeof(struct bhv_alternatives_mod), GFP_KERNEL);
+	if (!n) {
+		bhv_fail("No memory left!");
+		return;
+	}
+
+	n->begin = begin;
+	n->end = end;
+	n->delete_policy = BHV_ALTERNATIVES_DELETE_AFTER_PATCH;
+	n->allocated = true;
+	memcpy(&n->arch, arch, sizeof(n->arch));
+
+	bhv_alternatives_lock();
+	list_add(&(n->next), &bhv_alternatives_head);
+	bhv_alternatives_unlock();
+}
+
+void bhv_alternatives_delete_after_init(void)
+{
+	struct bhv_alternatives_mod *i, *tmp;
+
+	bhv_alternatives_lock();
+	list_for_each_entry_safe (i, tmp, &bhv_alternatives_head, next) {
+		if (i->delete_policy == BHV_ALTERNATIVES_DELETE_AFTER_INIT) {
+			list_del(&(i->next));
+			if (i->allocated) {
+				kfree(i);
+			}
+		}
+	}
+	bhv_alternatives_unlock();
+}
+
+// LOCK MUST BE HELD!
+static void __bhv_text
+bhv_alternatives_add_module_no_alloc(struct bhv_alternatives_mod *n)
+{
+	n->allocated = false;
+	list_add(&(n->next), &bhv_alternatives_head);
+}
+
+static void __bhv_text bhv_alternatives_init(void)
+{
+	uint32_t static_mods, i;
+	struct bhv_alternatives_mod *n =
+		bhv_alternatives_get_static_mods_vault(&static_mods);
+
+	for (i = 0; i < static_mods; i++)
+		bhv_alternatives_add_module_no_alloc(&n[i]);
+}
+
+static int __bhv_text bhv_alternatives_apply_vault(
+	void *search_param, void *arch, bhv_alternatives_filter_t filter,
+	bhv_patch_arg_t *arg)
+{
+	static bool initialized = false;
+
+	struct bhv_alternatives_mod *i, *tmp, *found;
+	int rv;
+
+	rv = bhv_vault_open_hyp();
+	if (rv) {
+		return rv;
+	}
+
+	if (!initialized) {
+		bhv_alternatives_init();
+		initialized = true;
+	}
+
+	found = NULL;
+	list_for_each_entry_safe (i, tmp, &bhv_alternatives_head, next) {
+		if (filter(search_param, i)) {
+			found = i;
+			break;
+		}
+	}
+
+	// Unknown module.
+	if (found == NULL) {
+		bhv_vault_close_hyp();
+		return -EACCES;
+	}
+
+	rv = bhv_alternatives_apply_vault_arch(found, arch, arg);
+
+	// Delete module. Only one patch allowed.
+	if (found->delete_policy == BHV_ALTERNATIVES_DELETE_AFTER_PATCH) {
+		list_del(&(found->next));
+		if (found->allocated) {
+			kfree(found);
+		}
+	}
+
+	// Close vault.
+	bhv_vault_close_hyp();
+
+	return rv;
+}
+
+struct alt_inst_search {
+	struct alt_instr *begin;
+	struct alt_instr *end;
+};
+static bool __bhv_text bhv_alternatives_find_by_alt(
+	void *search_param, struct bhv_alternatives_mod *cur)
+{
+	struct alt_inst_search *param = search_param;
+
+	if (cur->begin == param->begin && cur->end == param->end) {
+		return true;
+	}
+
+	return false;
+}
+
+int bhv_alternatives_apply(struct alt_instr *begin, struct alt_instr *end,
+			   void *arch)
+{
+	int rv = 0;
+	unsigned long flags;
+	static bhv_patch_arg_t bhv_arg;
+	struct alt_inst_search search = { .begin = begin, .end = end };
+
+	bhv_alternatives_lock();
+	local_irq_save(flags);
+	rv = bhv_alternatives_apply_vault(
+		&search, arch, bhv_alternatives_find_by_alt, &bhv_arg);
+	local_irq_restore(flags);
+	bhv_alternatives_unlock();
+
+	return rv;
+}
+
+int bhv_alternatives_apply_custom_filter(void *search_param, void *arch,
+					 bhv_alternatives_filter_t filter)
+{
+	int rv = 0;
+	unsigned long flags;
+	static bhv_patch_arg_t bhv_arg;
+
+	bhv_alternatives_lock();
+	local_irq_save(flags);
+	rv = bhv_alternatives_apply_vault(search_param, arch, filter, &bhv_arg);
+	local_irq_restore(flags);
+	bhv_alternatives_unlock();
+
+	return rv;
+}
\ No newline at end of file
diff --git kernel/bhv/patch_jump_label.c kernel/bhv/patch_jump_label.c
new file mode 100644
index 000000000000..5d90a14e7a73
--- /dev/null
+++ kernel/bhv/patch_jump_label.c
@@ -0,0 +1,177 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ */
+
+#include <linux/jump_label.h>
+#include <linux/module.h>
+#include <linux/mm.h>
+#include <linux/irqflags.h>
+#include <asm/bhv/patch.h>
+#include <bhv/interface/patch.h>
+#include <bhv/patch.h>
+#include <bhv/vault.h>
+
+static DEFINE_MUTEX(bhv_jump_label_mutex);
+static LIST_HEAD(bhv_static_key_mod_head);
+
+struct bhv_static_key_mod {
+	struct jump_entry *entries_start;
+	struct jump_entry *entries_stop;
+#ifdef CONFIG_MODULES
+	struct module *mod;
+#endif /* CONFIG_MODULES */
+	struct list_head list;
+};
+
+static void __always_inline bhv_jump_label_lock(void)
+{
+	mutex_lock(&bhv_jump_label_mutex);
+}
+
+static void __always_inline bhv_jump_label_unlock(void)
+{
+	mutex_unlock(&bhv_jump_label_mutex);
+}
+
+#ifdef CONFIG_MODULES
+int bhv_jump_label_add_module(struct module *mod)
+{
+	struct bhv_static_key_mod *n;
+
+	n = kzalloc(sizeof(struct bhv_static_key_mod), GFP_KERNEL);
+	if (!n)
+		return -ENOMEM;
+
+	n->entries_start = mod->jump_entries;
+	n->entries_stop = mod->jump_entries + mod->num_jump_entries;
+	n->mod = mod;
+
+	bhv_jump_label_lock();
+	list_add(&(n->list), &bhv_static_key_mod_head);
+	bhv_jump_label_unlock();
+
+	return 0;
+}
+
+void bhv_jump_label_del_module(struct module *mod)
+{
+	struct bhv_static_key_mod *i, *tmp;
+
+	bhv_jump_label_lock();
+	list_for_each_entry_safe (i, tmp, &bhv_static_key_mod_head, list) {
+		if (i->mod == mod)
+			list_del(&(i->list));
+	}
+	bhv_jump_label_unlock();
+}
+#endif /* CONFIG_MODULES */
+
+enum jump_label_type __bhv_text bhv_jump_label_type(struct jump_entry *entry)
+{
+	struct static_key *key = jump_entry_key(entry);
+	bool enabled = static_key_enabled(key);
+	bool branch = jump_entry_is_branch(entry);
+
+	/* See the comment in linux/jump_label.h */
+	return enabled ^ branch;
+}
+
+bool __bhv_text validate_jmp_labels(struct jump_entry *entry,
+				    const void *opcode, size_t len,
+				    uint64_t *dest_phys_addr)
+{
+	struct bhv_static_key_mod *i;
+
+	if (entry >= __start___jump_table && entry < __stop___jump_table) {
+		*dest_phys_addr = virt_to_phys((void *)jump_entry_code(entry));
+		return bhv_jump_label_validate_opcode(
+			entry, bhv_jump_label_type(entry), opcode, len);
+	}
+
+	list_for_each_entry (i, &bhv_static_key_mod_head, list) {
+		if (entry >= i->entries_start && entry < i->entries_stop) {
+			uint64_t offset =
+				jump_entry_code(entry) & (PAGE_SIZE - 1);
+			struct page *p =
+				vmalloc_to_page((void *)jump_entry_code(entry));
+			if (p == NULL) {
+				pr_err("%s: Cannot translate addr @ 0x%llx",
+				       __FUNCTION__,
+				       (uint64_t)((void *)jump_entry_code(
+					       entry)));
+				return false;
+			}
+			*dest_phys_addr =
+				(page_to_pfn(p) << PAGE_SHIFT) | offset;
+			return bhv_jump_label_validate_opcode(
+				entry, bhv_jump_label_type(entry), opcode, len);
+		}
+	}
+
+	return false;
+}
+
+int __bhv_text bhv_vault_patch_jump_label(struct jump_entry *entry,
+					  const void *opcode, size_t len,
+					  bhv_patch_arg_t *bhv_arg)
+{
+	int rv = 0;
+	unsigned long r;
+	bool validation_ok;
+	uint64_t dest_phys_addr;
+
+	rv = bhv_vault_open_hyp();
+	if (rv) {
+		return rv;
+	}
+
+	if (len > BHV_MAX_INSN_SZ) {
+		bhv_vault_close_hyp();
+		return -E2BIG;
+	}
+
+	memcpy(bhv_arg->bhv_patch_patch_arg.src_value, opcode, len);
+	bhv_arg->bhv_patch_patch_arg.size = (uint64_t)len;
+
+	validation_ok =
+		validate_jmp_labels(entry,
+				    bhv_arg->bhv_patch_patch_arg.src_value, len,
+				    &dest_phys_addr);
+	if (!validation_ok) {
+		bhv_vault_close_hyp();
+		return -EACCES;
+	}
+
+	bhv_arg->bhv_patch_patch_arg.dest_phys_addr = dest_phys_addr;
+
+	r = bhv_hypercall_vas(BHV_VAS_BACKEND_PATCH, BHV_VAS_PATCH_OP_PATCH,
+			      bhv_arg);
+	if (r)
+		panic("BHV vault close failure! hypercall returned %lu", r);
+	return 0;
+}
+
+int bhv_patch_jump_label(struct jump_entry *entry, const void *opcode,
+			 size_t len)
+{
+	int rv = 0;
+	unsigned long flags;
+
+	/*
+	 * This allocation assumes synchronization around
+	 * bhv_vault_patch_jump_label(...).  This is the current solution
+	 * here as jump label patching happens before kmem caches are
+	 * allocated.
+	 */
+	static bhv_patch_arg_t bhv_arg;
+
+	bhv_jump_label_lock();
+	local_irq_save(flags);
+	rv = bhv_vault_patch_jump_label(entry, opcode, len, &bhv_arg);
+	local_irq_restore(flags);
+	bhv_jump_label_unlock();
+
+	return rv;
+}
diff --git kernel/bhv/start.c kernel/bhv/start.c
new file mode 100644
index 000000000000..9b52e81f8d83
--- /dev/null
+++ kernel/bhv/start.c
@@ -0,0 +1,91 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2022 - BedRock Systems Inc
+ * Authors: Jonas Pfoh <jonas@bedrocksystems.com>
+ *          Sergej Proskurin <sergej@bedrocksystems.com>
+ *          Sebastian Vogl <sebastian@bedrocksystems.com>
+ */
+
+#include <bhv/bhv_print.h>
+
+#include <asm/sections.h>
+#include <asm/page.h>
+#include <asm/io.h>
+#include <asm/syscall.h>
+
+#include <linux/init_task.h>
+
+#include <bhv/bhv.h>
+#include <bhv/creds.h>
+#include <bhv/guestlog.h>
+#include <bhv/init.h>
+#include <bhv/integrity.h>
+#include <bhv/interface/common.h>
+#include <bhv/patch.h>
+#include <bhv/start.h>
+
+void __init bhv_init_platform(void)
+{
+	int rv = bhv_init_hyp(_sinittext, _einittext - _sinittext, _stext,
+			      _etext - _stext);
+	if (rv) {
+		pr_err("BHV: init hypercall failed: hypercall returned %u", rv);
+		return;
+	}
+
+	bhv_debug("Kernel text: start=0x%px end=0x%px", _stext, _etext);
+	bhv_debug("System call table: start=0x%px", sys_call_table);
+
+	bhv_initialized = true;
+	bhv_configuration_bitmap = (unsigned long *)__bhv_data_start;
+
+	rv = bhv_cred_init();
+	if (rv) {
+		pr_err("BHV: Cannot configure the BHV creds subsystem");
+		return;
+	}
+}
+
+void bhv_start(void)
+{
+	int rc;
+	bhv_mem_region_node_t *n;
+
+	if (!is_bhv_initialized())
+		return;
+
+	if (bhv_integrity_is_enabled()) {
+		n = kmem_cache_alloc(bhv_mem_region_cache, GFP_KERNEL);
+		if (!n) {
+			bhv_fail("BHV: failed to allocate mem region");
+			return;
+		}
+
+		/* Remove init text from host mappings */
+		n->region.bhv_mem_region_remove.start_addr =
+			virt_to_phys(_sinittext);
+		n->region.bhv_mem_region_remove.next = BHV_INVALID_PHYS_ADDR;
+
+		rc = bhv_remove_kern_phys_mem_region_by_region_hyp(&n->region);
+		if (rc)
+			pr_err("BHV: remove region hypercall failed: %d", rc);
+
+		kmem_cache_free(bhv_mem_region_cache, n);
+	}
+
+	rc = bhv_start_arch();
+	if (rc)
+		pr_err("BHV: bhv_start_arch failed");
+
+	if (bhv_integrity_is_enabled()) {
+		// Free alternatives used during init
+		bhv_alternatives_delete_after_init();
+	}
+
+	// Enable logging
+	bhv_guestlog_start();
+
+	rc = bhv_start_hyp();
+	if (rc)
+		pr_err("BHV: start hypercall failed: %d", rc);
+}
diff --git kernel/bpf/bpf_struct_ops.c kernel/bpf/bpf_struct_ops.c
index ac283f9b2332..4afe69e3c07c 100644
--- kernel/bpf/bpf_struct_ops.c
+++ kernel/bpf/bpf_struct_ops.c
@@ -452,6 +452,7 @@ static int bpf_struct_ops_map_update_elem(struct bpf_map *map, void *key,
 
 	set_memory_ro((long)st_map->image, 1);
 	set_memory_x((long)st_map->image, 1);
+	bhv_bpf_protect_x(st_map->image, PAGE_SIZE);
 	err = st_ops->reg(kdata);
 	if (likely(!err)) {
 		/* Pair with smp_load_acquire() during lookup_elem().
@@ -470,6 +471,7 @@ static int bpf_struct_ops_map_update_elem(struct bpf_map *map, void *key,
 	 */
 	set_memory_nx((long)st_map->image, 1);
 	set_memory_rw((long)st_map->image, 1);
+	bhv_bpf_unprotect(st_map->image);
 	bpf_map_put(map);
 
 reset_unlock:
diff --git kernel/bpf/core.c kernel/bpf/core.c
index 72e4bf0ee546..17d266c4f654 100644
--- kernel/bpf/core.c
+++ kernel/bpf/core.c
@@ -899,6 +899,12 @@ void bpf_jit_binary_free(struct bpf_binary_header *hdr)
 {
 	u32 pages = hdr->pages;
 
+	/*
+	 * XXX: bpf_jit_free_exec is a weak symbol. As long as we do not
+	 * directly free memory sections from inside module_memfree, we will not
+	 * be able to place bhv_bpf_unprotect into bpf_jit_free_exec.
+	 */
+	bhv_bpf_unprotect(hdr);
 	bpf_jit_free_exec(hdr);
 	bpf_jit_uncharge_modmem(pages);
 }
diff --git kernel/bpf/trampoline.c kernel/bpf/trampoline.c
index 986dabc3d11f..a8ddc45aa8c9 100644
--- kernel/bpf/trampoline.c
+++ kernel/bpf/trampoline.c
@@ -38,6 +38,11 @@ void *bpf_jit_alloc_exec_page(void)
 	 * everytime new program is attached or detached.
 	 */
 	set_memory_x((long)image, 1);
+	/*
+	 * XXX: Make sure that we foresee all cases that would allow new
+	 * programs to attach/detach and handle the permissions appropriately.
+	 */
+	bhv_bpf_protect_x(image, PAGE_SIZE);
 	return image;
 }
 
@@ -171,6 +176,7 @@ static void __bpf_tramp_image_put_deferred(struct work_struct *work)
 
 	im = container_of(work, struct bpf_tramp_image, work);
 	bpf_image_ksym_del(&im->ksym);
+	bhv_bpf_unprotect(im->image);
 	bpf_jit_free_exec(im->image);
 	bpf_jit_uncharge_modmem(1);
 	percpu_ref_exit(&im->pcref);
@@ -289,6 +295,7 @@ static struct bpf_tramp_image *bpf_tramp_image_alloc(u64 key, u32 idx)
 	return im;
 
 out_free_image:
+	bhv_bpf_unprotect(im->image);
 	bpf_jit_free_exec(im->image);
 out_uncharge:
 	bpf_jit_uncharge_modmem(1);
diff --git kernel/cred.c kernel/cred.c
index 421b1149c651..b3d4fd6c0c8f 100644
--- kernel/cred.c
+++ kernel/cred.c
@@ -17,6 +17,8 @@
 #include <linux/cn_proc.h>
 #include <linux/uidgid.h>
 
+#include <bhv/creds.h>
+
 #if 0
 #define kdebug(FMT, ...)						\
 	printk("[%-5.5s%5u] " FMT "\n",					\
@@ -112,6 +114,7 @@ static void put_cred_rcu(struct rcu_head *rcu)
 #endif
 
 	security_cred_free(cred);
+	bhv_cred_release(cred);
 	key_put(cred->session_keyring);
 	key_put(cred->process_keyring);
 	key_put(cred->thread_keyring);
@@ -451,6 +454,8 @@ int commit_creds(struct cred *new)
 #endif
 	BUG_ON(atomic_read(&new->usage) < 1);
 
+	bhv_cred_commit(new);
+
 	get_cred(new); /* we will require a ref for the subj creds too */
 
 	/* dumpability changes */
@@ -690,6 +695,9 @@ struct cred *prepare_kernel_cred(struct task_struct *daemon)
 
 	kdebug("prepare_kernel_cred() alloc %p", new);
 
+	if (bhv_cred_assign_priv(new, daemon))
+		return NULL;
+
 	if (daemon)
 		old = get_task_cred(daemon);
 	else
diff --git kernel/fork.c kernel/fork.c
index 3f96400a0ac6..ba2b7434a5d4 100644
--- kernel/fork.c
+++ kernel/fork.c
@@ -97,6 +97,8 @@
 #include <linux/scs.h>
 #include <linux/io_uring.h>
 
+#include <bhv/creds.h>
+
 #include <asm/pgalloc.h>
 #include <linux/uaccess.h>
 #include <asm/mmu_context.h>
@@ -2087,9 +2089,12 @@ static __latent_entropy struct task_struct *copy_process(
 	retval = security_task_alloc(p, clone_flags);
 	if (retval)
 		goto bad_fork_cleanup_audit;
-	retval = copy_semundo(clone_flags, p);
+	retval = bhv_cred_assign(p, clone_flags);
 	if (retval)
 		goto bad_fork_cleanup_security;
+	retval = copy_semundo(clone_flags, p);
+	if (retval)
+		goto bad_fork_cleanup_bhv_assign;
 	retval = copy_files(clone_flags, p);
 	if (retval)
 		goto bad_fork_cleanup_semundo;
@@ -2356,6 +2361,7 @@ static __latent_entropy struct task_struct *copy_process(
 	exit_files(p); /* blocking */
 bad_fork_cleanup_semundo:
 	exit_sem(p);
+bad_fork_cleanup_bhv_assign:
 bad_fork_cleanup_security:
 	security_task_free(p);
 bad_fork_cleanup_audit:
diff --git kernel/jump_label.c kernel/jump_label.c
index 4ae693ce71a4..37ae60aa8986 100644
--- kernel/jump_label.c
+++ kernel/jump_label.c
@@ -19,6 +19,8 @@
 #include <linux/cpu.h>
 #include <asm/sections.h>
 
+#include <bhv/patch.h>
+
 /* mutex to protect coming/going of the jump_label table */
 static DEFINE_MUTEX(jump_label_mutex);
 
@@ -678,7 +680,7 @@ static int jump_label_add_module(struct module *mod)
 			__jump_label_update(key, iter, iter_stop, true);
 	}
 
-	return 0;
+	return bhv_jump_label_add_module(mod);
 }
 
 static void jump_label_del_module(struct module *mod)
@@ -689,6 +691,8 @@ static void jump_label_del_module(struct module *mod)
 	struct static_key *key = NULL;
 	struct static_key_mod *jlm, **prev;
 
+	bhv_jump_label_del_module(mod);
+
 	for (iter = iter_start; iter < iter_stop; iter++) {
 		if (jump_entry_key(iter) == key)
 			continue;
diff --git kernel/module.c kernel/module.c
index 185b2655bc20..e5c3bd1b5454 100644
--- kernel/module.c
+++ kernel/module.c
@@ -60,6 +60,8 @@
 #include <uapi/linux/module.h>
 #include "module-internal.h"
 
+#include <bhv/module.h>
+
 #define CREATE_TRACE_POINTS
 #include <trace/events/module.h>
 
@@ -2263,6 +2265,8 @@ static void free_module(struct module *mod)
 
 	/* Finally, free the core (containing the module structure) */
 	module_memfree(mod->core_layout.base);
+
+	bhv_module_unload(mod);
 }
 
 void *__symbol_get(const char *symbol)
@@ -3618,6 +3622,7 @@ static void module_deallocate(struct module *mod, struct load_info *info)
 	module_arch_freeing_init(mod);
 	module_memfree(mod->init_layout.base);
 	module_memfree(mod->core_layout.base);
+	bhv_module_unload(mod);
 }
 
 int __weak module_finalize(const Elf_Ehdr *hdr,
@@ -3776,6 +3781,7 @@ static noinline int do_init_module(struct module *mod)
 	module_enable_ro(mod, true);
 	mod_tree_remove_init(mod);
 	module_arch_freeing_init(mod);
+	bhv_module_load_complete(mod);
 	mod->init_layout.base = NULL;
 	mod->init_layout.size = 0;
 	mod->init_layout.ro_size = 0;
@@ -4075,6 +4081,8 @@ static int load_module(struct load_info *info, const char __user *uargs,
 	if (err)
 		goto ddebug_cleanup;
 
+	bhv_module_load_prepare(mod);
+
 	err = prepare_coming_module(mod);
 	if (err)
 		goto bug_cleanup;
diff --git security/Kconfig security/Kconfig
index 7561f6f99f1d..dc3b6ada1845 100644
--- security/Kconfig
+++ security/Kconfig
@@ -235,6 +235,7 @@ source "security/smack/Kconfig"
 source "security/tomoyo/Kconfig"
 source "security/apparmor/Kconfig"
 source "security/loadpin/Kconfig"
+source "security/bhv/Kconfig"
 source "security/yama/Kconfig"
 source "security/safesetid/Kconfig"
 source "security/lockdown/Kconfig"
@@ -277,11 +278,11 @@ endchoice
 
 config LSM
 	string "Ordered list of enabled LSMs"
-	default "lockdown,yama,loadpin,safesetid,integrity,smack,selinux,tomoyo,apparmor,bpf" if DEFAULT_SECURITY_SMACK
-	default "lockdown,yama,loadpin,safesetid,integrity,apparmor,selinux,smack,tomoyo,bpf" if DEFAULT_SECURITY_APPARMOR
-	default "lockdown,yama,loadpin,safesetid,integrity,tomoyo,bpf" if DEFAULT_SECURITY_TOMOYO
-	default "lockdown,yama,loadpin,safesetid,integrity,bpf" if DEFAULT_SECURITY_DAC
-	default "lockdown,yama,loadpin,safesetid,integrity,selinux,smack,tomoyo,apparmor,bpf"
+	default "lockdown,yama,loadpin,safesetid,integrity,smack,selinux,tomoyo,apparmor,bpf,bhv" if DEFAULT_SECURITY_SMACK
+	default "lockdown,yama,loadpin,safesetid,integrity,apparmor,selinux,smack,tomoyo,bpf,bhv" if DEFAULT_SECURITY_APPARMOR
+	default "lockdown,yama,loadpin,safesetid,integrity,tomoyo,bpf,bhv" if DEFAULT_SECURITY_TOMOYO
+	default "lockdown,yama,loadpin,safesetid,integrity,bpf,bhv" if DEFAULT_SECURITY_DAC
+	default "lockdown,yama,loadpin,safesetid,integrity,selinux,smack,tomoyo,apparmor,bpf,bhv"
 	help
 	  A comma-separated list of LSMs, in initialization order.
 	  Any LSMs left off this list will be ignored. This can be
diff --git security/Makefile security/Makefile
index 3baf435de541..9958117a6395 100644
--- security/Makefile
+++ security/Makefile
@@ -10,6 +10,7 @@ subdir-$(CONFIG_SECURITY_TOMOYO)        += tomoyo
 subdir-$(CONFIG_SECURITY_APPARMOR)	+= apparmor
 subdir-$(CONFIG_SECURITY_YAMA)		+= yama
 subdir-$(CONFIG_SECURITY_LOADPIN)	+= loadpin
+subdir-$(CONFIG_SECURITY_BHV)		+= bhv
 subdir-$(CONFIG_SECURITY_SAFESETID)    += safesetid
 subdir-$(CONFIG_SECURITY_LOCKDOWN_LSM)	+= lockdown
 subdir-$(CONFIG_BPF_LSM)		+= bpf
@@ -28,6 +29,7 @@ obj-$(CONFIG_SECURITY_TOMOYO)		+= tomoyo/
 obj-$(CONFIG_SECURITY_APPARMOR)		+= apparmor/
 obj-$(CONFIG_SECURITY_YAMA)		+= yama/
 obj-$(CONFIG_SECURITY_LOADPIN)		+= loadpin/
+obj-$(CONFIG_SECURITY_BHV)		+= bhv/
 obj-$(CONFIG_SECURITY_SAFESETID)       += safesetid/
 obj-$(CONFIG_SECURITY_LOCKDOWN_LSM)	+= lockdown/
 obj-$(CONFIG_CGROUPS)			+= device_cgroup.o
diff --git security/bhv/Kconfig security/bhv/Kconfig
new file mode 100644
index 000000000000..309c33608091
--- /dev/null
+++ security/bhv/Kconfig
@@ -0,0 +1,9 @@
+# SPDX-License-Identifier: GPL-2.0-only
+config SECURITY_BHV
+	bool "Enable the BHV LSM."
+	depends on SECURITY
+	depends on BHV_VAS
+	default y
+	help
+	  Enables the BHV LSM. The BHV LSM provides hooking capabilities for
+	  additional protections such as the process and the driver ACL.
diff --git security/bhv/Makefile security/bhv/Makefile
new file mode 100644
index 000000000000..f921bdf385ea
--- /dev/null
+++ security/bhv/Makefile
@@ -0,0 +1,2 @@
+# SPDX-License-Identifier: GPL-2.0-only
+obj-$(CONFIG_SECURITY_BHV) += bhv.o
diff --git security/bhv/bhv.c security/bhv/bhv.c
new file mode 100644
index 000000000000..56ca69a80ac4
--- /dev/null
+++ security/bhv/bhv.c
@@ -0,0 +1,155 @@
+#include <linux/lsm_hooks.h>
+#include <linux/binfmts.h>
+
+#include <bhv/acl.h>
+#include <bhv/guestlog.h>
+
+static int bhv_read_file(struct file *file, enum kernel_read_file_id id,
+			 bool whole_file)
+{
+	if (id == READING_MODULE) {
+		char *filename = NULL;
+		char *filename_buf = NULL;
+
+		if (file != NULL && whole_file) {
+			filename_buf = (char *)__get_free_pages(GFP_KERNEL, 0);
+			if (filename_buf == NULL) {
+				bhv_fail(
+					"BHV: Unable to allocate acl violation filename buf");
+				return -ENOMEM;
+			}
+			filename =
+				d_path(&file->f_path, filename_buf, PAGE_SIZE);
+			if (IS_ERR(filename))
+				filename = NULL;
+			pr_debug("[bhv] READ DATA HOOK: %s", filename);
+
+			if (bhv_guestlog_log_driver_events()) {
+				if (filename != NULL)
+					bhv_guestlog_log_driver_load(filename);
+				else
+					bhv_guestlog_log_driver_load(
+						"[ UNKNOWN DRIVER ]");
+			}
+		}
+
+		if (bhv_acl_is_driver_acl_enabled()) {
+			if (bhv_block_driver(filename)) {
+				if (filename_buf)
+					free_pages((unsigned long)filename_buf,
+						   0);
+				return -EPERM;
+			}
+		}
+		if (filename_buf)
+			free_pages((unsigned long)filename_buf, 0);
+	}
+	return 0;
+}
+
+static int bhv_load_data(enum kernel_load_data_id id, bool contents)
+{
+	const char *origin = kernel_read_file_id_str(id);
+	pr_debug("[bhv] LOAD DATA HOOK: %s", origin);
+
+	if (id == LOADING_MODULE) {
+		if (bhv_guestlog_log_driver_events()) {
+			bhv_guestlog_log_driver_load("[ UNKNOWN DRIVER ]");
+		}
+
+		if (bhv_acl_is_driver_acl_enabled()) {
+			if (bhv_block_driver(NULL))
+				return -EPERM;
+		}
+	}
+
+	return 0;
+}
+
+static int bhv_task_alloc(struct task_struct *target,
+			  long unsigned int clone_flags)
+{
+	pr_debug("[bhv] TASK CREATE HOOK:");
+	pr_debug("\t-> PID: %d", target->pid);
+	pr_debug("\t-> PPID: %d", target->parent->pid);
+	pr_debug("\t-> NAME: %s", target->comm);
+
+	if (bhv_guestlog_log_process_events()) {
+		bhv_guestlog_log_process_fork(target->pid, target->comm,
+					      target->parent->pid,
+					      target->parent->comm);
+	}
+
+	// Filters kernel treads
+	if (bhv_acl_is_proc_acl_enabled() && target->mm != NULL) {
+		char *filename = NULL;
+		char *filename_buf = (char *)__get_free_pages(GFP_KERNEL, 0);
+		if (filename_buf == NULL) {
+			bhv_fail(
+				"BHV: Unable to allocate acl violation filename buf");
+			return -ENOMEM;
+		}
+		filename = d_path(&target->mm->exe_file->f_path, filename_buf,
+				  PAGE_SIZE);
+		if (IS_ERR(filename))
+			filename = NULL;
+		if (bhv_block_process(filename)) {
+			free_pages((unsigned long)filename_buf, 0);
+			return -EPERM;
+		}
+		free_pages((unsigned long)filename_buf, 0);
+	}
+
+	return 0;
+}
+
+static void bhv_task_free(struct task_struct *target)
+{
+	pr_debug("[bhv] TASK FREE HOOK:");
+	pr_debug("\t-> PID: %d", target->pid);
+	pr_debug("\t-> PPID: %d", target->parent->pid);
+	pr_debug("\t-> NAME: %s", target->comm);
+
+	if (bhv_guestlog_log_process_events()) {
+		bhv_guestlog_log_process_exit(target->pid, target->parent->pid,
+					      target->comm);
+	}
+}
+
+static int bhv_bprm_check_security(struct linux_binprm *bprm)
+{
+	pr_debug("[bhv] BPRM CHECK SECURITY HOOK:");
+	pr_debug("\t-> FILENAME: %s", bprm->filename);
+
+	if (bhv_guestlog_log_process_events()) {
+		bhv_guestlog_log_process_exec(
+			current->pid, current->parent->pid, bprm->filename);
+	}
+
+	if (bhv_acl_is_proc_acl_enabled()) {
+		if (bhv_block_process(bprm->filename))
+			return -EPERM;
+	}
+
+	return 0;
+}
+
+static struct security_hook_list bhv_hooks[] __lsm_ro_after_init = {
+	LSM_HOOK_INIT(kernel_read_file, bhv_read_file), // finit_module
+	LSM_HOOK_INIT(kernel_load_data, bhv_load_data), // init_module
+	LSM_HOOK_INIT(task_alloc, bhv_task_alloc), // fork
+	LSM_HOOK_INIT(task_free, bhv_task_free), // exit
+	LSM_HOOK_INIT(bprm_check_security, bhv_bprm_check_security), // execve
+};
+
+static int __init bhv_init(void)
+{
+	pr_info("[bhv] LSM active");
+	security_add_hooks(bhv_hooks, ARRAY_SIZE(bhv_hooks), "bhv");
+	return 0;
+}
+
+DEFINE_LSM(bhv) = {
+	.name = "bhv",
+	.init = bhv_init,
+};
